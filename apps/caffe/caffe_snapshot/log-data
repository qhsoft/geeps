I1024 14:29:05.213105 21201 caffe.cpp:187] Using GPUs 0
I1024 14:29:05.228776 21201 caffe.cpp:192] GPU 0: GeForce GTX 1080 Ti
I1024 14:29:05.432652 21201 solver.cpp:48] Initializing solver from parameters: 
test_iter: 156
test_interval: 1000
base_lr: 0.001
display: 100
max_iter: 100000
lr_policy: "fixed"
momentum: 0.9
weight_decay: 0.004
snapshot: 2000
snapshot_prefix: "examples/cifar10/1parts/inception_snapshot"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/1parts/inception_train_val.prototxt.caffe"
snapshot_after_train: false
test_initialization: false
I1024 14:29:05.432744 21201 solver.cpp:91] Creating training net from net file: examples/cifar10/1parts/inception_train_val.prototxt.caffe
I1024 14:29:05.433112 21201 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1024 14:29:05.433135 21201 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1024 14:29:05.433354 21201 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_quick"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mean_file: "examples/cifar10/1parts/mean.binaryproto.0"
  }
  data_param {
    source: "examples/cifar10/1parts/cifar10_train_lmdb.0"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv_conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv_conv1"
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv_conv1"
  top: "bn_conv1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "bn_conv1"
  top: "bn_conv1"
}
layer {
  name: "conv_in3a_1x1"
  type: "Convolution"
  bottom: "bn_conv1"
  top: "conv_in3a_1x1"
  convolution_param {
    num_output: 32
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in3a_1x1"
  type: "BatchNorm"
  bottom: "conv_in3a_1x1"
  top: "bn_in3a_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in3a_1x1"
  type: "ReLU"
  bottom: "bn_in3a_1x1"
  top: "bn_in3a_1x1"
}
layer {
  name: "conv_in3a_3x3"
  type: "Convolution"
  bottom: "bn_conv1"
  top: "conv_in3a_3x3"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in3a_3x3"
  type: "BatchNorm"
  bottom: "conv_in3a_3x3"
  top: "bn_in3a_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in3a_3x3"
  type: "ReLU"
  bottom: "bn_in3a_3x3"
  top: "bn_in3a_3x3"
}
layer {
  name: "ch_concat_in3a_chconcat"
  type: "Concat"
  bottom: "bn_in3a_1x1"
  bottom: "bn_in3a_3x3"
  top: "ch_concat_in3a_chconcat"
}
layer {
  name: "conv_in3b_1x1"
  type: "Convolution"
  bottom: "ch_concat_in3a_chconcat"
  top: "conv_in3b_1x1"
  convolution_param {
    num_output: 32
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in3b_1x1"
  type: "BatchNorm"
  bottom: "conv_in3b_1x1"
  top: "bn_in3b_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in3b_1x1"
  type: "ReLU"
  bottom: "bn_in3b_1x1"
  top: "bn_in3b_1x1"
}
layer {
  name: "conv_in3b_3x3"
  type: "Convolution"
  bottom: "ch_concat_in3a_chconcat"
  top: "conv_in3b_3x3"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in3b_3x3"
  type: "BatchNorm"
  bottom: "conv_in3b_3x3"
  top: "bn_in3b_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in3b_3x3"
  type: "ReLU"
  bottom: "bn_in3b_3x3"
  top: "bn_in3b_3x3"
}
layer {
  name: "ch_concat_in3b_chconcat"
  type: "Concat"
  bottom: "bn_in3b_1x1"
  bottom: "bn_in3b_3x3"
  top: "ch_concat_in3b_chconcat"
}
layer {
  name: "conv_in3c_3x3"
  type: "Convolution"
  bottom: "ch_concat_in3b_chconcat"
  top: "conv_in3c_3x3"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in3c_3x3"
  type: "BatchNorm"
  bottom: "conv_in3c_3x3"
  top: "bn_in3c_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in3c_3x3"
  type: "ReLU"
  bottom: "bn_in3c_3x3"
  top: "bn_in3c_3x3"
}
layer {
  name: "max_pool_in3c_pool"
  type: "Pooling"
  bottom: "ch_concat_in3b_chconcat"
  top: "max_pool_in3c_pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ch_concat_in3c_chconcat"
  type: "Concat"
  bottom: "bn_in3c_3x3"
  bottom: "max_pool_in3c_pool"
  top: "ch_concat_in3c_chconcat"
}
layer {
  name: "conv_in4a_1x1"
  type: "Convolution"
  bottom: "ch_concat_in3c_chconcat"
  top: "conv_in4a_1x1"
  convolution_param {
    num_output: 112
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4a_1x1"
  type: "BatchNorm"
  bottom: "conv_in4a_1x1"
  top: "bn_in4a_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4a_1x1"
  type: "ReLU"
  bottom: "bn_in4a_1x1"
  top: "bn_in4a_1x1"
}
layer {
  name: "conv_in4a_3x3"
  type: "Convolution"
  bottom: "ch_concat_in3c_chconcat"
  top: "conv_in4a_3x3"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4a_3x3"
  type: "BatchNorm"
  bottom: "conv_in4a_3x3"
  top: "bn_in4a_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4a_3x3"
  type: "ReLU"
  bottom: "bn_in4a_3x3"
  top: "bn_in4a_3x3"
}
layer {
  name: "ch_concat_in4a_chconcat"
  type: "Concat"
  bottom: "bn_in4a_1x1"
  bottom: "bn_in4a_3x3"
  top: "ch_concat_in4a_chconcat"
}
layer {
  name: "conv_in4b_1x1"
  type: "Convolution"
  bottom: "ch_concat_in4a_chconcat"
  top: "conv_in4b_1x1"
  convolution_param {
    num_output: 96
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4b_1x1"
  type: "BatchNorm"
  bottom: "conv_in4b_1x1"
  top: "bn_in4b_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4b_1x1"
  type: "ReLU"
  bottom: "bn_in4b_1x1"
  top: "bn_in4b_1x1"
}
layer {
  name: "conv_in4b_3x3"
  type: "Convolution"
  bottom: "ch_concat_in4a_chconcat"
  top: "conv_in4b_3x3"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4b_3x3"
  type: "BatchNorm"
  bottom: "conv_in4b_3x3"
  top: "bn_in4b_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4b_3x3"
  type: "ReLU"
  bottom: "bn_in4b_3x3"
  top: "bn_in4b_3x3"
}
layer {
  name: "ch_concat_in4b_chconcat"
  type: "Concat"
  bottom: "bn_in4b_1x1"
  bottom: "bn_in4b_3x3"
  top: "ch_concat_in4b_chconcat"
}
layer {
  name: "conv_in4c_1x1"
  type: "Convolution"
  bottom: "ch_concat_in4b_chconcat"
  top: "conv_in4c_1x1"
  convolution_param {
    num_output: 80
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4c_1x1"
  type: "BatchNorm"
  bottom: "conv_in4c_1x1"
  top: "bn_in4c_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4c_1x1"
  type: "ReLU"
  bottom: "bn_in4c_1x1"
  top: "bn_in4c_1x1"
}
layer {
  name: "conv_in4c_3x3"
  type: "Convolution"
  bottom: "ch_concat_in4b_chconcat"
  top: "conv_in4c_3x3"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4c_3x3"
  type: "BatchNorm"
  bottom: "conv_in4c_3x3"
  top: "bn_in4c_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4c_3x3"
  type: "ReLU"
  bottom: "bn_in4c_3x3"
  top: "bn_in4c_3x3"
}
layer {
  name: "ch_concat_in4c_chconcat"
  type: "Concat"
  bottom: "bn_in4c_1x1"
  bottom: "bn_in4c_3x3"
  top: "ch_concat_in4c_chconcat"
}
layer {
  name: "conv_in4d_1x1"
  type: "Convolution"
  bottom: "ch_concat_in4c_chconcat"
  top: "conv_in4d_1x1"
  convolution_param {
    num_output: 48
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4d_1x1"
  type: "BatchNorm"
  bottom: "conv_in4d_1x1"
  top: "bn_in4d_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4d_1x1"
  type: "ReLU"
  bottom: "bn_in4d_1x1"
  top: "bn_in4d_1x1"
}
layer {
  name: "conv_in4d_3x3"
  type: "Convolution"
  bottom: "ch_concat_in4c_chconcat"
  top: "conv_in4d_3x3"
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4d_3x3"
  type: "BatchNorm"
  bottom: "conv_in4d_3x3"
  top: "bn_in4d_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4d_3x3"
  type: "ReLU"
  bottom: "bn_in4d_3x3"
  top: "bn_in4d_3x3"
}
layer {
  name: "ch_concat_in4d_chconcat"
  type: "Concat"
  bottom: "bn_in4d_1x1"
  bottom: "bn_in4d_3x3"
  top: "ch_concat_in4d_chconcat"
}
layer {
  name: "conv_in4e_3x3"
  type: "Convolution"
  bottom: "ch_concat_in4d_chconcat"
  top: "conv_in4e_3x3"
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4e_3x3"
  type: "BatchNorm"
  bottom: "conv_in4e_3x3"
  top: "bn_in4e_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4e_3x3"
  type: "ReLU"
  bottom: "bn_in4e_3x3"
  top: "bn_in4e_3x3"
}
layer {
  name: "max_pool_in4e_pool"
  type: "Pooling"
  bottom: "ch_concat_in4d_chconcat"
  top: "max_pool_in4e_pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ch_concat_in4e_chconcat"
  type: "Concat"
  bottom: "bn_in4e_3x3"
  bottom: "max_pool_in4e_pool"
  top: "ch_concat_in4e_chconcat"
}
layer {
  name: "conv_in5a_1x1"
  type: "Convolution"
  bottom: "ch_concat_in4e_chconcat"
  top: "conv_in5a_1x1"
  convolution_param {
    num_output: 176
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in5a_1x1"
  type: "BatchNorm"
  bottom: "conv_in5a_1x1"
  top: "bn_in5a_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in5a_1x1"
  type: "ReLU"
  bottom: "bn_in5a_1x1"
  top: "bn_in5a_1x1"
}
layer {
  name: "conv_in5a_3x3"
  type: "Convolution"
  bottom: "ch_concat_in4e_chconcat"
  top: "conv_in5a_3x3"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in5a_3x3"
  type: "BatchNorm"
  bottom: "conv_in5a_3x3"
  top: "bn_in5a_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in5a_3x3"
  type: "ReLU"
  bottom: "bn_in5a_3x3"
  top: "bn_in5a_3x3"
}
layer {
  name: "ch_concat_in5a_chconcat"
  type: "Concat"
  bottom: "bn_in5a_1x1"
  bottom: "bn_in5a_3x3"
  top: "ch_concat_in5a_chconcat"
}
layer {
  name: "conv_in5b_1x1"
  type: "Convolution"
  bottom: "ch_concat_in5a_chconcat"
  top: "conv_in5b_1x1"
  convolution_param {
    num_output: 176
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in5b_1x1"
  type: "BatchNorm"
  bottom: "conv_in5b_1x1"
  top: "bn_in5b_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in5b_1x1"
  type: "ReLU"
  bottom: "bn_in5b_1x1"
  top: "bn_in5b_1x1"
}
layer {
  name: "conv_in5b_3x3"
  type: "Convolution"
  bottom: "ch_concat_in5a_chconcat"
  top: "conv_in5b_3x3"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in5b_3x3"
  type: "BatchNorm"
  bottom: "conv_in5b_3x3"
  top: "bn_in5b_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in5b_3x3"
  type: "ReLU"
  bottom: "bn_in5b_3x3"
  top: "bn_in5b_3x3"
}
layer {
  name: "ch_concat_in5b_chconcat"
  type: "Concat"
  bottom: "bn_in5b_1x1"
  bottom: "bn_in5b_3x3"
  top: "ch_concat_in5b_chconcat"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "ch_concat_in5b_chconcat"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "fc1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  bottom: "label"
  top: "loss"
  include {
    phase: TRAIN
  }
}
I1024 14:29:05.433588 21201 layer_factory.hpp:77] Creating layer cifar
I1024 14:29:05.433985 21201 net.cpp:91] Creating Layer cifar
I1024 14:29:05.433995 21201 net.cpp:399] cifar -> data
I1024 14:29:05.434010 21201 net.cpp:399] cifar -> label
I1024 14:29:05.434020 21201 data_transformer.cpp:25] Loading mean file from: examples/cifar10/1parts/mean.binaryproto.0
I1024 14:29:05.434720 21209 db_lmdb.cpp:38] Opened lmdb examples/cifar10/1parts/cifar10_train_lmdb.0
I1024 14:29:05.442440 21201 data_layer.cpp:41] output data size: 100,3,32,32
I1024 14:29:05.444607 21201 net.cpp:141] Setting up cifar
I1024 14:29:05.444618 21201 net.cpp:148] Top shape: 100 3 32 32 (307200)
I1024 14:29:05.444622 21201 net.cpp:148] Top shape: 100 (100)
I1024 14:29:05.444623 21201 net.cpp:156] Memory required for data: 1229200
I1024 14:29:05.444630 21201 layer_factory.hpp:77] Creating layer conv_conv1
I1024 14:29:05.444643 21201 net.cpp:91] Creating Layer conv_conv1
I1024 14:29:05.444648 21201 net.cpp:425] conv_conv1 <- data
I1024 14:29:05.444679 21201 net.cpp:399] conv_conv1 -> conv_conv1
I1024 14:29:05.444876 21201 net.cpp:141] Setting up conv_conv1
I1024 14:29:05.444882 21201 net.cpp:148] Top shape: 100 96 32 32 (9830400)
I1024 14:29:05.444885 21201 net.cpp:156] Memory required for data: 40550800
I1024 14:29:05.444895 21201 layer_factory.hpp:77] Creating layer bn_conv1
I1024 14:29:05.444900 21201 net.cpp:91] Creating Layer bn_conv1
I1024 14:29:05.444901 21201 net.cpp:425] bn_conv1 <- conv_conv1
I1024 14:29:05.444905 21201 net.cpp:399] bn_conv1 -> bn_conv1
I1024 14:29:05.445495 21201 net.cpp:141] Setting up bn_conv1
I1024 14:29:05.445504 21201 net.cpp:148] Top shape: 100 96 32 32 (9830400)
I1024 14:29:05.445506 21201 net.cpp:156] Memory required for data: 79872400
I1024 14:29:05.445514 21201 layer_factory.hpp:77] Creating layer relu_conv1
I1024 14:29:05.445518 21201 net.cpp:91] Creating Layer relu_conv1
I1024 14:29:05.445520 21201 net.cpp:425] relu_conv1 <- bn_conv1
I1024 14:29:05.445523 21201 net.cpp:386] relu_conv1 -> bn_conv1 (in-place)
I1024 14:29:05.445528 21201 net.cpp:141] Setting up relu_conv1
I1024 14:29:05.445529 21201 net.cpp:148] Top shape: 100 96 32 32 (9830400)
I1024 14:29:05.445531 21201 net.cpp:156] Memory required for data: 119194000
I1024 14:29:05.445534 21201 layer_factory.hpp:77] Creating layer bn_conv1_relu_conv1_0_split
I1024 14:29:05.445538 21201 net.cpp:91] Creating Layer bn_conv1_relu_conv1_0_split
I1024 14:29:05.445539 21201 net.cpp:425] bn_conv1_relu_conv1_0_split <- bn_conv1
I1024 14:29:05.445557 21201 net.cpp:399] bn_conv1_relu_conv1_0_split -> bn_conv1_relu_conv1_0_split_0
I1024 14:29:05.445562 21201 net.cpp:399] bn_conv1_relu_conv1_0_split -> bn_conv1_relu_conv1_0_split_1
I1024 14:29:05.445601 21201 net.cpp:141] Setting up bn_conv1_relu_conv1_0_split
I1024 14:29:05.445606 21201 net.cpp:148] Top shape: 100 96 32 32 (9830400)
I1024 14:29:05.445611 21201 net.cpp:148] Top shape: 100 96 32 32 (9830400)
I1024 14:29:05.445613 21201 net.cpp:156] Memory required for data: 197837200
I1024 14:29:05.445616 21201 layer_factory.hpp:77] Creating layer conv_in3a_1x1
I1024 14:29:05.445621 21201 net.cpp:91] Creating Layer conv_in3a_1x1
I1024 14:29:05.445626 21201 net.cpp:425] conv_in3a_1x1 <- bn_conv1_relu_conv1_0_split_0
I1024 14:29:05.445631 21201 net.cpp:399] conv_in3a_1x1 -> conv_in3a_1x1
I1024 14:29:05.445807 21201 net.cpp:141] Setting up conv_in3a_1x1
I1024 14:29:05.445813 21201 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I1024 14:29:05.445816 21201 net.cpp:156] Memory required for data: 210944400
I1024 14:29:05.445818 21201 layer_factory.hpp:77] Creating layer bn_in3a_1x1
I1024 14:29:05.445822 21201 net.cpp:91] Creating Layer bn_in3a_1x1
I1024 14:29:05.445824 21201 net.cpp:425] bn_in3a_1x1 <- conv_in3a_1x1
I1024 14:29:05.445828 21201 net.cpp:399] bn_in3a_1x1 -> bn_in3a_1x1
I1024 14:29:05.446084 21201 net.cpp:141] Setting up bn_in3a_1x1
I1024 14:29:05.446089 21201 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I1024 14:29:05.446091 21201 net.cpp:156] Memory required for data: 224051600
I1024 14:29:05.446097 21201 layer_factory.hpp:77] Creating layer relu_in3a_1x1
I1024 14:29:05.446101 21201 net.cpp:91] Creating Layer relu_in3a_1x1
I1024 14:29:05.446103 21201 net.cpp:425] relu_in3a_1x1 <- bn_in3a_1x1
I1024 14:29:05.446106 21201 net.cpp:386] relu_in3a_1x1 -> bn_in3a_1x1 (in-place)
I1024 14:29:05.446110 21201 net.cpp:141] Setting up relu_in3a_1x1
I1024 14:29:05.446112 21201 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I1024 14:29:05.446115 21201 net.cpp:156] Memory required for data: 237158800
I1024 14:29:05.446117 21201 layer_factory.hpp:77] Creating layer conv_in3a_3x3
I1024 14:29:05.446141 21201 net.cpp:91] Creating Layer conv_in3a_3x3
I1024 14:29:05.446146 21201 net.cpp:425] conv_in3a_3x3 <- bn_conv1_relu_conv1_0_split_1
I1024 14:29:05.446151 21201 net.cpp:399] conv_in3a_3x3 -> conv_in3a_3x3
I1024 14:29:05.446759 21201 net.cpp:141] Setting up conv_in3a_3x3
I1024 14:29:05.446768 21201 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I1024 14:29:05.446769 21201 net.cpp:156] Memory required for data: 250266000
I1024 14:29:05.446774 21201 layer_factory.hpp:77] Creating layer bn_in3a_3x3
I1024 14:29:05.446777 21201 net.cpp:91] Creating Layer bn_in3a_3x3
I1024 14:29:05.446779 21201 net.cpp:425] bn_in3a_3x3 <- conv_in3a_3x3
I1024 14:29:05.446782 21201 net.cpp:399] bn_in3a_3x3 -> bn_in3a_3x3
I1024 14:29:05.446954 21201 net.cpp:141] Setting up bn_in3a_3x3
I1024 14:29:05.446961 21201 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I1024 14:29:05.446964 21201 net.cpp:156] Memory required for data: 263373200
I1024 14:29:05.446970 21201 layer_factory.hpp:77] Creating layer relu_in3a_3x3
I1024 14:29:05.446974 21201 net.cpp:91] Creating Layer relu_in3a_3x3
I1024 14:29:05.446976 21201 net.cpp:425] relu_in3a_3x3 <- bn_in3a_3x3
I1024 14:29:05.446979 21201 net.cpp:386] relu_in3a_3x3 -> bn_in3a_3x3 (in-place)
I1024 14:29:05.446982 21201 net.cpp:141] Setting up relu_in3a_3x3
I1024 14:29:05.446985 21201 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I1024 14:29:05.446987 21201 net.cpp:156] Memory required for data: 276480400
I1024 14:29:05.446990 21201 layer_factory.hpp:77] Creating layer ch_concat_in3a_chconcat
I1024 14:29:05.446992 21201 net.cpp:91] Creating Layer ch_concat_in3a_chconcat
I1024 14:29:05.446995 21201 net.cpp:425] ch_concat_in3a_chconcat <- bn_in3a_1x1
I1024 14:29:05.447011 21201 net.cpp:425] ch_concat_in3a_chconcat <- bn_in3a_3x3
I1024 14:29:05.447015 21201 net.cpp:399] ch_concat_in3a_chconcat -> ch_concat_in3a_chconcat
I1024 14:29:05.447031 21201 net.cpp:141] Setting up ch_concat_in3a_chconcat
I1024 14:29:05.447037 21201 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I1024 14:29:05.447054 21201 net.cpp:156] Memory required for data: 302694800
I1024 14:29:05.447057 21201 layer_factory.hpp:77] Creating layer ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split
I1024 14:29:05.447060 21201 net.cpp:91] Creating Layer ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split
I1024 14:29:05.447062 21201 net.cpp:425] ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split <- ch_concat_in3a_chconcat
I1024 14:29:05.447065 21201 net.cpp:399] ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split -> ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split_0
I1024 14:29:05.447069 21201 net.cpp:399] ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split -> ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split_1
I1024 14:29:05.447087 21201 net.cpp:141] Setting up ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split
I1024 14:29:05.447089 21201 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I1024 14:29:05.447093 21201 net.cpp:148] Top shape: 100 64 32 32 (6553600)
I1024 14:29:05.447109 21201 net.cpp:156] Memory required for data: 355123600
I1024 14:29:05.447119 21201 layer_factory.hpp:77] Creating layer conv_in3b_1x1
I1024 14:29:05.447125 21201 net.cpp:91] Creating Layer conv_in3b_1x1
I1024 14:29:05.447139 21201 net.cpp:425] conv_in3b_1x1 <- ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split_0
I1024 14:29:05.447142 21201 net.cpp:399] conv_in3b_1x1 -> conv_in3b_1x1
I1024 14:29:05.447335 21201 net.cpp:141] Setting up conv_in3b_1x1
I1024 14:29:05.447340 21201 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I1024 14:29:05.447341 21201 net.cpp:156] Memory required for data: 368230800
I1024 14:29:05.447345 21201 layer_factory.hpp:77] Creating layer bn_in3b_1x1
I1024 14:29:05.447371 21201 net.cpp:91] Creating Layer bn_in3b_1x1
I1024 14:29:05.447373 21201 net.cpp:425] bn_in3b_1x1 <- conv_in3b_1x1
I1024 14:29:05.447377 21201 net.cpp:399] bn_in3b_1x1 -> bn_in3b_1x1
I1024 14:29:05.447576 21201 net.cpp:141] Setting up bn_in3b_1x1
I1024 14:29:05.447582 21201 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I1024 14:29:05.447584 21201 net.cpp:156] Memory required for data: 381338000
I1024 14:29:05.447589 21201 layer_factory.hpp:77] Creating layer relu_in3b_1x1
I1024 14:29:05.447592 21201 net.cpp:91] Creating Layer relu_in3b_1x1
I1024 14:29:05.447594 21201 net.cpp:425] relu_in3b_1x1 <- bn_in3b_1x1
I1024 14:29:05.447597 21201 net.cpp:386] relu_in3b_1x1 -> bn_in3b_1x1 (in-place)
I1024 14:29:05.447600 21201 net.cpp:141] Setting up relu_in3b_1x1
I1024 14:29:05.447602 21201 net.cpp:148] Top shape: 100 32 32 32 (3276800)
I1024 14:29:05.447604 21201 net.cpp:156] Memory required for data: 394445200
I1024 14:29:05.447607 21201 layer_factory.hpp:77] Creating layer conv_in3b_3x3
I1024 14:29:05.447612 21201 net.cpp:91] Creating Layer conv_in3b_3x3
I1024 14:29:05.447613 21201 net.cpp:425] conv_in3b_3x3 <- ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split_1
I1024 14:29:05.447618 21201 net.cpp:399] conv_in3b_3x3 -> conv_in3b_3x3
I1024 14:29:05.447852 21201 net.cpp:141] Setting up conv_in3b_3x3
I1024 14:29:05.447857 21201 net.cpp:148] Top shape: 100 48 32 32 (4915200)
I1024 14:29:05.447860 21201 net.cpp:156] Memory required for data: 414106000
I1024 14:29:05.447863 21201 layer_factory.hpp:77] Creating layer bn_in3b_3x3
I1024 14:29:05.447866 21201 net.cpp:91] Creating Layer bn_in3b_3x3
I1024 14:29:05.447868 21201 net.cpp:425] bn_in3b_3x3 <- conv_in3b_3x3
I1024 14:29:05.447871 21201 net.cpp:399] bn_in3b_3x3 -> bn_in3b_3x3
I1024 14:29:05.448050 21201 net.cpp:141] Setting up bn_in3b_3x3
I1024 14:29:05.448055 21201 net.cpp:148] Top shape: 100 48 32 32 (4915200)
I1024 14:29:05.448072 21201 net.cpp:156] Memory required for data: 433766800
I1024 14:29:05.448077 21201 layer_factory.hpp:77] Creating layer relu_in3b_3x3
I1024 14:29:05.448081 21201 net.cpp:91] Creating Layer relu_in3b_3x3
I1024 14:29:05.448082 21201 net.cpp:425] relu_in3b_3x3 <- bn_in3b_3x3
I1024 14:29:05.448086 21201 net.cpp:386] relu_in3b_3x3 -> bn_in3b_3x3 (in-place)
I1024 14:29:05.448088 21201 net.cpp:141] Setting up relu_in3b_3x3
I1024 14:29:05.448093 21201 net.cpp:148] Top shape: 100 48 32 32 (4915200)
I1024 14:29:05.448096 21201 net.cpp:156] Memory required for data: 453427600
I1024 14:29:05.448097 21201 layer_factory.hpp:77] Creating layer ch_concat_in3b_chconcat
I1024 14:29:05.448099 21201 net.cpp:91] Creating Layer ch_concat_in3b_chconcat
I1024 14:29:05.448102 21201 net.cpp:425] ch_concat_in3b_chconcat <- bn_in3b_1x1
I1024 14:29:05.448107 21201 net.cpp:425] ch_concat_in3b_chconcat <- bn_in3b_3x3
I1024 14:29:05.448109 21201 net.cpp:399] ch_concat_in3b_chconcat -> ch_concat_in3b_chconcat
I1024 14:29:05.448127 21201 net.cpp:141] Setting up ch_concat_in3b_chconcat
I1024 14:29:05.448133 21201 net.cpp:148] Top shape: 100 80 32 32 (8192000)
I1024 14:29:05.448135 21201 net.cpp:156] Memory required for data: 486195600
I1024 14:29:05.448137 21201 layer_factory.hpp:77] Creating layer ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split
I1024 14:29:05.448140 21201 net.cpp:91] Creating Layer ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split
I1024 14:29:05.448155 21201 net.cpp:425] ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split <- ch_concat_in3b_chconcat
I1024 14:29:05.448159 21201 net.cpp:399] ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split -> ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split_0
I1024 14:29:05.448184 21201 net.cpp:399] ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split -> ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split_1
I1024 14:29:05.448207 21201 net.cpp:141] Setting up ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split
I1024 14:29:05.448213 21201 net.cpp:148] Top shape: 100 80 32 32 (8192000)
I1024 14:29:05.448216 21201 net.cpp:148] Top shape: 100 80 32 32 (8192000)
I1024 14:29:05.448218 21201 net.cpp:156] Memory required for data: 551731600
I1024 14:29:05.448220 21201 layer_factory.hpp:77] Creating layer conv_in3c_3x3
I1024 14:29:05.448225 21201 net.cpp:91] Creating Layer conv_in3c_3x3
I1024 14:29:05.448227 21201 net.cpp:425] conv_in3c_3x3 <- ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split_0
I1024 14:29:05.448230 21201 net.cpp:399] conv_in3c_3x3 -> conv_in3c_3x3
I1024 14:29:05.448506 21201 net.cpp:141] Setting up conv_in3c_3x3
I1024 14:29:05.448513 21201 net.cpp:148] Top shape: 100 80 16 16 (2048000)
I1024 14:29:05.448516 21201 net.cpp:156] Memory required for data: 559923600
I1024 14:29:05.448518 21201 layer_factory.hpp:77] Creating layer bn_in3c_3x3
I1024 14:29:05.448523 21201 net.cpp:91] Creating Layer bn_in3c_3x3
I1024 14:29:05.448525 21201 net.cpp:425] bn_in3c_3x3 <- conv_in3c_3x3
I1024 14:29:05.448529 21201 net.cpp:399] bn_in3c_3x3 -> bn_in3c_3x3
I1024 14:29:05.448675 21201 net.cpp:141] Setting up bn_in3c_3x3
I1024 14:29:05.448681 21201 net.cpp:148] Top shape: 100 80 16 16 (2048000)
I1024 14:29:05.448683 21201 net.cpp:156] Memory required for data: 568115600
I1024 14:29:05.448690 21201 layer_factory.hpp:77] Creating layer relu_in3c_3x3
I1024 14:29:05.448694 21201 net.cpp:91] Creating Layer relu_in3c_3x3
I1024 14:29:05.448696 21201 net.cpp:425] relu_in3c_3x3 <- bn_in3c_3x3
I1024 14:29:05.448699 21201 net.cpp:386] relu_in3c_3x3 -> bn_in3c_3x3 (in-place)
I1024 14:29:05.448702 21201 net.cpp:141] Setting up relu_in3c_3x3
I1024 14:29:05.448705 21201 net.cpp:148] Top shape: 100 80 16 16 (2048000)
I1024 14:29:05.448707 21201 net.cpp:156] Memory required for data: 576307600
I1024 14:29:05.448710 21201 layer_factory.hpp:77] Creating layer max_pool_in3c_pool
I1024 14:29:05.448715 21201 net.cpp:91] Creating Layer max_pool_in3c_pool
I1024 14:29:05.448719 21201 net.cpp:425] max_pool_in3c_pool <- ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split_1
I1024 14:29:05.448724 21201 net.cpp:399] max_pool_in3c_pool -> max_pool_in3c_pool
I1024 14:29:05.448750 21201 net.cpp:141] Setting up max_pool_in3c_pool
I1024 14:29:05.448755 21201 net.cpp:148] Top shape: 100 80 16 16 (2048000)
I1024 14:29:05.448756 21201 net.cpp:156] Memory required for data: 584499600
I1024 14:29:05.448758 21201 layer_factory.hpp:77] Creating layer ch_concat_in3c_chconcat
I1024 14:29:05.448761 21201 net.cpp:91] Creating Layer ch_concat_in3c_chconcat
I1024 14:29:05.448763 21201 net.cpp:425] ch_concat_in3c_chconcat <- bn_in3c_3x3
I1024 14:29:05.448766 21201 net.cpp:425] ch_concat_in3c_chconcat <- max_pool_in3c_pool
I1024 14:29:05.448770 21201 net.cpp:399] ch_concat_in3c_chconcat -> ch_concat_in3c_chconcat
I1024 14:29:05.448786 21201 net.cpp:141] Setting up ch_concat_in3c_chconcat
I1024 14:29:05.448791 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.448796 21201 net.cpp:156] Memory required for data: 600883600
I1024 14:29:05.448797 21201 layer_factory.hpp:77] Creating layer ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split
I1024 14:29:05.448813 21201 net.cpp:91] Creating Layer ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split
I1024 14:29:05.448817 21201 net.cpp:425] ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split <- ch_concat_in3c_chconcat
I1024 14:29:05.448819 21201 net.cpp:399] ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split -> ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split_0
I1024 14:29:05.448837 21201 net.cpp:399] ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split -> ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split_1
I1024 14:29:05.448860 21201 net.cpp:141] Setting up ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split
I1024 14:29:05.448873 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.448875 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.448877 21201 net.cpp:156] Memory required for data: 633651600
I1024 14:29:05.448879 21201 layer_factory.hpp:77] Creating layer conv_in4a_1x1
I1024 14:29:05.448884 21201 net.cpp:91] Creating Layer conv_in4a_1x1
I1024 14:29:05.448886 21201 net.cpp:425] conv_in4a_1x1 <- ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split_0
I1024 14:29:05.448889 21201 net.cpp:399] conv_in4a_1x1 -> conv_in4a_1x1
I1024 14:29:05.449053 21201 net.cpp:141] Setting up conv_in4a_1x1
I1024 14:29:05.449057 21201 net.cpp:148] Top shape: 100 112 16 16 (2867200)
I1024 14:29:05.449074 21201 net.cpp:156] Memory required for data: 645120400
I1024 14:29:05.449076 21201 layer_factory.hpp:77] Creating layer bn_in4a_1x1
I1024 14:29:05.449079 21201 net.cpp:91] Creating Layer bn_in4a_1x1
I1024 14:29:05.449082 21201 net.cpp:425] bn_in4a_1x1 <- conv_in4a_1x1
I1024 14:29:05.449086 21201 net.cpp:399] bn_in4a_1x1 -> bn_in4a_1x1
I1024 14:29:05.449240 21201 net.cpp:141] Setting up bn_in4a_1x1
I1024 14:29:05.449245 21201 net.cpp:148] Top shape: 100 112 16 16 (2867200)
I1024 14:29:05.449259 21201 net.cpp:156] Memory required for data: 656589200
I1024 14:29:05.449265 21201 layer_factory.hpp:77] Creating layer relu_in4a_1x1
I1024 14:29:05.449268 21201 net.cpp:91] Creating Layer relu_in4a_1x1
I1024 14:29:05.449271 21201 net.cpp:425] relu_in4a_1x1 <- bn_in4a_1x1
I1024 14:29:05.449275 21201 net.cpp:386] relu_in4a_1x1 -> bn_in4a_1x1 (in-place)
I1024 14:29:05.449280 21201 net.cpp:141] Setting up relu_in4a_1x1
I1024 14:29:05.449282 21201 net.cpp:148] Top shape: 100 112 16 16 (2867200)
I1024 14:29:05.449285 21201 net.cpp:156] Memory required for data: 668058000
I1024 14:29:05.449286 21201 layer_factory.hpp:77] Creating layer conv_in4a_3x3
I1024 14:29:05.449290 21201 net.cpp:91] Creating Layer conv_in4a_3x3
I1024 14:29:05.449295 21201 net.cpp:425] conv_in4a_3x3 <- ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split_1
I1024 14:29:05.449301 21201 net.cpp:399] conv_in4a_3x3 -> conv_in4a_3x3
I1024 14:29:05.449620 21201 net.cpp:141] Setting up conv_in4a_3x3
I1024 14:29:05.449626 21201 net.cpp:148] Top shape: 100 48 16 16 (1228800)
I1024 14:29:05.449630 21201 net.cpp:156] Memory required for data: 672973200
I1024 14:29:05.449635 21201 layer_factory.hpp:77] Creating layer bn_in4a_3x3
I1024 14:29:05.449640 21201 net.cpp:91] Creating Layer bn_in4a_3x3
I1024 14:29:05.449645 21201 net.cpp:425] bn_in4a_3x3 <- conv_in4a_3x3
I1024 14:29:05.449647 21201 net.cpp:399] bn_in4a_3x3 -> bn_in4a_3x3
I1024 14:29:05.449792 21201 net.cpp:141] Setting up bn_in4a_3x3
I1024 14:29:05.449797 21201 net.cpp:148] Top shape: 100 48 16 16 (1228800)
I1024 14:29:05.449800 21201 net.cpp:156] Memory required for data: 677888400
I1024 14:29:05.449810 21201 layer_factory.hpp:77] Creating layer relu_in4a_3x3
I1024 14:29:05.449817 21201 net.cpp:91] Creating Layer relu_in4a_3x3
I1024 14:29:05.449821 21201 net.cpp:425] relu_in4a_3x3 <- bn_in4a_3x3
I1024 14:29:05.449827 21201 net.cpp:386] relu_in4a_3x3 -> bn_in4a_3x3 (in-place)
I1024 14:29:05.449832 21201 net.cpp:141] Setting up relu_in4a_3x3
I1024 14:29:05.449837 21201 net.cpp:148] Top shape: 100 48 16 16 (1228800)
I1024 14:29:05.449841 21201 net.cpp:156] Memory required for data: 682803600
I1024 14:29:05.449846 21201 layer_factory.hpp:77] Creating layer ch_concat_in4a_chconcat
I1024 14:29:05.449851 21201 net.cpp:91] Creating Layer ch_concat_in4a_chconcat
I1024 14:29:05.449854 21201 net.cpp:425] ch_concat_in4a_chconcat <- bn_in4a_1x1
I1024 14:29:05.449858 21201 net.cpp:425] ch_concat_in4a_chconcat <- bn_in4a_3x3
I1024 14:29:05.449864 21201 net.cpp:399] ch_concat_in4a_chconcat -> ch_concat_in4a_chconcat
I1024 14:29:05.449882 21201 net.cpp:141] Setting up ch_concat_in4a_chconcat
I1024 14:29:05.449887 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.449892 21201 net.cpp:156] Memory required for data: 699187600
I1024 14:29:05.449894 21201 layer_factory.hpp:77] Creating layer ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split
I1024 14:29:05.449906 21201 net.cpp:91] Creating Layer ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split
I1024 14:29:05.449911 21201 net.cpp:425] ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split <- ch_concat_in4a_chconcat
I1024 14:29:05.449916 21201 net.cpp:399] ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split -> ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split_0
I1024 14:29:05.449924 21201 net.cpp:399] ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split -> ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split_1
I1024 14:29:05.449952 21201 net.cpp:141] Setting up ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split
I1024 14:29:05.449959 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.449961 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.449965 21201 net.cpp:156] Memory required for data: 731955600
I1024 14:29:05.449970 21201 layer_factory.hpp:77] Creating layer conv_in4b_1x1
I1024 14:29:05.449976 21201 net.cpp:91] Creating Layer conv_in4b_1x1
I1024 14:29:05.449981 21201 net.cpp:425] conv_in4b_1x1 <- ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split_0
I1024 14:29:05.449987 21201 net.cpp:399] conv_in4b_1x1 -> conv_in4b_1x1
I1024 14:29:05.450549 21201 net.cpp:141] Setting up conv_in4b_1x1
I1024 14:29:05.450557 21201 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I1024 14:29:05.450561 21201 net.cpp:156] Memory required for data: 741786000
I1024 14:29:05.450565 21201 layer_factory.hpp:77] Creating layer bn_in4b_1x1
I1024 14:29:05.450573 21201 net.cpp:91] Creating Layer bn_in4b_1x1
I1024 14:29:05.450577 21201 net.cpp:425] bn_in4b_1x1 <- conv_in4b_1x1
I1024 14:29:05.450583 21201 net.cpp:399] bn_in4b_1x1 -> bn_in4b_1x1
I1024 14:29:05.450731 21201 net.cpp:141] Setting up bn_in4b_1x1
I1024 14:29:05.450737 21201 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I1024 14:29:05.450738 21201 net.cpp:156] Memory required for data: 751616400
I1024 14:29:05.450745 21201 layer_factory.hpp:77] Creating layer relu_in4b_1x1
I1024 14:29:05.450752 21201 net.cpp:91] Creating Layer relu_in4b_1x1
I1024 14:29:05.450755 21201 net.cpp:425] relu_in4b_1x1 <- bn_in4b_1x1
I1024 14:29:05.450760 21201 net.cpp:386] relu_in4b_1x1 -> bn_in4b_1x1 (in-place)
I1024 14:29:05.450767 21201 net.cpp:141] Setting up relu_in4b_1x1
I1024 14:29:05.450772 21201 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I1024 14:29:05.450775 21201 net.cpp:156] Memory required for data: 761446800
I1024 14:29:05.450778 21201 layer_factory.hpp:77] Creating layer conv_in4b_3x3
I1024 14:29:05.450784 21201 net.cpp:91] Creating Layer conv_in4b_3x3
I1024 14:29:05.450788 21201 net.cpp:425] conv_in4b_3x3 <- ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split_1
I1024 14:29:05.450795 21201 net.cpp:399] conv_in4b_3x3 -> conv_in4b_3x3
I1024 14:29:05.451189 21201 net.cpp:141] Setting up conv_in4b_3x3
I1024 14:29:05.451195 21201 net.cpp:148] Top shape: 100 64 16 16 (1638400)
I1024 14:29:05.451196 21201 net.cpp:156] Memory required for data: 768000400
I1024 14:29:05.451201 21201 layer_factory.hpp:77] Creating layer bn_in4b_3x3
I1024 14:29:05.451206 21201 net.cpp:91] Creating Layer bn_in4b_3x3
I1024 14:29:05.451210 21201 net.cpp:425] bn_in4b_3x3 <- conv_in4b_3x3
I1024 14:29:05.451215 21201 net.cpp:399] bn_in4b_3x3 -> bn_in4b_3x3
I1024 14:29:05.451360 21201 net.cpp:141] Setting up bn_in4b_3x3
I1024 14:29:05.451365 21201 net.cpp:148] Top shape: 100 64 16 16 (1638400)
I1024 14:29:05.451369 21201 net.cpp:156] Memory required for data: 774554000
I1024 14:29:05.451375 21201 layer_factory.hpp:77] Creating layer relu_in4b_3x3
I1024 14:29:05.451380 21201 net.cpp:91] Creating Layer relu_in4b_3x3
I1024 14:29:05.451385 21201 net.cpp:425] relu_in4b_3x3 <- bn_in4b_3x3
I1024 14:29:05.451388 21201 net.cpp:386] relu_in4b_3x3 -> bn_in4b_3x3 (in-place)
I1024 14:29:05.451395 21201 net.cpp:141] Setting up relu_in4b_3x3
I1024 14:29:05.451400 21201 net.cpp:148] Top shape: 100 64 16 16 (1638400)
I1024 14:29:05.451403 21201 net.cpp:156] Memory required for data: 781107600
I1024 14:29:05.451414 21201 layer_factory.hpp:77] Creating layer ch_concat_in4b_chconcat
I1024 14:29:05.451421 21201 net.cpp:91] Creating Layer ch_concat_in4b_chconcat
I1024 14:29:05.451424 21201 net.cpp:425] ch_concat_in4b_chconcat <- bn_in4b_1x1
I1024 14:29:05.451428 21201 net.cpp:425] ch_concat_in4b_chconcat <- bn_in4b_3x3
I1024 14:29:05.451434 21201 net.cpp:399] ch_concat_in4b_chconcat -> ch_concat_in4b_chconcat
I1024 14:29:05.451452 21201 net.cpp:141] Setting up ch_concat_in4b_chconcat
I1024 14:29:05.451458 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.451460 21201 net.cpp:156] Memory required for data: 797491600
I1024 14:29:05.451462 21201 layer_factory.hpp:77] Creating layer ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split
I1024 14:29:05.451468 21201 net.cpp:91] Creating Layer ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split
I1024 14:29:05.451472 21201 net.cpp:425] ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split <- ch_concat_in4b_chconcat
I1024 14:29:05.451478 21201 net.cpp:399] ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split -> ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split_0
I1024 14:29:05.451484 21201 net.cpp:399] ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split -> ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split_1
I1024 14:29:05.451509 21201 net.cpp:141] Setting up ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split
I1024 14:29:05.451514 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.451517 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.451520 21201 net.cpp:156] Memory required for data: 830259600
I1024 14:29:05.451524 21201 layer_factory.hpp:77] Creating layer conv_in4c_1x1
I1024 14:29:05.451530 21201 net.cpp:91] Creating Layer conv_in4c_1x1
I1024 14:29:05.451534 21201 net.cpp:425] conv_in4c_1x1 <- ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split_0
I1024 14:29:05.451539 21201 net.cpp:399] conv_in4c_1x1 -> conv_in4c_1x1
I1024 14:29:05.451678 21201 net.cpp:141] Setting up conv_in4c_1x1
I1024 14:29:05.451684 21201 net.cpp:148] Top shape: 100 80 16 16 (2048000)
I1024 14:29:05.451686 21201 net.cpp:156] Memory required for data: 838451600
I1024 14:29:05.451690 21201 layer_factory.hpp:77] Creating layer bn_in4c_1x1
I1024 14:29:05.451695 21201 net.cpp:91] Creating Layer bn_in4c_1x1
I1024 14:29:05.451700 21201 net.cpp:425] bn_in4c_1x1 <- conv_in4c_1x1
I1024 14:29:05.451705 21201 net.cpp:399] bn_in4c_1x1 -> bn_in4c_1x1
I1024 14:29:05.451862 21201 net.cpp:141] Setting up bn_in4c_1x1
I1024 14:29:05.451869 21201 net.cpp:148] Top shape: 100 80 16 16 (2048000)
I1024 14:29:05.451871 21201 net.cpp:156] Memory required for data: 846643600
I1024 14:29:05.451887 21201 layer_factory.hpp:77] Creating layer relu_in4c_1x1
I1024 14:29:05.451894 21201 net.cpp:91] Creating Layer relu_in4c_1x1
I1024 14:29:05.451896 21201 net.cpp:425] relu_in4c_1x1 <- bn_in4c_1x1
I1024 14:29:05.451902 21201 net.cpp:386] relu_in4c_1x1 -> bn_in4c_1x1 (in-place)
I1024 14:29:05.451908 21201 net.cpp:141] Setting up relu_in4c_1x1
I1024 14:29:05.451913 21201 net.cpp:148] Top shape: 100 80 16 16 (2048000)
I1024 14:29:05.451917 21201 net.cpp:156] Memory required for data: 854835600
I1024 14:29:05.451920 21201 layer_factory.hpp:77] Creating layer conv_in4c_3x3
I1024 14:29:05.451927 21201 net.cpp:91] Creating Layer conv_in4c_3x3
I1024 14:29:05.451932 21201 net.cpp:425] conv_in4c_3x3 <- ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split_1
I1024 14:29:05.451936 21201 net.cpp:399] conv_in4c_3x3 -> conv_in4c_3x3
I1024 14:29:05.452411 21201 net.cpp:141] Setting up conv_in4c_3x3
I1024 14:29:05.452417 21201 net.cpp:148] Top shape: 100 80 16 16 (2048000)
I1024 14:29:05.452419 21201 net.cpp:156] Memory required for data: 863027600
I1024 14:29:05.452422 21201 layer_factory.hpp:77] Creating layer bn_in4c_3x3
I1024 14:29:05.452430 21201 net.cpp:91] Creating Layer bn_in4c_3x3
I1024 14:29:05.452435 21201 net.cpp:425] bn_in4c_3x3 <- conv_in4c_3x3
I1024 14:29:05.452440 21201 net.cpp:399] bn_in4c_3x3 -> bn_in4c_3x3
I1024 14:29:05.452618 21201 net.cpp:141] Setting up bn_in4c_3x3
I1024 14:29:05.452625 21201 net.cpp:148] Top shape: 100 80 16 16 (2048000)
I1024 14:29:05.452627 21201 net.cpp:156] Memory required for data: 871219600
I1024 14:29:05.452636 21201 layer_factory.hpp:77] Creating layer relu_in4c_3x3
I1024 14:29:05.452656 21201 net.cpp:91] Creating Layer relu_in4c_3x3
I1024 14:29:05.452661 21201 net.cpp:425] relu_in4c_3x3 <- bn_in4c_3x3
I1024 14:29:05.452664 21201 net.cpp:386] relu_in4c_3x3 -> bn_in4c_3x3 (in-place)
I1024 14:29:05.452670 21201 net.cpp:141] Setting up relu_in4c_3x3
I1024 14:29:05.452675 21201 net.cpp:148] Top shape: 100 80 16 16 (2048000)
I1024 14:29:05.452680 21201 net.cpp:156] Memory required for data: 879411600
I1024 14:29:05.452683 21201 layer_factory.hpp:77] Creating layer ch_concat_in4c_chconcat
I1024 14:29:05.452687 21201 net.cpp:91] Creating Layer ch_concat_in4c_chconcat
I1024 14:29:05.452692 21201 net.cpp:425] ch_concat_in4c_chconcat <- bn_in4c_1x1
I1024 14:29:05.452697 21201 net.cpp:425] ch_concat_in4c_chconcat <- bn_in4c_3x3
I1024 14:29:05.452703 21201 net.cpp:399] ch_concat_in4c_chconcat -> ch_concat_in4c_chconcat
I1024 14:29:05.452723 21201 net.cpp:141] Setting up ch_concat_in4c_chconcat
I1024 14:29:05.452728 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.452730 21201 net.cpp:156] Memory required for data: 895795600
I1024 14:29:05.452733 21201 layer_factory.hpp:77] Creating layer ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split
I1024 14:29:05.452739 21201 net.cpp:91] Creating Layer ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split
I1024 14:29:05.452742 21201 net.cpp:425] ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split <- ch_concat_in4c_chconcat
I1024 14:29:05.452749 21201 net.cpp:399] ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split -> ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split_0
I1024 14:29:05.452756 21201 net.cpp:399] ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split -> ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split_1
I1024 14:29:05.452783 21201 net.cpp:141] Setting up ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split
I1024 14:29:05.452788 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.452792 21201 net.cpp:148] Top shape: 100 160 16 16 (4096000)
I1024 14:29:05.452795 21201 net.cpp:156] Memory required for data: 928563600
I1024 14:29:05.452798 21201 layer_factory.hpp:77] Creating layer conv_in4d_1x1
I1024 14:29:05.452805 21201 net.cpp:91] Creating Layer conv_in4d_1x1
I1024 14:29:05.452810 21201 net.cpp:425] conv_in4d_1x1 <- ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split_0
I1024 14:29:05.452816 21201 net.cpp:399] conv_in4d_1x1 -> conv_in4d_1x1
I1024 14:29:05.452940 21201 net.cpp:141] Setting up conv_in4d_1x1
I1024 14:29:05.452946 21201 net.cpp:148] Top shape: 100 48 16 16 (1228800)
I1024 14:29:05.452947 21201 net.cpp:156] Memory required for data: 933478800
I1024 14:29:05.452952 21201 layer_factory.hpp:77] Creating layer bn_in4d_1x1
I1024 14:29:05.452958 21201 net.cpp:91] Creating Layer bn_in4d_1x1
I1024 14:29:05.452963 21201 net.cpp:425] bn_in4d_1x1 <- conv_in4d_1x1
I1024 14:29:05.452967 21201 net.cpp:399] bn_in4d_1x1 -> bn_in4d_1x1
I1024 14:29:05.453125 21201 net.cpp:141] Setting up bn_in4d_1x1
I1024 14:29:05.453130 21201 net.cpp:148] Top shape: 100 48 16 16 (1228800)
I1024 14:29:05.453133 21201 net.cpp:156] Memory required for data: 938394000
I1024 14:29:05.453140 21201 layer_factory.hpp:77] Creating layer relu_in4d_1x1
I1024 14:29:05.453146 21201 net.cpp:91] Creating Layer relu_in4d_1x1
I1024 14:29:05.453150 21201 net.cpp:425] relu_in4d_1x1 <- bn_in4d_1x1
I1024 14:29:05.453155 21201 net.cpp:386] relu_in4d_1x1 -> bn_in4d_1x1 (in-place)
I1024 14:29:05.453161 21201 net.cpp:141] Setting up relu_in4d_1x1
I1024 14:29:05.453166 21201 net.cpp:148] Top shape: 100 48 16 16 (1228800)
I1024 14:29:05.453171 21201 net.cpp:156] Memory required for data: 943309200
I1024 14:29:05.453173 21201 layer_factory.hpp:77] Creating layer conv_in4d_3x3
I1024 14:29:05.453181 21201 net.cpp:91] Creating Layer conv_in4d_3x3
I1024 14:29:05.453191 21201 net.cpp:425] conv_in4d_3x3 <- ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split_1
I1024 14:29:05.453198 21201 net.cpp:399] conv_in4d_3x3 -> conv_in4d_3x3
I1024 14:29:05.453748 21201 net.cpp:141] Setting up conv_in4d_3x3
I1024 14:29:05.453754 21201 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I1024 14:29:05.453758 21201 net.cpp:156] Memory required for data: 953139600
I1024 14:29:05.453761 21201 layer_factory.hpp:77] Creating layer bn_in4d_3x3
I1024 14:29:05.453768 21201 net.cpp:91] Creating Layer bn_in4d_3x3
I1024 14:29:05.453771 21201 net.cpp:425] bn_in4d_3x3 <- conv_in4d_3x3
I1024 14:29:05.453778 21201 net.cpp:399] bn_in4d_3x3 -> bn_in4d_3x3
I1024 14:29:05.453933 21201 net.cpp:141] Setting up bn_in4d_3x3
I1024 14:29:05.453938 21201 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I1024 14:29:05.453940 21201 net.cpp:156] Memory required for data: 962970000
I1024 14:29:05.453948 21201 layer_factory.hpp:77] Creating layer relu_in4d_3x3
I1024 14:29:05.453954 21201 net.cpp:91] Creating Layer relu_in4d_3x3
I1024 14:29:05.453958 21201 net.cpp:425] relu_in4d_3x3 <- bn_in4d_3x3
I1024 14:29:05.453963 21201 net.cpp:386] relu_in4d_3x3 -> bn_in4d_3x3 (in-place)
I1024 14:29:05.453969 21201 net.cpp:141] Setting up relu_in4d_3x3
I1024 14:29:05.453974 21201 net.cpp:148] Top shape: 100 96 16 16 (2457600)
I1024 14:29:05.453977 21201 net.cpp:156] Memory required for data: 972800400
I1024 14:29:05.453980 21201 layer_factory.hpp:77] Creating layer ch_concat_in4d_chconcat
I1024 14:29:05.453987 21201 net.cpp:91] Creating Layer ch_concat_in4d_chconcat
I1024 14:29:05.453991 21201 net.cpp:425] ch_concat_in4d_chconcat <- bn_in4d_1x1
I1024 14:29:05.453995 21201 net.cpp:425] ch_concat_in4d_chconcat <- bn_in4d_3x3
I1024 14:29:05.454000 21201 net.cpp:399] ch_concat_in4d_chconcat -> ch_concat_in4d_chconcat
I1024 14:29:05.454020 21201 net.cpp:141] Setting up ch_concat_in4d_chconcat
I1024 14:29:05.454025 21201 net.cpp:148] Top shape: 100 144 16 16 (3686400)
I1024 14:29:05.454027 21201 net.cpp:156] Memory required for data: 987546000
I1024 14:29:05.454030 21201 layer_factory.hpp:77] Creating layer ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split
I1024 14:29:05.454036 21201 net.cpp:91] Creating Layer ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split
I1024 14:29:05.454041 21201 net.cpp:425] ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split <- ch_concat_in4d_chconcat
I1024 14:29:05.454046 21201 net.cpp:399] ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split -> ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split_0
I1024 14:29:05.454053 21201 net.cpp:399] ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split -> ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split_1
I1024 14:29:05.454080 21201 net.cpp:141] Setting up ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split
I1024 14:29:05.454085 21201 net.cpp:148] Top shape: 100 144 16 16 (3686400)
I1024 14:29:05.454087 21201 net.cpp:148] Top shape: 100 144 16 16 (3686400)
I1024 14:29:05.454090 21201 net.cpp:156] Memory required for data: 1017037200
I1024 14:29:05.454094 21201 layer_factory.hpp:77] Creating layer conv_in4e_3x3
I1024 14:29:05.454103 21201 net.cpp:91] Creating Layer conv_in4e_3x3
I1024 14:29:05.454107 21201 net.cpp:425] conv_in4e_3x3 <- ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split_0
I1024 14:29:05.454113 21201 net.cpp:399] conv_in4e_3x3 -> conv_in4e_3x3
I1024 14:29:05.455045 21201 net.cpp:141] Setting up conv_in4e_3x3
I1024 14:29:05.455054 21201 net.cpp:148] Top shape: 100 96 8 8 (614400)
I1024 14:29:05.455056 21201 net.cpp:156] Memory required for data: 1019494800
I1024 14:29:05.455061 21201 layer_factory.hpp:77] Creating layer bn_in4e_3x3
I1024 14:29:05.455070 21201 net.cpp:91] Creating Layer bn_in4e_3x3
I1024 14:29:05.455073 21201 net.cpp:425] bn_in4e_3x3 <- conv_in4e_3x3
I1024 14:29:05.455078 21201 net.cpp:399] bn_in4e_3x3 -> bn_in4e_3x3
I1024 14:29:05.455245 21201 net.cpp:141] Setting up bn_in4e_3x3
I1024 14:29:05.455250 21201 net.cpp:148] Top shape: 100 96 8 8 (614400)
I1024 14:29:05.455252 21201 net.cpp:156] Memory required for data: 1021952400
I1024 14:29:05.455268 21201 layer_factory.hpp:77] Creating layer relu_in4e_3x3
I1024 14:29:05.455274 21201 net.cpp:91] Creating Layer relu_in4e_3x3
I1024 14:29:05.455279 21201 net.cpp:425] relu_in4e_3x3 <- bn_in4e_3x3
I1024 14:29:05.455284 21201 net.cpp:386] relu_in4e_3x3 -> bn_in4e_3x3 (in-place)
I1024 14:29:05.455291 21201 net.cpp:141] Setting up relu_in4e_3x3
I1024 14:29:05.455296 21201 net.cpp:148] Top shape: 100 96 8 8 (614400)
I1024 14:29:05.455301 21201 net.cpp:156] Memory required for data: 1024410000
I1024 14:29:05.455303 21201 layer_factory.hpp:77] Creating layer max_pool_in4e_pool
I1024 14:29:05.455308 21201 net.cpp:91] Creating Layer max_pool_in4e_pool
I1024 14:29:05.455314 21201 net.cpp:425] max_pool_in4e_pool <- ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split_1
I1024 14:29:05.455320 21201 net.cpp:399] max_pool_in4e_pool -> max_pool_in4e_pool
I1024 14:29:05.455349 21201 net.cpp:141] Setting up max_pool_in4e_pool
I1024 14:29:05.455354 21201 net.cpp:148] Top shape: 100 144 8 8 (921600)
I1024 14:29:05.455356 21201 net.cpp:156] Memory required for data: 1028096400
I1024 14:29:05.455359 21201 layer_factory.hpp:77] Creating layer ch_concat_in4e_chconcat
I1024 14:29:05.455365 21201 net.cpp:91] Creating Layer ch_concat_in4e_chconcat
I1024 14:29:05.455368 21201 net.cpp:425] ch_concat_in4e_chconcat <- bn_in4e_3x3
I1024 14:29:05.455373 21201 net.cpp:425] ch_concat_in4e_chconcat <- max_pool_in4e_pool
I1024 14:29:05.455380 21201 net.cpp:399] ch_concat_in4e_chconcat -> ch_concat_in4e_chconcat
I1024 14:29:05.455399 21201 net.cpp:141] Setting up ch_concat_in4e_chconcat
I1024 14:29:05.455404 21201 net.cpp:148] Top shape: 100 240 8 8 (1536000)
I1024 14:29:05.455407 21201 net.cpp:156] Memory required for data: 1034240400
I1024 14:29:05.455410 21201 layer_factory.hpp:77] Creating layer ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split
I1024 14:29:05.455422 21201 net.cpp:91] Creating Layer ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split
I1024 14:29:05.455426 21201 net.cpp:425] ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split <- ch_concat_in4e_chconcat
I1024 14:29:05.455431 21201 net.cpp:399] ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split -> ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split_0
I1024 14:29:05.455440 21201 net.cpp:399] ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split -> ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split_1
I1024 14:29:05.455466 21201 net.cpp:141] Setting up ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split
I1024 14:29:05.455471 21201 net.cpp:148] Top shape: 100 240 8 8 (1536000)
I1024 14:29:05.455474 21201 net.cpp:148] Top shape: 100 240 8 8 (1536000)
I1024 14:29:05.455478 21201 net.cpp:156] Memory required for data: 1046528400
I1024 14:29:05.455482 21201 layer_factory.hpp:77] Creating layer conv_in5a_1x1
I1024 14:29:05.455488 21201 net.cpp:91] Creating Layer conv_in5a_1x1
I1024 14:29:05.455492 21201 net.cpp:425] conv_in5a_1x1 <- ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split_0
I1024 14:29:05.455499 21201 net.cpp:399] conv_in5a_1x1 -> conv_in5a_1x1
I1024 14:29:05.455746 21201 net.cpp:141] Setting up conv_in5a_1x1
I1024 14:29:05.455754 21201 net.cpp:148] Top shape: 100 176 8 8 (1126400)
I1024 14:29:05.455755 21201 net.cpp:156] Memory required for data: 1051034000
I1024 14:29:05.455760 21201 layer_factory.hpp:77] Creating layer bn_in5a_1x1
I1024 14:29:05.455767 21201 net.cpp:91] Creating Layer bn_in5a_1x1
I1024 14:29:05.455771 21201 net.cpp:425] bn_in5a_1x1 <- conv_in5a_1x1
I1024 14:29:05.455776 21201 net.cpp:399] bn_in5a_1x1 -> bn_in5a_1x1
I1024 14:29:05.455935 21201 net.cpp:141] Setting up bn_in5a_1x1
I1024 14:29:05.455940 21201 net.cpp:148] Top shape: 100 176 8 8 (1126400)
I1024 14:29:05.455942 21201 net.cpp:156] Memory required for data: 1055539600
I1024 14:29:05.455950 21201 layer_factory.hpp:77] Creating layer relu_in5a_1x1
I1024 14:29:05.455955 21201 net.cpp:91] Creating Layer relu_in5a_1x1
I1024 14:29:05.455960 21201 net.cpp:425] relu_in5a_1x1 <- bn_in5a_1x1
I1024 14:29:05.455965 21201 net.cpp:386] relu_in5a_1x1 -> bn_in5a_1x1 (in-place)
I1024 14:29:05.455977 21201 net.cpp:141] Setting up relu_in5a_1x1
I1024 14:29:05.455983 21201 net.cpp:148] Top shape: 100 176 8 8 (1126400)
I1024 14:29:05.455987 21201 net.cpp:156] Memory required for data: 1060045200
I1024 14:29:05.455991 21201 layer_factory.hpp:77] Creating layer conv_in5a_3x3
I1024 14:29:05.455996 21201 net.cpp:91] Creating Layer conv_in5a_3x3
I1024 14:29:05.456001 21201 net.cpp:425] conv_in5a_3x3 <- ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split_1
I1024 14:29:05.456007 21201 net.cpp:399] conv_in5a_3x3 -> conv_in5a_3x3
I1024 14:29:05.457278 21201 net.cpp:141] Setting up conv_in5a_3x3
I1024 14:29:05.457285 21201 net.cpp:148] Top shape: 100 160 8 8 (1024000)
I1024 14:29:05.457289 21201 net.cpp:156] Memory required for data: 1064141200
I1024 14:29:05.457293 21201 layer_factory.hpp:77] Creating layer bn_in5a_3x3
I1024 14:29:05.457301 21201 net.cpp:91] Creating Layer bn_in5a_3x3
I1024 14:29:05.457305 21201 net.cpp:425] bn_in5a_3x3 <- conv_in5a_3x3
I1024 14:29:05.457312 21201 net.cpp:399] bn_in5a_3x3 -> bn_in5a_3x3
I1024 14:29:05.457473 21201 net.cpp:141] Setting up bn_in5a_3x3
I1024 14:29:05.457478 21201 net.cpp:148] Top shape: 100 160 8 8 (1024000)
I1024 14:29:05.457479 21201 net.cpp:156] Memory required for data: 1068237200
I1024 14:29:05.457487 21201 layer_factory.hpp:77] Creating layer relu_in5a_3x3
I1024 14:29:05.457494 21201 net.cpp:91] Creating Layer relu_in5a_3x3
I1024 14:29:05.457499 21201 net.cpp:425] relu_in5a_3x3 <- bn_in5a_3x3
I1024 14:29:05.457504 21201 net.cpp:386] relu_in5a_3x3 -> bn_in5a_3x3 (in-place)
I1024 14:29:05.457509 21201 net.cpp:141] Setting up relu_in5a_3x3
I1024 14:29:05.457515 21201 net.cpp:148] Top shape: 100 160 8 8 (1024000)
I1024 14:29:05.457518 21201 net.cpp:156] Memory required for data: 1072333200
I1024 14:29:05.457521 21201 layer_factory.hpp:77] Creating layer ch_concat_in5a_chconcat
I1024 14:29:05.457528 21201 net.cpp:91] Creating Layer ch_concat_in5a_chconcat
I1024 14:29:05.457533 21201 net.cpp:425] ch_concat_in5a_chconcat <- bn_in5a_1x1
I1024 14:29:05.457536 21201 net.cpp:425] ch_concat_in5a_chconcat <- bn_in5a_3x3
I1024 14:29:05.457542 21201 net.cpp:399] ch_concat_in5a_chconcat -> ch_concat_in5a_chconcat
I1024 14:29:05.457568 21201 net.cpp:141] Setting up ch_concat_in5a_chconcat
I1024 14:29:05.457573 21201 net.cpp:148] Top shape: 100 336 8 8 (2150400)
I1024 14:29:05.457576 21201 net.cpp:156] Memory required for data: 1080934800
I1024 14:29:05.457578 21201 layer_factory.hpp:77] Creating layer ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split
I1024 14:29:05.457587 21201 net.cpp:91] Creating Layer ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split
I1024 14:29:05.457590 21201 net.cpp:425] ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split <- ch_concat_in5a_chconcat
I1024 14:29:05.457595 21201 net.cpp:399] ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split -> ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split_0
I1024 14:29:05.457602 21201 net.cpp:399] ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split -> ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split_1
I1024 14:29:05.457629 21201 net.cpp:141] Setting up ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split
I1024 14:29:05.457634 21201 net.cpp:148] Top shape: 100 336 8 8 (2150400)
I1024 14:29:05.457638 21201 net.cpp:148] Top shape: 100 336 8 8 (2150400)
I1024 14:29:05.457641 21201 net.cpp:156] Memory required for data: 1098138000
I1024 14:29:05.457646 21201 layer_factory.hpp:77] Creating layer conv_in5b_1x1
I1024 14:29:05.457653 21201 net.cpp:91] Creating Layer conv_in5b_1x1
I1024 14:29:05.457656 21201 net.cpp:425] conv_in5b_1x1 <- ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split_0
I1024 14:29:05.457662 21201 net.cpp:399] conv_in5b_1x1 -> conv_in5b_1x1
I1024 14:29:05.457959 21201 net.cpp:141] Setting up conv_in5b_1x1
I1024 14:29:05.457964 21201 net.cpp:148] Top shape: 100 176 8 8 (1126400)
I1024 14:29:05.457967 21201 net.cpp:156] Memory required for data: 1102643600
I1024 14:29:05.457970 21201 layer_factory.hpp:77] Creating layer bn_in5b_1x1
I1024 14:29:05.457984 21201 net.cpp:91] Creating Layer bn_in5b_1x1
I1024 14:29:05.457988 21201 net.cpp:425] bn_in5b_1x1 <- conv_in5b_1x1
I1024 14:29:05.457993 21201 net.cpp:399] bn_in5b_1x1 -> bn_in5b_1x1
I1024 14:29:05.458151 21201 net.cpp:141] Setting up bn_in5b_1x1
I1024 14:29:05.458158 21201 net.cpp:148] Top shape: 100 176 8 8 (1126400)
I1024 14:29:05.458159 21201 net.cpp:156] Memory required for data: 1107149200
I1024 14:29:05.458165 21201 layer_factory.hpp:77] Creating layer relu_in5b_1x1
I1024 14:29:05.458173 21201 net.cpp:91] Creating Layer relu_in5b_1x1
I1024 14:29:05.458178 21201 net.cpp:425] relu_in5b_1x1 <- bn_in5b_1x1
I1024 14:29:05.458181 21201 net.cpp:386] relu_in5b_1x1 -> bn_in5b_1x1 (in-place)
I1024 14:29:05.458187 21201 net.cpp:141] Setting up relu_in5b_1x1
I1024 14:29:05.458192 21201 net.cpp:148] Top shape: 100 176 8 8 (1126400)
I1024 14:29:05.458196 21201 net.cpp:156] Memory required for data: 1111654800
I1024 14:29:05.458199 21201 layer_factory.hpp:77] Creating layer conv_in5b_3x3
I1024 14:29:05.458207 21201 net.cpp:91] Creating Layer conv_in5b_3x3
I1024 14:29:05.458211 21201 net.cpp:425] conv_in5b_3x3 <- ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split_1
I1024 14:29:05.458218 21201 net.cpp:399] conv_in5b_3x3 -> conv_in5b_3x3
I1024 14:29:05.460285 21201 net.cpp:141] Setting up conv_in5b_3x3
I1024 14:29:05.460294 21201 net.cpp:148] Top shape: 100 160 8 8 (1024000)
I1024 14:29:05.460295 21201 net.cpp:156] Memory required for data: 1115750800
I1024 14:29:05.460301 21201 layer_factory.hpp:77] Creating layer bn_in5b_3x3
I1024 14:29:05.460309 21201 net.cpp:91] Creating Layer bn_in5b_3x3
I1024 14:29:05.460312 21201 net.cpp:425] bn_in5b_3x3 <- conv_in5b_3x3
I1024 14:29:05.460319 21201 net.cpp:399] bn_in5b_3x3 -> bn_in5b_3x3
I1024 14:29:05.460484 21201 net.cpp:141] Setting up bn_in5b_3x3
I1024 14:29:05.460490 21201 net.cpp:148] Top shape: 100 160 8 8 (1024000)
I1024 14:29:05.460492 21201 net.cpp:156] Memory required for data: 1119846800
I1024 14:29:05.460500 21201 layer_factory.hpp:77] Creating layer relu_in5b_3x3
I1024 14:29:05.460505 21201 net.cpp:91] Creating Layer relu_in5b_3x3
I1024 14:29:05.460510 21201 net.cpp:425] relu_in5b_3x3 <- bn_in5b_3x3
I1024 14:29:05.460515 21201 net.cpp:386] relu_in5b_3x3 -> bn_in5b_3x3 (in-place)
I1024 14:29:05.460521 21201 net.cpp:141] Setting up relu_in5b_3x3
I1024 14:29:05.460527 21201 net.cpp:148] Top shape: 100 160 8 8 (1024000)
I1024 14:29:05.460530 21201 net.cpp:156] Memory required for data: 1123942800
I1024 14:29:05.460535 21201 layer_factory.hpp:77] Creating layer ch_concat_in5b_chconcat
I1024 14:29:05.460538 21201 net.cpp:91] Creating Layer ch_concat_in5b_chconcat
I1024 14:29:05.460542 21201 net.cpp:425] ch_concat_in5b_chconcat <- bn_in5b_1x1
I1024 14:29:05.460546 21201 net.cpp:425] ch_concat_in5b_chconcat <- bn_in5b_3x3
I1024 14:29:05.460552 21201 net.cpp:399] ch_concat_in5b_chconcat -> ch_concat_in5b_chconcat
I1024 14:29:05.460572 21201 net.cpp:141] Setting up ch_concat_in5b_chconcat
I1024 14:29:05.460577 21201 net.cpp:148] Top shape: 100 336 8 8 (2150400)
I1024 14:29:05.460580 21201 net.cpp:156] Memory required for data: 1132544400
I1024 14:29:05.460583 21201 layer_factory.hpp:77] Creating layer global_pool
I1024 14:29:05.460588 21201 net.cpp:91] Creating Layer global_pool
I1024 14:29:05.460597 21201 net.cpp:425] global_pool <- ch_concat_in5b_chconcat
I1024 14:29:05.460602 21201 net.cpp:399] global_pool -> global_pool
I1024 14:29:05.460623 21201 net.cpp:141] Setting up global_pool
I1024 14:29:05.460628 21201 net.cpp:148] Top shape: 100 336 2 2 (134400)
I1024 14:29:05.460630 21201 net.cpp:156] Memory required for data: 1133082000
I1024 14:29:05.460633 21201 layer_factory.hpp:77] Creating layer fc1
I1024 14:29:05.460640 21201 net.cpp:91] Creating Layer fc1
I1024 14:29:05.460644 21201 net.cpp:425] fc1 <- global_pool
I1024 14:29:05.460649 21201 net.cpp:399] fc1 -> fc1
I1024 14:29:05.460759 21201 net.cpp:141] Setting up fc1
I1024 14:29:05.460764 21201 net.cpp:148] Top shape: 100 10 (1000)
I1024 14:29:05.460767 21201 net.cpp:156] Memory required for data: 1133086000
I1024 14:29:05.460779 21201 layer_factory.hpp:77] Creating layer loss
I1024 14:29:05.460786 21201 net.cpp:91] Creating Layer loss
I1024 14:29:05.460790 21201 net.cpp:425] loss <- fc1
I1024 14:29:05.460794 21201 net.cpp:425] loss <- label
I1024 14:29:05.460803 21201 net.cpp:399] loss -> loss
I1024 14:29:05.460813 21201 layer_factory.hpp:77] Creating layer loss
I1024 14:29:05.460870 21201 net.cpp:141] Setting up loss
I1024 14:29:05.460875 21201 net.cpp:148] Top shape: (1)
I1024 14:29:05.460877 21201 net.cpp:151]     with loss weight 1
I1024 14:29:05.460892 21201 net.cpp:156] Memory required for data: 1133086004
I1024 14:29:05.460896 21201 net.cpp:217] loss needs backward computation.
I1024 14:29:05.460902 21201 net.cpp:217] fc1 needs backward computation.
I1024 14:29:05.460907 21201 net.cpp:217] global_pool needs backward computation.
I1024 14:29:05.460911 21201 net.cpp:217] ch_concat_in5b_chconcat needs backward computation.
I1024 14:29:05.460916 21201 net.cpp:217] relu_in5b_3x3 needs backward computation.
I1024 14:29:05.460918 21201 net.cpp:217] bn_in5b_3x3 needs backward computation.
I1024 14:29:05.460923 21201 net.cpp:217] conv_in5b_3x3 needs backward computation.
I1024 14:29:05.460927 21201 net.cpp:217] relu_in5b_1x1 needs backward computation.
I1024 14:29:05.460930 21201 net.cpp:217] bn_in5b_1x1 needs backward computation.
I1024 14:29:05.460933 21201 net.cpp:217] conv_in5b_1x1 needs backward computation.
I1024 14:29:05.460937 21201 net.cpp:217] ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split needs backward computation.
I1024 14:29:05.460942 21201 net.cpp:217] ch_concat_in5a_chconcat needs backward computation.
I1024 14:29:05.460945 21201 net.cpp:217] relu_in5a_3x3 needs backward computation.
I1024 14:29:05.460948 21201 net.cpp:217] bn_in5a_3x3 needs backward computation.
I1024 14:29:05.460952 21201 net.cpp:217] conv_in5a_3x3 needs backward computation.
I1024 14:29:05.460955 21201 net.cpp:217] relu_in5a_1x1 needs backward computation.
I1024 14:29:05.460959 21201 net.cpp:217] bn_in5a_1x1 needs backward computation.
I1024 14:29:05.460963 21201 net.cpp:217] conv_in5a_1x1 needs backward computation.
I1024 14:29:05.460966 21201 net.cpp:217] ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split needs backward computation.
I1024 14:29:05.460969 21201 net.cpp:217] ch_concat_in4e_chconcat needs backward computation.
I1024 14:29:05.460974 21201 net.cpp:217] max_pool_in4e_pool needs backward computation.
I1024 14:29:05.460978 21201 net.cpp:217] relu_in4e_3x3 needs backward computation.
I1024 14:29:05.460981 21201 net.cpp:217] bn_in4e_3x3 needs backward computation.
I1024 14:29:05.460984 21201 net.cpp:217] conv_in4e_3x3 needs backward computation.
I1024 14:29:05.460988 21201 net.cpp:217] ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split needs backward computation.
I1024 14:29:05.460991 21201 net.cpp:217] ch_concat_in4d_chconcat needs backward computation.
I1024 14:29:05.460995 21201 net.cpp:217] relu_in4d_3x3 needs backward computation.
I1024 14:29:05.460999 21201 net.cpp:217] bn_in4d_3x3 needs backward computation.
I1024 14:29:05.461002 21201 net.cpp:217] conv_in4d_3x3 needs backward computation.
I1024 14:29:05.461006 21201 net.cpp:217] relu_in4d_1x1 needs backward computation.
I1024 14:29:05.461010 21201 net.cpp:217] bn_in4d_1x1 needs backward computation.
I1024 14:29:05.461014 21201 net.cpp:217] conv_in4d_1x1 needs backward computation.
I1024 14:29:05.461017 21201 net.cpp:217] ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split needs backward computation.
I1024 14:29:05.461021 21201 net.cpp:217] ch_concat_in4c_chconcat needs backward computation.
I1024 14:29:05.461025 21201 net.cpp:217] relu_in4c_3x3 needs backward computation.
I1024 14:29:05.461028 21201 net.cpp:217] bn_in4c_3x3 needs backward computation.
I1024 14:29:05.461032 21201 net.cpp:217] conv_in4c_3x3 needs backward computation.
I1024 14:29:05.461035 21201 net.cpp:217] relu_in4c_1x1 needs backward computation.
I1024 14:29:05.461040 21201 net.cpp:217] bn_in4c_1x1 needs backward computation.
I1024 14:29:05.461043 21201 net.cpp:217] conv_in4c_1x1 needs backward computation.
I1024 14:29:05.461053 21201 net.cpp:217] ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split needs backward computation.
I1024 14:29:05.461058 21201 net.cpp:217] ch_concat_in4b_chconcat needs backward computation.
I1024 14:29:05.461063 21201 net.cpp:217] relu_in4b_3x3 needs backward computation.
I1024 14:29:05.461066 21201 net.cpp:217] bn_in4b_3x3 needs backward computation.
I1024 14:29:05.461069 21201 net.cpp:217] conv_in4b_3x3 needs backward computation.
I1024 14:29:05.461074 21201 net.cpp:217] relu_in4b_1x1 needs backward computation.
I1024 14:29:05.461079 21201 net.cpp:217] bn_in4b_1x1 needs backward computation.
I1024 14:29:05.461082 21201 net.cpp:217] conv_in4b_1x1 needs backward computation.
I1024 14:29:05.461086 21201 net.cpp:217] ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split needs backward computation.
I1024 14:29:05.461091 21201 net.cpp:217] ch_concat_in4a_chconcat needs backward computation.
I1024 14:29:05.461094 21201 net.cpp:217] relu_in4a_3x3 needs backward computation.
I1024 14:29:05.461097 21201 net.cpp:217] bn_in4a_3x3 needs backward computation.
I1024 14:29:05.461100 21201 net.cpp:217] conv_in4a_3x3 needs backward computation.
I1024 14:29:05.461103 21201 net.cpp:217] relu_in4a_1x1 needs backward computation.
I1024 14:29:05.461107 21201 net.cpp:217] bn_in4a_1x1 needs backward computation.
I1024 14:29:05.461112 21201 net.cpp:217] conv_in4a_1x1 needs backward computation.
I1024 14:29:05.461115 21201 net.cpp:217] ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split needs backward computation.
I1024 14:29:05.461118 21201 net.cpp:217] ch_concat_in3c_chconcat needs backward computation.
I1024 14:29:05.461123 21201 net.cpp:217] max_pool_in3c_pool needs backward computation.
I1024 14:29:05.461127 21201 net.cpp:217] relu_in3c_3x3 needs backward computation.
I1024 14:29:05.461130 21201 net.cpp:217] bn_in3c_3x3 needs backward computation.
I1024 14:29:05.461134 21201 net.cpp:217] conv_in3c_3x3 needs backward computation.
I1024 14:29:05.461138 21201 net.cpp:217] ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split needs backward computation.
I1024 14:29:05.461148 21201 net.cpp:217] ch_concat_in3b_chconcat needs backward computation.
I1024 14:29:05.461151 21201 net.cpp:217] relu_in3b_3x3 needs backward computation.
I1024 14:29:05.461155 21201 net.cpp:217] bn_in3b_3x3 needs backward computation.
I1024 14:29:05.461160 21201 net.cpp:217] conv_in3b_3x3 needs backward computation.
I1024 14:29:05.461163 21201 net.cpp:217] relu_in3b_1x1 needs backward computation.
I1024 14:29:05.461167 21201 net.cpp:217] bn_in3b_1x1 needs backward computation.
I1024 14:29:05.461170 21201 net.cpp:217] conv_in3b_1x1 needs backward computation.
I1024 14:29:05.461175 21201 net.cpp:217] ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split needs backward computation.
I1024 14:29:05.461179 21201 net.cpp:217] ch_concat_in3a_chconcat needs backward computation.
I1024 14:29:05.461182 21201 net.cpp:217] relu_in3a_3x3 needs backward computation.
I1024 14:29:05.461185 21201 net.cpp:217] bn_in3a_3x3 needs backward computation.
I1024 14:29:05.461190 21201 net.cpp:217] conv_in3a_3x3 needs backward computation.
I1024 14:29:05.461194 21201 net.cpp:217] relu_in3a_1x1 needs backward computation.
I1024 14:29:05.461197 21201 net.cpp:217] bn_in3a_1x1 needs backward computation.
I1024 14:29:05.461200 21201 net.cpp:217] conv_in3a_1x1 needs backward computation.
I1024 14:29:05.461205 21201 net.cpp:217] bn_conv1_relu_conv1_0_split needs backward computation.
I1024 14:29:05.461208 21201 net.cpp:217] relu_conv1 needs backward computation.
I1024 14:29:05.461212 21201 net.cpp:217] bn_conv1 needs backward computation.
I1024 14:29:05.461215 21201 net.cpp:217] conv_conv1 needs backward computation.
I1024 14:29:05.461220 21201 net.cpp:219] cifar does not need backward computation.
I1024 14:29:05.461225 21201 net.cpp:261] This network produces output loss
I1024 14:29:05.461264 21201 net.cpp:274] Network initialization done.
I1024 14:29:05.461634 21201 solver.cpp:181] Creating test net (#0) specified by net file: examples/cifar10/1parts/inception_train_val.prototxt.caffe
I1024 14:29:05.461684 21201 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1024 14:29:05.461707 21201 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer loss
I1024 14:29:05.461915 21201 net.cpp:49] Initializing net from parameters: 
name: "CIFAR10_quick"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/1parts/mean.binaryproto.0"
  }
  data_param {
    source: "examples/cifar10/1parts/cifar10_test_lmdb.0"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv_conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv_conv1"
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv_conv1"
  top: "bn_conv1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_conv1"
  type: "ReLU"
  bottom: "bn_conv1"
  top: "bn_conv1"
}
layer {
  name: "conv_in3a_1x1"
  type: "Convolution"
  bottom: "bn_conv1"
  top: "conv_in3a_1x1"
  convolution_param {
    num_output: 32
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in3a_1x1"
  type: "BatchNorm"
  bottom: "conv_in3a_1x1"
  top: "bn_in3a_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in3a_1x1"
  type: "ReLU"
  bottom: "bn_in3a_1x1"
  top: "bn_in3a_1x1"
}
layer {
  name: "conv_in3a_3x3"
  type: "Convolution"
  bottom: "bn_conv1"
  top: "conv_in3a_3x3"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in3a_3x3"
  type: "BatchNorm"
  bottom: "conv_in3a_3x3"
  top: "bn_in3a_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in3a_3x3"
  type: "ReLU"
  bottom: "bn_in3a_3x3"
  top: "bn_in3a_3x3"
}
layer {
  name: "ch_concat_in3a_chconcat"
  type: "Concat"
  bottom: "bn_in3a_1x1"
  bottom: "bn_in3a_3x3"
  top: "ch_concat_in3a_chconcat"
}
layer {
  name: "conv_in3b_1x1"
  type: "Convolution"
  bottom: "ch_concat_in3a_chconcat"
  top: "conv_in3b_1x1"
  convolution_param {
    num_output: 32
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in3b_1x1"
  type: "BatchNorm"
  bottom: "conv_in3b_1x1"
  top: "bn_in3b_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in3b_1x1"
  type: "ReLU"
  bottom: "bn_in3b_1x1"
  top: "bn_in3b_1x1"
}
layer {
  name: "conv_in3b_3x3"
  type: "Convolution"
  bottom: "ch_concat_in3a_chconcat"
  top: "conv_in3b_3x3"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in3b_3x3"
  type: "BatchNorm"
  bottom: "conv_in3b_3x3"
  top: "bn_in3b_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in3b_3x3"
  type: "ReLU"
  bottom: "bn_in3b_3x3"
  top: "bn_in3b_3x3"
}
layer {
  name: "ch_concat_in3b_chconcat"
  type: "Concat"
  bottom: "bn_in3b_1x1"
  bottom: "bn_in3b_3x3"
  top: "ch_concat_in3b_chconcat"
}
layer {
  name: "conv_in3c_3x3"
  type: "Convolution"
  bottom: "ch_concat_in3b_chconcat"
  top: "conv_in3c_3x3"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in3c_3x3"
  type: "BatchNorm"
  bottom: "conv_in3c_3x3"
  top: "bn_in3c_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in3c_3x3"
  type: "ReLU"
  bottom: "bn_in3c_3x3"
  top: "bn_in3c_3x3"
}
layer {
  name: "max_pool_in3c_pool"
  type: "Pooling"
  bottom: "ch_concat_in3b_chconcat"
  top: "max_pool_in3c_pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ch_concat_in3c_chconcat"
  type: "Concat"
  bottom: "bn_in3c_3x3"
  bottom: "max_pool_in3c_pool"
  top: "ch_concat_in3c_chconcat"
}
layer {
  name: "conv_in4a_1x1"
  type: "Convolution"
  bottom: "ch_concat_in3c_chconcat"
  top: "conv_in4a_1x1"
  convolution_param {
    num_output: 112
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4a_1x1"
  type: "BatchNorm"
  bottom: "conv_in4a_1x1"
  top: "bn_in4a_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4a_1x1"
  type: "ReLU"
  bottom: "bn_in4a_1x1"
  top: "bn_in4a_1x1"
}
layer {
  name: "conv_in4a_3x3"
  type: "Convolution"
  bottom: "ch_concat_in3c_chconcat"
  top: "conv_in4a_3x3"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4a_3x3"
  type: "BatchNorm"
  bottom: "conv_in4a_3x3"
  top: "bn_in4a_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4a_3x3"
  type: "ReLU"
  bottom: "bn_in4a_3x3"
  top: "bn_in4a_3x3"
}
layer {
  name: "ch_concat_in4a_chconcat"
  type: "Concat"
  bottom: "bn_in4a_1x1"
  bottom: "bn_in4a_3x3"
  top: "ch_concat_in4a_chconcat"
}
layer {
  name: "conv_in4b_1x1"
  type: "Convolution"
  bottom: "ch_concat_in4a_chconcat"
  top: "conv_in4b_1x1"
  convolution_param {
    num_output: 96
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4b_1x1"
  type: "BatchNorm"
  bottom: "conv_in4b_1x1"
  top: "bn_in4b_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4b_1x1"
  type: "ReLU"
  bottom: "bn_in4b_1x1"
  top: "bn_in4b_1x1"
}
layer {
  name: "conv_in4b_3x3"
  type: "Convolution"
  bottom: "ch_concat_in4a_chconcat"
  top: "conv_in4b_3x3"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4b_3x3"
  type: "BatchNorm"
  bottom: "conv_in4b_3x3"
  top: "bn_in4b_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4b_3x3"
  type: "ReLU"
  bottom: "bn_in4b_3x3"
  top: "bn_in4b_3x3"
}
layer {
  name: "ch_concat_in4b_chconcat"
  type: "Concat"
  bottom: "bn_in4b_1x1"
  bottom: "bn_in4b_3x3"
  top: "ch_concat_in4b_chconcat"
}
layer {
  name: "conv_in4c_1x1"
  type: "Convolution"
  bottom: "ch_concat_in4b_chconcat"
  top: "conv_in4c_1x1"
  convolution_param {
    num_output: 80
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4c_1x1"
  type: "BatchNorm"
  bottom: "conv_in4c_1x1"
  top: "bn_in4c_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4c_1x1"
  type: "ReLU"
  bottom: "bn_in4c_1x1"
  top: "bn_in4c_1x1"
}
layer {
  name: "conv_in4c_3x3"
  type: "Convolution"
  bottom: "ch_concat_in4b_chconcat"
  top: "conv_in4c_3x3"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4c_3x3"
  type: "BatchNorm"
  bottom: "conv_in4c_3x3"
  top: "bn_in4c_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4c_3x3"
  type: "ReLU"
  bottom: "bn_in4c_3x3"
  top: "bn_in4c_3x3"
}
layer {
  name: "ch_concat_in4c_chconcat"
  type: "Concat"
  bottom: "bn_in4c_1x1"
  bottom: "bn_in4c_3x3"
  top: "ch_concat_in4c_chconcat"
}
layer {
  name: "conv_in4d_1x1"
  type: "Convolution"
  bottom: "ch_concat_in4c_chconcat"
  top: "conv_in4d_1x1"
  convolution_param {
    num_output: 48
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4d_1x1"
  type: "BatchNorm"
  bottom: "conv_in4d_1x1"
  top: "bn_in4d_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4d_1x1"
  type: "ReLU"
  bottom: "bn_in4d_1x1"
  top: "bn_in4d_1x1"
}
layer {
  name: "conv_in4d_3x3"
  type: "Convolution"
  bottom: "ch_concat_in4c_chconcat"
  top: "conv_in4d_3x3"
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4d_3x3"
  type: "BatchNorm"
  bottom: "conv_in4d_3x3"
  top: "bn_in4d_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4d_3x3"
  type: "ReLU"
  bottom: "bn_in4d_3x3"
  top: "bn_in4d_3x3"
}
layer {
  name: "ch_concat_in4d_chconcat"
  type: "Concat"
  bottom: "bn_in4d_1x1"
  bottom: "bn_in4d_3x3"
  top: "ch_concat_in4d_chconcat"
}
layer {
  name: "conv_in4e_3x3"
  type: "Convolution"
  bottom: "ch_concat_in4d_chconcat"
  top: "conv_in4e_3x3"
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in4e_3x3"
  type: "BatchNorm"
  bottom: "conv_in4e_3x3"
  top: "bn_in4e_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in4e_3x3"
  type: "ReLU"
  bottom: "bn_in4e_3x3"
  top: "bn_in4e_3x3"
}
layer {
  name: "max_pool_in4e_pool"
  type: "Pooling"
  bottom: "ch_concat_in4d_chconcat"
  top: "max_pool_in4e_pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "ch_concat_in4e_chconcat"
  type: "Concat"
  bottom: "bn_in4e_3x3"
  bottom: "max_pool_in4e_pool"
  top: "ch_concat_in4e_chconcat"
}
layer {
  name: "conv_in5a_1x1"
  type: "Convolution"
  bottom: "ch_concat_in4e_chconcat"
  top: "conv_in5a_1x1"
  convolution_param {
    num_output: 176
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in5a_1x1"
  type: "BatchNorm"
  bottom: "conv_in5a_1x1"
  top: "bn_in5a_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in5a_1x1"
  type: "ReLU"
  bottom: "bn_in5a_1x1"
  top: "bn_in5a_1x1"
}
layer {
  name: "conv_in5a_3x3"
  type: "Convolution"
  bottom: "ch_concat_in4e_chconcat"
  top: "conv_in5a_3x3"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in5a_3x3"
  type: "BatchNorm"
  bottom: "conv_in5a_3x3"
  top: "bn_in5a_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in5a_3x3"
  type: "ReLU"
  bottom: "bn_in5a_3x3"
  top: "bn_in5a_3x3"
}
layer {
  name: "ch_concat_in5a_chconcat"
  type: "Concat"
  bottom: "bn_in5a_1x1"
  bottom: "bn_in5a_3x3"
  top: "ch_concat_in5a_chconcat"
}
layer {
  name: "conv_in5b_1x1"
  type: "Convolution"
  bottom: "ch_concat_in5a_chconcat"
  top: "conv_in5b_1x1"
  convolution_param {
    num_output: 176
    bias_term: false
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in5b_1x1"
  type: "BatchNorm"
  bottom: "conv_in5b_1x1"
  top: "bn_in5b_1x1"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in5b_1x1"
  type: "ReLU"
  bottom: "bn_in5b_1x1"
  top: "bn_in5b_1x1"
}
layer {
  name: "conv_in5b_3x3"
  type: "Convolution"
  bottom: "ch_concat_in5a_chconcat"
  top: "conv_in5b_3x3"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn_in5b_3x3"
  type: "BatchNorm"
  bottom: "conv_in5b_3x3"
  top: "bn_in5b_3x3"
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.9
    eps: 0.0001
    scale_filler {
      type: "constant"
      value: 1
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_in5b_3x3"
  type: "ReLU"
  bottom: "bn_in5b_3x3"
  top: "bn_in5b_3x3"
}
layer {
  name: "ch_concat_in5b_chconcat"
  type: "Concat"
  bottom: "bn_in5b_1x1"
  bottom: "bn_in5b_3x3"
  top: "ch_concat_in5b_chconcat"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "ch_concat_in5b_chconcat"
  top: "global_pool"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "fc1"
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I1024 14:29:05.462134 21201 layer_factory.hpp:77] Creating layer cifar
I1024 14:29:05.462190 21201 net.cpp:91] Creating Layer cifar
I1024 14:29:05.462198 21201 net.cpp:399] cifar -> data
I1024 14:29:05.462205 21201 net.cpp:399] cifar -> label
I1024 14:29:05.462213 21201 data_transformer.cpp:25] Loading mean file from: examples/cifar10/1parts/mean.binaryproto.0
I1024 14:29:05.463088 21211 db_lmdb.cpp:38] Opened lmdb examples/cifar10/1parts/cifar10_test_lmdb.0
I1024 14:29:05.463145 21201 data_layer.cpp:41] output data size: 32,3,32,32
I1024 14:29:05.463874 21201 net.cpp:141] Setting up cifar
I1024 14:29:05.463881 21201 net.cpp:148] Top shape: 32 3 32 32 (98304)
I1024 14:29:05.463884 21201 net.cpp:148] Top shape: 32 (32)
I1024 14:29:05.463887 21201 net.cpp:156] Memory required for data: 393344
I1024 14:29:05.463889 21201 layer_factory.hpp:77] Creating layer conv_conv1
I1024 14:29:05.463896 21201 net.cpp:91] Creating Layer conv_conv1
I1024 14:29:05.463897 21201 net.cpp:425] conv_conv1 <- data
I1024 14:29:05.463902 21201 net.cpp:399] conv_conv1 -> conv_conv1
I1024 14:29:05.464093 21201 net.cpp:141] Setting up conv_conv1
I1024 14:29:05.464098 21201 net.cpp:148] Top shape: 32 96 32 32 (3145728)
I1024 14:29:05.464100 21201 net.cpp:156] Memory required for data: 12976256
I1024 14:29:05.464107 21201 layer_factory.hpp:77] Creating layer bn_conv1
I1024 14:29:05.464112 21201 net.cpp:91] Creating Layer bn_conv1
I1024 14:29:05.464113 21201 net.cpp:425] bn_conv1 <- conv_conv1
I1024 14:29:05.464116 21201 net.cpp:399] bn_conv1 -> bn_conv1
I1024 14:29:05.464285 21201 net.cpp:141] Setting up bn_conv1
I1024 14:29:05.464292 21201 net.cpp:148] Top shape: 32 96 32 32 (3145728)
I1024 14:29:05.464293 21201 net.cpp:156] Memory required for data: 25559168
I1024 14:29:05.464301 21201 layer_factory.hpp:77] Creating layer relu_conv1
I1024 14:29:05.464304 21201 net.cpp:91] Creating Layer relu_conv1
I1024 14:29:05.464306 21201 net.cpp:425] relu_conv1 <- bn_conv1
I1024 14:29:05.464310 21201 net.cpp:386] relu_conv1 -> bn_conv1 (in-place)
I1024 14:29:05.464314 21201 net.cpp:141] Setting up relu_conv1
I1024 14:29:05.464318 21201 net.cpp:148] Top shape: 32 96 32 32 (3145728)
I1024 14:29:05.464323 21201 net.cpp:156] Memory required for data: 38142080
I1024 14:29:05.464325 21201 layer_factory.hpp:77] Creating layer bn_conv1_relu_conv1_0_split
I1024 14:29:05.464330 21201 net.cpp:91] Creating Layer bn_conv1_relu_conv1_0_split
I1024 14:29:05.464334 21201 net.cpp:425] bn_conv1_relu_conv1_0_split <- bn_conv1
I1024 14:29:05.464340 21201 net.cpp:399] bn_conv1_relu_conv1_0_split -> bn_conv1_relu_conv1_0_split_0
I1024 14:29:05.464347 21201 net.cpp:399] bn_conv1_relu_conv1_0_split -> bn_conv1_relu_conv1_0_split_1
I1024 14:29:05.464375 21201 net.cpp:141] Setting up bn_conv1_relu_conv1_0_split
I1024 14:29:05.464380 21201 net.cpp:148] Top shape: 32 96 32 32 (3145728)
I1024 14:29:05.464382 21201 net.cpp:148] Top shape: 32 96 32 32 (3145728)
I1024 14:29:05.464385 21201 net.cpp:156] Memory required for data: 63307904
I1024 14:29:05.464388 21201 layer_factory.hpp:77] Creating layer conv_in3a_1x1
I1024 14:29:05.464398 21201 net.cpp:91] Creating Layer conv_in3a_1x1
I1024 14:29:05.464402 21201 net.cpp:425] conv_in3a_1x1 <- bn_conv1_relu_conv1_0_split_0
I1024 14:29:05.464407 21201 net.cpp:399] conv_in3a_1x1 -> conv_in3a_1x1
I1024 14:29:05.464525 21201 net.cpp:141] Setting up conv_in3a_1x1
I1024 14:29:05.464531 21201 net.cpp:148] Top shape: 32 32 32 32 (1048576)
I1024 14:29:05.464534 21201 net.cpp:156] Memory required for data: 67502208
I1024 14:29:05.464536 21201 layer_factory.hpp:77] Creating layer bn_in3a_1x1
I1024 14:29:05.464545 21201 net.cpp:91] Creating Layer bn_in3a_1x1
I1024 14:29:05.464550 21201 net.cpp:425] bn_in3a_1x1 <- conv_in3a_1x1
I1024 14:29:05.464555 21201 net.cpp:399] bn_in3a_1x1 -> bn_in3a_1x1
I1024 14:29:05.464818 21201 net.cpp:141] Setting up bn_in3a_1x1
I1024 14:29:05.464825 21201 net.cpp:148] Top shape: 32 32 32 32 (1048576)
I1024 14:29:05.464829 21201 net.cpp:156] Memory required for data: 71696512
I1024 14:29:05.464839 21201 layer_factory.hpp:77] Creating layer relu_in3a_1x1
I1024 14:29:05.464845 21201 net.cpp:91] Creating Layer relu_in3a_1x1
I1024 14:29:05.464848 21201 net.cpp:425] relu_in3a_1x1 <- bn_in3a_1x1
I1024 14:29:05.464855 21201 net.cpp:386] relu_in3a_1x1 -> bn_in3a_1x1 (in-place)
I1024 14:29:05.464861 21201 net.cpp:141] Setting up relu_in3a_1x1
I1024 14:29:05.464874 21201 net.cpp:148] Top shape: 32 32 32 32 (1048576)
I1024 14:29:05.464877 21201 net.cpp:156] Memory required for data: 75890816
I1024 14:29:05.464882 21201 layer_factory.hpp:77] Creating layer conv_in3a_3x3
I1024 14:29:05.464890 21201 net.cpp:91] Creating Layer conv_in3a_3x3
I1024 14:29:05.464895 21201 net.cpp:425] conv_in3a_3x3 <- bn_conv1_relu_conv1_0_split_1
I1024 14:29:05.464900 21201 net.cpp:399] conv_in3a_3x3 -> conv_in3a_3x3
I1024 14:29:05.465099 21201 net.cpp:141] Setting up conv_in3a_3x3
I1024 14:29:05.465106 21201 net.cpp:148] Top shape: 32 32 32 32 (1048576)
I1024 14:29:05.465107 21201 net.cpp:156] Memory required for data: 80085120
I1024 14:29:05.465111 21201 layer_factory.hpp:77] Creating layer bn_in3a_3x3
I1024 14:29:05.465121 21201 net.cpp:91] Creating Layer bn_in3a_3x3
I1024 14:29:05.465126 21201 net.cpp:425] bn_in3a_3x3 <- conv_in3a_3x3
I1024 14:29:05.465131 21201 net.cpp:399] bn_in3a_3x3 -> bn_in3a_3x3
I1024 14:29:05.465315 21201 net.cpp:141] Setting up bn_in3a_3x3
I1024 14:29:05.465322 21201 net.cpp:148] Top shape: 32 32 32 32 (1048576)
I1024 14:29:05.465325 21201 net.cpp:156] Memory required for data: 84279424
I1024 14:29:05.465334 21201 layer_factory.hpp:77] Creating layer relu_in3a_3x3
I1024 14:29:05.465340 21201 net.cpp:91] Creating Layer relu_in3a_3x3
I1024 14:29:05.465344 21201 net.cpp:425] relu_in3a_3x3 <- bn_in3a_3x3
I1024 14:29:05.465349 21201 net.cpp:386] relu_in3a_3x3 -> bn_in3a_3x3 (in-place)
I1024 14:29:05.465355 21201 net.cpp:141] Setting up relu_in3a_3x3
I1024 14:29:05.465360 21201 net.cpp:148] Top shape: 32 32 32 32 (1048576)
I1024 14:29:05.465366 21201 net.cpp:156] Memory required for data: 88473728
I1024 14:29:05.465369 21201 layer_factory.hpp:77] Creating layer ch_concat_in3a_chconcat
I1024 14:29:05.465373 21201 net.cpp:91] Creating Layer ch_concat_in3a_chconcat
I1024 14:29:05.465378 21201 net.cpp:425] ch_concat_in3a_chconcat <- bn_in3a_1x1
I1024 14:29:05.465382 21201 net.cpp:425] ch_concat_in3a_chconcat <- bn_in3a_3x3
I1024 14:29:05.465389 21201 net.cpp:399] ch_concat_in3a_chconcat -> ch_concat_in3a_chconcat
I1024 14:29:05.465407 21201 net.cpp:141] Setting up ch_concat_in3a_chconcat
I1024 14:29:05.465414 21201 net.cpp:148] Top shape: 32 64 32 32 (2097152)
I1024 14:29:05.465415 21201 net.cpp:156] Memory required for data: 96862336
I1024 14:29:05.465420 21201 layer_factory.hpp:77] Creating layer ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split
I1024 14:29:05.465426 21201 net.cpp:91] Creating Layer ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split
I1024 14:29:05.465430 21201 net.cpp:425] ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split <- ch_concat_in3a_chconcat
I1024 14:29:05.465433 21201 net.cpp:399] ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split -> ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split_0
I1024 14:29:05.465440 21201 net.cpp:399] ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split -> ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split_1
I1024 14:29:05.465461 21201 net.cpp:141] Setting up ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split
I1024 14:29:05.465464 21201 net.cpp:148] Top shape: 32 64 32 32 (2097152)
I1024 14:29:05.465467 21201 net.cpp:148] Top shape: 32 64 32 32 (2097152)
I1024 14:29:05.465469 21201 net.cpp:156] Memory required for data: 113639552
I1024 14:29:05.465471 21201 layer_factory.hpp:77] Creating layer conv_in3b_1x1
I1024 14:29:05.465476 21201 net.cpp:91] Creating Layer conv_in3b_1x1
I1024 14:29:05.465478 21201 net.cpp:425] conv_in3b_1x1 <- ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split_0
I1024 14:29:05.465482 21201 net.cpp:399] conv_in3b_1x1 -> conv_in3b_1x1
I1024 14:29:05.465636 21201 net.cpp:141] Setting up conv_in3b_1x1
I1024 14:29:05.465641 21201 net.cpp:148] Top shape: 32 32 32 32 (1048576)
I1024 14:29:05.465644 21201 net.cpp:156] Memory required for data: 117833856
I1024 14:29:05.465647 21201 layer_factory.hpp:77] Creating layer bn_in3b_1x1
I1024 14:29:05.465652 21201 net.cpp:91] Creating Layer bn_in3b_1x1
I1024 14:29:05.465656 21201 net.cpp:425] bn_in3b_1x1 <- conv_in3b_1x1
I1024 14:29:05.465664 21201 net.cpp:399] bn_in3b_1x1 -> bn_in3b_1x1
I1024 14:29:05.465831 21201 net.cpp:141] Setting up bn_in3b_1x1
I1024 14:29:05.465836 21201 net.cpp:148] Top shape: 32 32 32 32 (1048576)
I1024 14:29:05.465837 21201 net.cpp:156] Memory required for data: 122028160
I1024 14:29:05.465842 21201 layer_factory.hpp:77] Creating layer relu_in3b_1x1
I1024 14:29:05.465847 21201 net.cpp:91] Creating Layer relu_in3b_1x1
I1024 14:29:05.465848 21201 net.cpp:425] relu_in3b_1x1 <- bn_in3b_1x1
I1024 14:29:05.465850 21201 net.cpp:386] relu_in3b_1x1 -> bn_in3b_1x1 (in-place)
I1024 14:29:05.465854 21201 net.cpp:141] Setting up relu_in3b_1x1
I1024 14:29:05.465857 21201 net.cpp:148] Top shape: 32 32 32 32 (1048576)
I1024 14:29:05.465859 21201 net.cpp:156] Memory required for data: 126222464
I1024 14:29:05.465862 21201 layer_factory.hpp:77] Creating layer conv_in3b_3x3
I1024 14:29:05.465869 21201 net.cpp:91] Creating Layer conv_in3b_3x3
I1024 14:29:05.465873 21201 net.cpp:425] conv_in3b_3x3 <- ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split_1
I1024 14:29:05.465875 21201 net.cpp:399] conv_in3b_3x3 -> conv_in3b_3x3
I1024 14:29:05.466064 21201 net.cpp:141] Setting up conv_in3b_3x3
I1024 14:29:05.466069 21201 net.cpp:148] Top shape: 32 48 32 32 (1572864)
I1024 14:29:05.466071 21201 net.cpp:156] Memory required for data: 132513920
I1024 14:29:05.466073 21201 layer_factory.hpp:77] Creating layer bn_in3b_3x3
I1024 14:29:05.466076 21201 net.cpp:91] Creating Layer bn_in3b_3x3
I1024 14:29:05.466079 21201 net.cpp:425] bn_in3b_3x3 <- conv_in3b_3x3
I1024 14:29:05.466084 21201 net.cpp:399] bn_in3b_3x3 -> bn_in3b_3x3
I1024 14:29:05.466241 21201 net.cpp:141] Setting up bn_in3b_3x3
I1024 14:29:05.466246 21201 net.cpp:148] Top shape: 32 48 32 32 (1572864)
I1024 14:29:05.466249 21201 net.cpp:156] Memory required for data: 138805376
I1024 14:29:05.466253 21201 layer_factory.hpp:77] Creating layer relu_in3b_3x3
I1024 14:29:05.466258 21201 net.cpp:91] Creating Layer relu_in3b_3x3
I1024 14:29:05.466259 21201 net.cpp:425] relu_in3b_3x3 <- bn_in3b_3x3
I1024 14:29:05.466262 21201 net.cpp:386] relu_in3b_3x3 -> bn_in3b_3x3 (in-place)
I1024 14:29:05.466265 21201 net.cpp:141] Setting up relu_in3b_3x3
I1024 14:29:05.466267 21201 net.cpp:148] Top shape: 32 48 32 32 (1572864)
I1024 14:29:05.466269 21201 net.cpp:156] Memory required for data: 145096832
I1024 14:29:05.466271 21201 layer_factory.hpp:77] Creating layer ch_concat_in3b_chconcat
I1024 14:29:05.466275 21201 net.cpp:91] Creating Layer ch_concat_in3b_chconcat
I1024 14:29:05.466277 21201 net.cpp:425] ch_concat_in3b_chconcat <- bn_in3b_1x1
I1024 14:29:05.466279 21201 net.cpp:425] ch_concat_in3b_chconcat <- bn_in3b_3x3
I1024 14:29:05.466284 21201 net.cpp:399] ch_concat_in3b_chconcat -> ch_concat_in3b_chconcat
I1024 14:29:05.466295 21201 net.cpp:141] Setting up ch_concat_in3b_chconcat
I1024 14:29:05.466300 21201 net.cpp:148] Top shape: 32 80 32 32 (2621440)
I1024 14:29:05.466301 21201 net.cpp:156] Memory required for data: 155582592
I1024 14:29:05.466303 21201 layer_factory.hpp:77] Creating layer ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split
I1024 14:29:05.466306 21201 net.cpp:91] Creating Layer ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split
I1024 14:29:05.466308 21201 net.cpp:425] ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split <- ch_concat_in3b_chconcat
I1024 14:29:05.466311 21201 net.cpp:399] ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split -> ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split_0
I1024 14:29:05.466315 21201 net.cpp:399] ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split -> ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split_1
I1024 14:29:05.466333 21201 net.cpp:141] Setting up ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split
I1024 14:29:05.466337 21201 net.cpp:148] Top shape: 32 80 32 32 (2621440)
I1024 14:29:05.466341 21201 net.cpp:148] Top shape: 32 80 32 32 (2621440)
I1024 14:29:05.466342 21201 net.cpp:156] Memory required for data: 176554112
I1024 14:29:05.466344 21201 layer_factory.hpp:77] Creating layer conv_in3c_3x3
I1024 14:29:05.466354 21201 net.cpp:91] Creating Layer conv_in3c_3x3
I1024 14:29:05.466357 21201 net.cpp:425] conv_in3c_3x3 <- ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split_0
I1024 14:29:05.466361 21201 net.cpp:399] conv_in3c_3x3 -> conv_in3c_3x3
I1024 14:29:05.466646 21201 net.cpp:141] Setting up conv_in3c_3x3
I1024 14:29:05.466651 21201 net.cpp:148] Top shape: 32 80 16 16 (655360)
I1024 14:29:05.466653 21201 net.cpp:156] Memory required for data: 179175552
I1024 14:29:05.466656 21201 layer_factory.hpp:77] Creating layer bn_in3c_3x3
I1024 14:29:05.466660 21201 net.cpp:91] Creating Layer bn_in3c_3x3
I1024 14:29:05.466663 21201 net.cpp:425] bn_in3c_3x3 <- conv_in3c_3x3
I1024 14:29:05.466666 21201 net.cpp:399] bn_in3c_3x3 -> bn_in3c_3x3
I1024 14:29:05.466823 21201 net.cpp:141] Setting up bn_in3c_3x3
I1024 14:29:05.466827 21201 net.cpp:148] Top shape: 32 80 16 16 (655360)
I1024 14:29:05.466830 21201 net.cpp:156] Memory required for data: 181796992
I1024 14:29:05.466837 21201 layer_factory.hpp:77] Creating layer relu_in3c_3x3
I1024 14:29:05.466841 21201 net.cpp:91] Creating Layer relu_in3c_3x3
I1024 14:29:05.466843 21201 net.cpp:425] relu_in3c_3x3 <- bn_in3c_3x3
I1024 14:29:05.466846 21201 net.cpp:386] relu_in3c_3x3 -> bn_in3c_3x3 (in-place)
I1024 14:29:05.466850 21201 net.cpp:141] Setting up relu_in3c_3x3
I1024 14:29:05.466853 21201 net.cpp:148] Top shape: 32 80 16 16 (655360)
I1024 14:29:05.466856 21201 net.cpp:156] Memory required for data: 184418432
I1024 14:29:05.466857 21201 layer_factory.hpp:77] Creating layer max_pool_in3c_pool
I1024 14:29:05.466859 21201 net.cpp:91] Creating Layer max_pool_in3c_pool
I1024 14:29:05.466862 21201 net.cpp:425] max_pool_in3c_pool <- ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split_1
I1024 14:29:05.466866 21201 net.cpp:399] max_pool_in3c_pool -> max_pool_in3c_pool
I1024 14:29:05.466886 21201 net.cpp:141] Setting up max_pool_in3c_pool
I1024 14:29:05.466889 21201 net.cpp:148] Top shape: 32 80 16 16 (655360)
I1024 14:29:05.466892 21201 net.cpp:156] Memory required for data: 187039872
I1024 14:29:05.466893 21201 layer_factory.hpp:77] Creating layer ch_concat_in3c_chconcat
I1024 14:29:05.466897 21201 net.cpp:91] Creating Layer ch_concat_in3c_chconcat
I1024 14:29:05.466898 21201 net.cpp:425] ch_concat_in3c_chconcat <- bn_in3c_3x3
I1024 14:29:05.466902 21201 net.cpp:425] ch_concat_in3c_chconcat <- max_pool_in3c_pool
I1024 14:29:05.466904 21201 net.cpp:399] ch_concat_in3c_chconcat -> ch_concat_in3c_chconcat
I1024 14:29:05.466917 21201 net.cpp:141] Setting up ch_concat_in3c_chconcat
I1024 14:29:05.466922 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.466923 21201 net.cpp:156] Memory required for data: 192282752
I1024 14:29:05.466925 21201 layer_factory.hpp:77] Creating layer ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split
I1024 14:29:05.466928 21201 net.cpp:91] Creating Layer ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split
I1024 14:29:05.466930 21201 net.cpp:425] ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split <- ch_concat_in3c_chconcat
I1024 14:29:05.466934 21201 net.cpp:399] ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split -> ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split_0
I1024 14:29:05.466938 21201 net.cpp:399] ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split -> ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split_1
I1024 14:29:05.466958 21201 net.cpp:141] Setting up ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split
I1024 14:29:05.466962 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.466964 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.466966 21201 net.cpp:156] Memory required for data: 202768512
I1024 14:29:05.466969 21201 layer_factory.hpp:77] Creating layer conv_in4a_1x1
I1024 14:29:05.466974 21201 net.cpp:91] Creating Layer conv_in4a_1x1
I1024 14:29:05.466976 21201 net.cpp:425] conv_in4a_1x1 <- ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split_0
I1024 14:29:05.466980 21201 net.cpp:399] conv_in4a_1x1 -> conv_in4a_1x1
I1024 14:29:05.467139 21201 net.cpp:141] Setting up conv_in4a_1x1
I1024 14:29:05.467144 21201 net.cpp:148] Top shape: 32 112 16 16 (917504)
I1024 14:29:05.467146 21201 net.cpp:156] Memory required for data: 206438528
I1024 14:29:05.467149 21201 layer_factory.hpp:77] Creating layer bn_in4a_1x1
I1024 14:29:05.467154 21201 net.cpp:91] Creating Layer bn_in4a_1x1
I1024 14:29:05.467156 21201 net.cpp:425] bn_in4a_1x1 <- conv_in4a_1x1
I1024 14:29:05.467159 21201 net.cpp:399] bn_in4a_1x1 -> bn_in4a_1x1
I1024 14:29:05.467316 21201 net.cpp:141] Setting up bn_in4a_1x1
I1024 14:29:05.467320 21201 net.cpp:148] Top shape: 32 112 16 16 (917504)
I1024 14:29:05.467322 21201 net.cpp:156] Memory required for data: 210108544
I1024 14:29:05.467327 21201 layer_factory.hpp:77] Creating layer relu_in4a_1x1
I1024 14:29:05.467331 21201 net.cpp:91] Creating Layer relu_in4a_1x1
I1024 14:29:05.467334 21201 net.cpp:425] relu_in4a_1x1 <- bn_in4a_1x1
I1024 14:29:05.467335 21201 net.cpp:386] relu_in4a_1x1 -> bn_in4a_1x1 (in-place)
I1024 14:29:05.467339 21201 net.cpp:141] Setting up relu_in4a_1x1
I1024 14:29:05.467341 21201 net.cpp:148] Top shape: 32 112 16 16 (917504)
I1024 14:29:05.467344 21201 net.cpp:156] Memory required for data: 213778560
I1024 14:29:05.467346 21201 layer_factory.hpp:77] Creating layer conv_in4a_3x3
I1024 14:29:05.467352 21201 net.cpp:91] Creating Layer conv_in4a_3x3
I1024 14:29:05.467355 21201 net.cpp:425] conv_in4a_3x3 <- ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split_1
I1024 14:29:05.467358 21201 net.cpp:399] conv_in4a_3x3 -> conv_in4a_3x3
I1024 14:29:05.467682 21201 net.cpp:141] Setting up conv_in4a_3x3
I1024 14:29:05.467687 21201 net.cpp:148] Top shape: 32 48 16 16 (393216)
I1024 14:29:05.467689 21201 net.cpp:156] Memory required for data: 215351424
I1024 14:29:05.467692 21201 layer_factory.hpp:77] Creating layer bn_in4a_3x3
I1024 14:29:05.467695 21201 net.cpp:91] Creating Layer bn_in4a_3x3
I1024 14:29:05.467697 21201 net.cpp:425] bn_in4a_3x3 <- conv_in4a_3x3
I1024 14:29:05.467701 21201 net.cpp:399] bn_in4a_3x3 -> bn_in4a_3x3
I1024 14:29:05.467857 21201 net.cpp:141] Setting up bn_in4a_3x3
I1024 14:29:05.467862 21201 net.cpp:148] Top shape: 32 48 16 16 (393216)
I1024 14:29:05.467864 21201 net.cpp:156] Memory required for data: 216924288
I1024 14:29:05.467869 21201 layer_factory.hpp:77] Creating layer relu_in4a_3x3
I1024 14:29:05.467875 21201 net.cpp:91] Creating Layer relu_in4a_3x3
I1024 14:29:05.467878 21201 net.cpp:425] relu_in4a_3x3 <- bn_in4a_3x3
I1024 14:29:05.467880 21201 net.cpp:386] relu_in4a_3x3 -> bn_in4a_3x3 (in-place)
I1024 14:29:05.467885 21201 net.cpp:141] Setting up relu_in4a_3x3
I1024 14:29:05.467886 21201 net.cpp:148] Top shape: 32 48 16 16 (393216)
I1024 14:29:05.467888 21201 net.cpp:156] Memory required for data: 218497152
I1024 14:29:05.467890 21201 layer_factory.hpp:77] Creating layer ch_concat_in4a_chconcat
I1024 14:29:05.467893 21201 net.cpp:91] Creating Layer ch_concat_in4a_chconcat
I1024 14:29:05.467895 21201 net.cpp:425] ch_concat_in4a_chconcat <- bn_in4a_1x1
I1024 14:29:05.467897 21201 net.cpp:425] ch_concat_in4a_chconcat <- bn_in4a_3x3
I1024 14:29:05.467900 21201 net.cpp:399] ch_concat_in4a_chconcat -> ch_concat_in4a_chconcat
I1024 14:29:05.467914 21201 net.cpp:141] Setting up ch_concat_in4a_chconcat
I1024 14:29:05.467918 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.467921 21201 net.cpp:156] Memory required for data: 223740032
I1024 14:29:05.467922 21201 layer_factory.hpp:77] Creating layer ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split
I1024 14:29:05.467926 21201 net.cpp:91] Creating Layer ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split
I1024 14:29:05.467927 21201 net.cpp:425] ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split <- ch_concat_in4a_chconcat
I1024 14:29:05.467931 21201 net.cpp:399] ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split -> ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split_0
I1024 14:29:05.467936 21201 net.cpp:399] ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split -> ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split_1
I1024 14:29:05.467964 21201 net.cpp:141] Setting up ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split
I1024 14:29:05.467969 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.467972 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.467973 21201 net.cpp:156] Memory required for data: 234225792
I1024 14:29:05.467975 21201 layer_factory.hpp:77] Creating layer conv_in4b_1x1
I1024 14:29:05.467980 21201 net.cpp:91] Creating Layer conv_in4b_1x1
I1024 14:29:05.467983 21201 net.cpp:425] conv_in4b_1x1 <- ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split_0
I1024 14:29:05.467986 21201 net.cpp:399] conv_in4b_1x1 -> conv_in4b_1x1
I1024 14:29:05.468134 21201 net.cpp:141] Setting up conv_in4b_1x1
I1024 14:29:05.468139 21201 net.cpp:148] Top shape: 32 96 16 16 (786432)
I1024 14:29:05.468142 21201 net.cpp:156] Memory required for data: 237371520
I1024 14:29:05.468144 21201 layer_factory.hpp:77] Creating layer bn_in4b_1x1
I1024 14:29:05.468147 21201 net.cpp:91] Creating Layer bn_in4b_1x1
I1024 14:29:05.468150 21201 net.cpp:425] bn_in4b_1x1 <- conv_in4b_1x1
I1024 14:29:05.468153 21201 net.cpp:399] bn_in4b_1x1 -> bn_in4b_1x1
I1024 14:29:05.468312 21201 net.cpp:141] Setting up bn_in4b_1x1
I1024 14:29:05.468317 21201 net.cpp:148] Top shape: 32 96 16 16 (786432)
I1024 14:29:05.468318 21201 net.cpp:156] Memory required for data: 240517248
I1024 14:29:05.468322 21201 layer_factory.hpp:77] Creating layer relu_in4b_1x1
I1024 14:29:05.468327 21201 net.cpp:91] Creating Layer relu_in4b_1x1
I1024 14:29:05.468329 21201 net.cpp:425] relu_in4b_1x1 <- bn_in4b_1x1
I1024 14:29:05.468333 21201 net.cpp:386] relu_in4b_1x1 -> bn_in4b_1x1 (in-place)
I1024 14:29:05.468335 21201 net.cpp:141] Setting up relu_in4b_1x1
I1024 14:29:05.468338 21201 net.cpp:148] Top shape: 32 96 16 16 (786432)
I1024 14:29:05.468341 21201 net.cpp:156] Memory required for data: 243662976
I1024 14:29:05.468343 21201 layer_factory.hpp:77] Creating layer conv_in4b_3x3
I1024 14:29:05.468348 21201 net.cpp:91] Creating Layer conv_in4b_3x3
I1024 14:29:05.468350 21201 net.cpp:425] conv_in4b_3x3 <- ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split_1
I1024 14:29:05.468354 21201 net.cpp:399] conv_in4b_3x3 -> conv_in4b_3x3
I1024 14:29:05.468798 21201 net.cpp:141] Setting up conv_in4b_3x3
I1024 14:29:05.468806 21201 net.cpp:148] Top shape: 32 64 16 16 (524288)
I1024 14:29:05.468809 21201 net.cpp:156] Memory required for data: 245760128
I1024 14:29:05.468816 21201 layer_factory.hpp:77] Creating layer bn_in4b_3x3
I1024 14:29:05.468824 21201 net.cpp:91] Creating Layer bn_in4b_3x3
I1024 14:29:05.468828 21201 net.cpp:425] bn_in4b_3x3 <- conv_in4b_3x3
I1024 14:29:05.468834 21201 net.cpp:399] bn_in4b_3x3 -> bn_in4b_3x3
I1024 14:29:05.468994 21201 net.cpp:141] Setting up bn_in4b_3x3
I1024 14:29:05.468998 21201 net.cpp:148] Top shape: 32 64 16 16 (524288)
I1024 14:29:05.469000 21201 net.cpp:156] Memory required for data: 247857280
I1024 14:29:05.469005 21201 layer_factory.hpp:77] Creating layer relu_in4b_3x3
I1024 14:29:05.469009 21201 net.cpp:91] Creating Layer relu_in4b_3x3
I1024 14:29:05.469012 21201 net.cpp:425] relu_in4b_3x3 <- bn_in4b_3x3
I1024 14:29:05.469014 21201 net.cpp:386] relu_in4b_3x3 -> bn_in4b_3x3 (in-place)
I1024 14:29:05.469017 21201 net.cpp:141] Setting up relu_in4b_3x3
I1024 14:29:05.469020 21201 net.cpp:148] Top shape: 32 64 16 16 (524288)
I1024 14:29:05.469022 21201 net.cpp:156] Memory required for data: 249954432
I1024 14:29:05.469024 21201 layer_factory.hpp:77] Creating layer ch_concat_in4b_chconcat
I1024 14:29:05.469027 21201 net.cpp:91] Creating Layer ch_concat_in4b_chconcat
I1024 14:29:05.469030 21201 net.cpp:425] ch_concat_in4b_chconcat <- bn_in4b_1x1
I1024 14:29:05.469033 21201 net.cpp:425] ch_concat_in4b_chconcat <- bn_in4b_3x3
I1024 14:29:05.469035 21201 net.cpp:399] ch_concat_in4b_chconcat -> ch_concat_in4b_chconcat
I1024 14:29:05.469049 21201 net.cpp:141] Setting up ch_concat_in4b_chconcat
I1024 14:29:05.469053 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.469055 21201 net.cpp:156] Memory required for data: 255197312
I1024 14:29:05.469066 21201 layer_factory.hpp:77] Creating layer ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split
I1024 14:29:05.469072 21201 net.cpp:91] Creating Layer ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split
I1024 14:29:05.469075 21201 net.cpp:425] ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split <- ch_concat_in4b_chconcat
I1024 14:29:05.469079 21201 net.cpp:399] ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split -> ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split_0
I1024 14:29:05.469084 21201 net.cpp:399] ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split -> ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split_1
I1024 14:29:05.469105 21201 net.cpp:141] Setting up ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split
I1024 14:29:05.469108 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.469111 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.469112 21201 net.cpp:156] Memory required for data: 265683072
I1024 14:29:05.469115 21201 layer_factory.hpp:77] Creating layer conv_in4c_1x1
I1024 14:29:05.469120 21201 net.cpp:91] Creating Layer conv_in4c_1x1
I1024 14:29:05.469121 21201 net.cpp:425] conv_in4c_1x1 <- ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split_0
I1024 14:29:05.469125 21201 net.cpp:399] conv_in4c_1x1 -> conv_in4c_1x1
I1024 14:29:05.469267 21201 net.cpp:141] Setting up conv_in4c_1x1
I1024 14:29:05.469271 21201 net.cpp:148] Top shape: 32 80 16 16 (655360)
I1024 14:29:05.469274 21201 net.cpp:156] Memory required for data: 268304512
I1024 14:29:05.469275 21201 layer_factory.hpp:77] Creating layer bn_in4c_1x1
I1024 14:29:05.469280 21201 net.cpp:91] Creating Layer bn_in4c_1x1
I1024 14:29:05.469282 21201 net.cpp:425] bn_in4c_1x1 <- conv_in4c_1x1
I1024 14:29:05.469285 21201 net.cpp:399] bn_in4c_1x1 -> bn_in4c_1x1
I1024 14:29:05.469449 21201 net.cpp:141] Setting up bn_in4c_1x1
I1024 14:29:05.469452 21201 net.cpp:148] Top shape: 32 80 16 16 (655360)
I1024 14:29:05.469455 21201 net.cpp:156] Memory required for data: 270925952
I1024 14:29:05.469463 21201 layer_factory.hpp:77] Creating layer relu_in4c_1x1
I1024 14:29:05.469466 21201 net.cpp:91] Creating Layer relu_in4c_1x1
I1024 14:29:05.469468 21201 net.cpp:425] relu_in4c_1x1 <- bn_in4c_1x1
I1024 14:29:05.469471 21201 net.cpp:386] relu_in4c_1x1 -> bn_in4c_1x1 (in-place)
I1024 14:29:05.469475 21201 net.cpp:141] Setting up relu_in4c_1x1
I1024 14:29:05.469477 21201 net.cpp:148] Top shape: 32 80 16 16 (655360)
I1024 14:29:05.469480 21201 net.cpp:156] Memory required for data: 273547392
I1024 14:29:05.469481 21201 layer_factory.hpp:77] Creating layer conv_in4c_3x3
I1024 14:29:05.469485 21201 net.cpp:91] Creating Layer conv_in4c_3x3
I1024 14:29:05.469487 21201 net.cpp:425] conv_in4c_3x3 <- ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split_1
I1024 14:29:05.469491 21201 net.cpp:399] conv_in4c_3x3 -> conv_in4c_3x3
I1024 14:29:05.469960 21201 net.cpp:141] Setting up conv_in4c_3x3
I1024 14:29:05.469965 21201 net.cpp:148] Top shape: 32 80 16 16 (655360)
I1024 14:29:05.469966 21201 net.cpp:156] Memory required for data: 276168832
I1024 14:29:05.469969 21201 layer_factory.hpp:77] Creating layer bn_in4c_3x3
I1024 14:29:05.469974 21201 net.cpp:91] Creating Layer bn_in4c_3x3
I1024 14:29:05.469975 21201 net.cpp:425] bn_in4c_3x3 <- conv_in4c_3x3
I1024 14:29:05.469979 21201 net.cpp:399] bn_in4c_3x3 -> bn_in4c_3x3
I1024 14:29:05.470134 21201 net.cpp:141] Setting up bn_in4c_3x3
I1024 14:29:05.470139 21201 net.cpp:148] Top shape: 32 80 16 16 (655360)
I1024 14:29:05.470141 21201 net.cpp:156] Memory required for data: 278790272
I1024 14:29:05.470145 21201 layer_factory.hpp:77] Creating layer relu_in4c_3x3
I1024 14:29:05.470149 21201 net.cpp:91] Creating Layer relu_in4c_3x3
I1024 14:29:05.470150 21201 net.cpp:425] relu_in4c_3x3 <- bn_in4c_3x3
I1024 14:29:05.470154 21201 net.cpp:386] relu_in4c_3x3 -> bn_in4c_3x3 (in-place)
I1024 14:29:05.470156 21201 net.cpp:141] Setting up relu_in4c_3x3
I1024 14:29:05.470158 21201 net.cpp:148] Top shape: 32 80 16 16 (655360)
I1024 14:29:05.470165 21201 net.cpp:156] Memory required for data: 281411712
I1024 14:29:05.470167 21201 layer_factory.hpp:77] Creating layer ch_concat_in4c_chconcat
I1024 14:29:05.470170 21201 net.cpp:91] Creating Layer ch_concat_in4c_chconcat
I1024 14:29:05.470172 21201 net.cpp:425] ch_concat_in4c_chconcat <- bn_in4c_1x1
I1024 14:29:05.470175 21201 net.cpp:425] ch_concat_in4c_chconcat <- bn_in4c_3x3
I1024 14:29:05.470178 21201 net.cpp:399] ch_concat_in4c_chconcat -> ch_concat_in4c_chconcat
I1024 14:29:05.470191 21201 net.cpp:141] Setting up ch_concat_in4c_chconcat
I1024 14:29:05.470196 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.470197 21201 net.cpp:156] Memory required for data: 286654592
I1024 14:29:05.470199 21201 layer_factory.hpp:77] Creating layer ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split
I1024 14:29:05.470202 21201 net.cpp:91] Creating Layer ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split
I1024 14:29:05.470204 21201 net.cpp:425] ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split <- ch_concat_in4c_chconcat
I1024 14:29:05.470208 21201 net.cpp:399] ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split -> ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split_0
I1024 14:29:05.470212 21201 net.cpp:399] ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split -> ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split_1
I1024 14:29:05.470230 21201 net.cpp:141] Setting up ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split
I1024 14:29:05.470234 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.470237 21201 net.cpp:148] Top shape: 32 160 16 16 (1310720)
I1024 14:29:05.470238 21201 net.cpp:156] Memory required for data: 297140352
I1024 14:29:05.470240 21201 layer_factory.hpp:77] Creating layer conv_in4d_1x1
I1024 14:29:05.470244 21201 net.cpp:91] Creating Layer conv_in4d_1x1
I1024 14:29:05.470247 21201 net.cpp:425] conv_in4d_1x1 <- ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split_0
I1024 14:29:05.470250 21201 net.cpp:399] conv_in4d_1x1 -> conv_in4d_1x1
I1024 14:29:05.470373 21201 net.cpp:141] Setting up conv_in4d_1x1
I1024 14:29:05.470377 21201 net.cpp:148] Top shape: 32 48 16 16 (393216)
I1024 14:29:05.470379 21201 net.cpp:156] Memory required for data: 298713216
I1024 14:29:05.470382 21201 layer_factory.hpp:77] Creating layer bn_in4d_1x1
I1024 14:29:05.470386 21201 net.cpp:91] Creating Layer bn_in4d_1x1
I1024 14:29:05.470387 21201 net.cpp:425] bn_in4d_1x1 <- conv_in4d_1x1
I1024 14:29:05.470391 21201 net.cpp:399] bn_in4d_1x1 -> bn_in4d_1x1
I1024 14:29:05.470547 21201 net.cpp:141] Setting up bn_in4d_1x1
I1024 14:29:05.470551 21201 net.cpp:148] Top shape: 32 48 16 16 (393216)
I1024 14:29:05.470553 21201 net.cpp:156] Memory required for data: 300286080
I1024 14:29:05.470558 21201 layer_factory.hpp:77] Creating layer relu_in4d_1x1
I1024 14:29:05.470561 21201 net.cpp:91] Creating Layer relu_in4d_1x1
I1024 14:29:05.470562 21201 net.cpp:425] relu_in4d_1x1 <- bn_in4d_1x1
I1024 14:29:05.470566 21201 net.cpp:386] relu_in4d_1x1 -> bn_in4d_1x1 (in-place)
I1024 14:29:05.470568 21201 net.cpp:141] Setting up relu_in4d_1x1
I1024 14:29:05.470571 21201 net.cpp:148] Top shape: 32 48 16 16 (393216)
I1024 14:29:05.470572 21201 net.cpp:156] Memory required for data: 301858944
I1024 14:29:05.470574 21201 layer_factory.hpp:77] Creating layer conv_in4d_3x3
I1024 14:29:05.470578 21201 net.cpp:91] Creating Layer conv_in4d_3x3
I1024 14:29:05.470582 21201 net.cpp:425] conv_in4d_3x3 <- ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split_1
I1024 14:29:05.470584 21201 net.cpp:399] conv_in4d_3x3 -> conv_in4d_3x3
I1024 14:29:05.471555 21201 net.cpp:141] Setting up conv_in4d_3x3
I1024 14:29:05.471562 21201 net.cpp:148] Top shape: 32 96 16 16 (786432)
I1024 14:29:05.471565 21201 net.cpp:156] Memory required for data: 305004672
I1024 14:29:05.471567 21201 layer_factory.hpp:77] Creating layer bn_in4d_3x3
I1024 14:29:05.471571 21201 net.cpp:91] Creating Layer bn_in4d_3x3
I1024 14:29:05.471575 21201 net.cpp:425] bn_in4d_3x3 <- conv_in4d_3x3
I1024 14:29:05.471577 21201 net.cpp:399] bn_in4d_3x3 -> bn_in4d_3x3
I1024 14:29:05.471746 21201 net.cpp:141] Setting up bn_in4d_3x3
I1024 14:29:05.471750 21201 net.cpp:148] Top shape: 32 96 16 16 (786432)
I1024 14:29:05.471752 21201 net.cpp:156] Memory required for data: 308150400
I1024 14:29:05.471757 21201 layer_factory.hpp:77] Creating layer relu_in4d_3x3
I1024 14:29:05.471760 21201 net.cpp:91] Creating Layer relu_in4d_3x3
I1024 14:29:05.471761 21201 net.cpp:425] relu_in4d_3x3 <- bn_in4d_3x3
I1024 14:29:05.471765 21201 net.cpp:386] relu_in4d_3x3 -> bn_in4d_3x3 (in-place)
I1024 14:29:05.471770 21201 net.cpp:141] Setting up relu_in4d_3x3
I1024 14:29:05.471771 21201 net.cpp:148] Top shape: 32 96 16 16 (786432)
I1024 14:29:05.471773 21201 net.cpp:156] Memory required for data: 311296128
I1024 14:29:05.471776 21201 layer_factory.hpp:77] Creating layer ch_concat_in4d_chconcat
I1024 14:29:05.471778 21201 net.cpp:91] Creating Layer ch_concat_in4d_chconcat
I1024 14:29:05.471781 21201 net.cpp:425] ch_concat_in4d_chconcat <- bn_in4d_1x1
I1024 14:29:05.471782 21201 net.cpp:425] ch_concat_in4d_chconcat <- bn_in4d_3x3
I1024 14:29:05.471786 21201 net.cpp:399] ch_concat_in4d_chconcat -> ch_concat_in4d_chconcat
I1024 14:29:05.471798 21201 net.cpp:141] Setting up ch_concat_in4d_chconcat
I1024 14:29:05.471801 21201 net.cpp:148] Top shape: 32 144 16 16 (1179648)
I1024 14:29:05.471803 21201 net.cpp:156] Memory required for data: 316014720
I1024 14:29:05.471806 21201 layer_factory.hpp:77] Creating layer ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split
I1024 14:29:05.471810 21201 net.cpp:91] Creating Layer ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split
I1024 14:29:05.471812 21201 net.cpp:425] ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split <- ch_concat_in4d_chconcat
I1024 14:29:05.471815 21201 net.cpp:399] ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split -> ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split_0
I1024 14:29:05.471819 21201 net.cpp:399] ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split -> ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split_1
I1024 14:29:05.471839 21201 net.cpp:141] Setting up ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split
I1024 14:29:05.471843 21201 net.cpp:148] Top shape: 32 144 16 16 (1179648)
I1024 14:29:05.471844 21201 net.cpp:148] Top shape: 32 144 16 16 (1179648)
I1024 14:29:05.471846 21201 net.cpp:156] Memory required for data: 325451904
I1024 14:29:05.471848 21201 layer_factory.hpp:77] Creating layer conv_in4e_3x3
I1024 14:29:05.471853 21201 net.cpp:91] Creating Layer conv_in4e_3x3
I1024 14:29:05.471854 21201 net.cpp:425] conv_in4e_3x3 <- ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split_0
I1024 14:29:05.471858 21201 net.cpp:399] conv_in4e_3x3 -> conv_in4e_3x3
I1024 14:29:05.472355 21201 net.cpp:141] Setting up conv_in4e_3x3
I1024 14:29:05.472359 21201 net.cpp:148] Top shape: 32 96 8 8 (196608)
I1024 14:29:05.472360 21201 net.cpp:156] Memory required for data: 326238336
I1024 14:29:05.472363 21201 layer_factory.hpp:77] Creating layer bn_in4e_3x3
I1024 14:29:05.472368 21201 net.cpp:91] Creating Layer bn_in4e_3x3
I1024 14:29:05.472370 21201 net.cpp:425] bn_in4e_3x3 <- conv_in4e_3x3
I1024 14:29:05.472373 21201 net.cpp:399] bn_in4e_3x3 -> bn_in4e_3x3
I1024 14:29:05.472537 21201 net.cpp:141] Setting up bn_in4e_3x3
I1024 14:29:05.472540 21201 net.cpp:148] Top shape: 32 96 8 8 (196608)
I1024 14:29:05.472543 21201 net.cpp:156] Memory required for data: 327024768
I1024 14:29:05.472548 21201 layer_factory.hpp:77] Creating layer relu_in4e_3x3
I1024 14:29:05.472553 21201 net.cpp:91] Creating Layer relu_in4e_3x3
I1024 14:29:05.472558 21201 net.cpp:425] relu_in4e_3x3 <- bn_in4e_3x3
I1024 14:29:05.472561 21201 net.cpp:386] relu_in4e_3x3 -> bn_in4e_3x3 (in-place)
I1024 14:29:05.472565 21201 net.cpp:141] Setting up relu_in4e_3x3
I1024 14:29:05.472568 21201 net.cpp:148] Top shape: 32 96 8 8 (196608)
I1024 14:29:05.472570 21201 net.cpp:156] Memory required for data: 327811200
I1024 14:29:05.472573 21201 layer_factory.hpp:77] Creating layer max_pool_in4e_pool
I1024 14:29:05.472578 21201 net.cpp:91] Creating Layer max_pool_in4e_pool
I1024 14:29:05.472584 21201 net.cpp:425] max_pool_in4e_pool <- ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split_1
I1024 14:29:05.472589 21201 net.cpp:399] max_pool_in4e_pool -> max_pool_in4e_pool
I1024 14:29:05.472635 21201 net.cpp:141] Setting up max_pool_in4e_pool
I1024 14:29:05.472637 21201 net.cpp:148] Top shape: 32 144 8 8 (294912)
I1024 14:29:05.472653 21201 net.cpp:156] Memory required for data: 328990848
I1024 14:29:05.472656 21201 layer_factory.hpp:77] Creating layer ch_concat_in4e_chconcat
I1024 14:29:05.472658 21201 net.cpp:91] Creating Layer ch_concat_in4e_chconcat
I1024 14:29:05.472661 21201 net.cpp:425] ch_concat_in4e_chconcat <- bn_in4e_3x3
I1024 14:29:05.472662 21201 net.cpp:425] ch_concat_in4e_chconcat <- max_pool_in4e_pool
I1024 14:29:05.472666 21201 net.cpp:399] ch_concat_in4e_chconcat -> ch_concat_in4e_chconcat
I1024 14:29:05.472679 21201 net.cpp:141] Setting up ch_concat_in4e_chconcat
I1024 14:29:05.472682 21201 net.cpp:148] Top shape: 32 240 8 8 (491520)
I1024 14:29:05.472684 21201 net.cpp:156] Memory required for data: 330956928
I1024 14:29:05.472687 21201 layer_factory.hpp:77] Creating layer ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split
I1024 14:29:05.472694 21201 net.cpp:91] Creating Layer ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split
I1024 14:29:05.472697 21201 net.cpp:425] ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split <- ch_concat_in4e_chconcat
I1024 14:29:05.472699 21201 net.cpp:399] ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split -> ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split_0
I1024 14:29:05.472703 21201 net.cpp:399] ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split -> ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split_1
I1024 14:29:05.472723 21201 net.cpp:141] Setting up ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split
I1024 14:29:05.472726 21201 net.cpp:148] Top shape: 32 240 8 8 (491520)
I1024 14:29:05.472728 21201 net.cpp:148] Top shape: 32 240 8 8 (491520)
I1024 14:29:05.472730 21201 net.cpp:156] Memory required for data: 334889088
I1024 14:29:05.472733 21201 layer_factory.hpp:77] Creating layer conv_in5a_1x1
I1024 14:29:05.472738 21201 net.cpp:91] Creating Layer conv_in5a_1x1
I1024 14:29:05.472739 21201 net.cpp:425] conv_in5a_1x1 <- ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split_0
I1024 14:29:05.472743 21201 net.cpp:399] conv_in5a_1x1 -> conv_in5a_1x1
I1024 14:29:05.472982 21201 net.cpp:141] Setting up conv_in5a_1x1
I1024 14:29:05.472986 21201 net.cpp:148] Top shape: 32 176 8 8 (360448)
I1024 14:29:05.472987 21201 net.cpp:156] Memory required for data: 336330880
I1024 14:29:05.472991 21201 layer_factory.hpp:77] Creating layer bn_in5a_1x1
I1024 14:29:05.472995 21201 net.cpp:91] Creating Layer bn_in5a_1x1
I1024 14:29:05.472996 21201 net.cpp:425] bn_in5a_1x1 <- conv_in5a_1x1
I1024 14:29:05.472999 21201 net.cpp:399] bn_in5a_1x1 -> bn_in5a_1x1
I1024 14:29:05.473161 21201 net.cpp:141] Setting up bn_in5a_1x1
I1024 14:29:05.473165 21201 net.cpp:148] Top shape: 32 176 8 8 (360448)
I1024 14:29:05.473167 21201 net.cpp:156] Memory required for data: 337772672
I1024 14:29:05.473171 21201 layer_factory.hpp:77] Creating layer relu_in5a_1x1
I1024 14:29:05.473175 21201 net.cpp:91] Creating Layer relu_in5a_1x1
I1024 14:29:05.473176 21201 net.cpp:425] relu_in5a_1x1 <- bn_in5a_1x1
I1024 14:29:05.473179 21201 net.cpp:386] relu_in5a_1x1 -> bn_in5a_1x1 (in-place)
I1024 14:29:05.473183 21201 net.cpp:141] Setting up relu_in5a_1x1
I1024 14:29:05.473186 21201 net.cpp:148] Top shape: 32 176 8 8 (360448)
I1024 14:29:05.473187 21201 net.cpp:156] Memory required for data: 339214464
I1024 14:29:05.473189 21201 layer_factory.hpp:77] Creating layer conv_in5a_3x3
I1024 14:29:05.473193 21201 net.cpp:91] Creating Layer conv_in5a_3x3
I1024 14:29:05.473196 21201 net.cpp:425] conv_in5a_3x3 <- ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split_1
I1024 14:29:05.473199 21201 net.cpp:399] conv_in5a_3x3 -> conv_in5a_3x3
I1024 14:29:05.474819 21201 net.cpp:141] Setting up conv_in5a_3x3
I1024 14:29:05.474826 21201 net.cpp:148] Top shape: 32 160 8 8 (327680)
I1024 14:29:05.474833 21201 net.cpp:156] Memory required for data: 340525184
I1024 14:29:05.474838 21201 layer_factory.hpp:77] Creating layer bn_in5a_3x3
I1024 14:29:05.474843 21201 net.cpp:91] Creating Layer bn_in5a_3x3
I1024 14:29:05.474844 21201 net.cpp:425] bn_in5a_3x3 <- conv_in5a_3x3
I1024 14:29:05.474848 21201 net.cpp:399] bn_in5a_3x3 -> bn_in5a_3x3
I1024 14:29:05.475016 21201 net.cpp:141] Setting up bn_in5a_3x3
I1024 14:29:05.475020 21201 net.cpp:148] Top shape: 32 160 8 8 (327680)
I1024 14:29:05.475023 21201 net.cpp:156] Memory required for data: 341835904
I1024 14:29:05.475028 21201 layer_factory.hpp:77] Creating layer relu_in5a_3x3
I1024 14:29:05.475030 21201 net.cpp:91] Creating Layer relu_in5a_3x3
I1024 14:29:05.475033 21201 net.cpp:425] relu_in5a_3x3 <- bn_in5a_3x3
I1024 14:29:05.475035 21201 net.cpp:386] relu_in5a_3x3 -> bn_in5a_3x3 (in-place)
I1024 14:29:05.475039 21201 net.cpp:141] Setting up relu_in5a_3x3
I1024 14:29:05.475042 21201 net.cpp:148] Top shape: 32 160 8 8 (327680)
I1024 14:29:05.475044 21201 net.cpp:156] Memory required for data: 343146624
I1024 14:29:05.475045 21201 layer_factory.hpp:77] Creating layer ch_concat_in5a_chconcat
I1024 14:29:05.475049 21201 net.cpp:91] Creating Layer ch_concat_in5a_chconcat
I1024 14:29:05.475050 21201 net.cpp:425] ch_concat_in5a_chconcat <- bn_in5a_1x1
I1024 14:29:05.475052 21201 net.cpp:425] ch_concat_in5a_chconcat <- bn_in5a_3x3
I1024 14:29:05.475055 21201 net.cpp:399] ch_concat_in5a_chconcat -> ch_concat_in5a_chconcat
I1024 14:29:05.475075 21201 net.cpp:141] Setting up ch_concat_in5a_chconcat
I1024 14:29:05.475078 21201 net.cpp:148] Top shape: 32 336 8 8 (688128)
I1024 14:29:05.475080 21201 net.cpp:156] Memory required for data: 345899136
I1024 14:29:05.475082 21201 layer_factory.hpp:77] Creating layer ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split
I1024 14:29:05.475085 21201 net.cpp:91] Creating Layer ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split
I1024 14:29:05.475087 21201 net.cpp:425] ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split <- ch_concat_in5a_chconcat
I1024 14:29:05.475090 21201 net.cpp:399] ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split -> ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split_0
I1024 14:29:05.475095 21201 net.cpp:399] ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split -> ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split_1
I1024 14:29:05.475116 21201 net.cpp:141] Setting up ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split
I1024 14:29:05.475118 21201 net.cpp:148] Top shape: 32 336 8 8 (688128)
I1024 14:29:05.475121 21201 net.cpp:148] Top shape: 32 336 8 8 (688128)
I1024 14:29:05.475122 21201 net.cpp:156] Memory required for data: 351404160
I1024 14:29:05.475124 21201 layer_factory.hpp:77] Creating layer conv_in5b_1x1
I1024 14:29:05.475129 21201 net.cpp:91] Creating Layer conv_in5b_1x1
I1024 14:29:05.475131 21201 net.cpp:425] conv_in5b_1x1 <- ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split_0
I1024 14:29:05.475134 21201 net.cpp:399] conv_in5b_1x1 -> conv_in5b_1x1
I1024 14:29:05.475459 21201 net.cpp:141] Setting up conv_in5b_1x1
I1024 14:29:05.475463 21201 net.cpp:148] Top shape: 32 176 8 8 (360448)
I1024 14:29:05.475466 21201 net.cpp:156] Memory required for data: 352845952
I1024 14:29:05.475468 21201 layer_factory.hpp:77] Creating layer bn_in5b_1x1
I1024 14:29:05.475471 21201 net.cpp:91] Creating Layer bn_in5b_1x1
I1024 14:29:05.475474 21201 net.cpp:425] bn_in5b_1x1 <- conv_in5b_1x1
I1024 14:29:05.475477 21201 net.cpp:399] bn_in5b_1x1 -> bn_in5b_1x1
I1024 14:29:05.475642 21201 net.cpp:141] Setting up bn_in5b_1x1
I1024 14:29:05.475646 21201 net.cpp:148] Top shape: 32 176 8 8 (360448)
I1024 14:29:05.475648 21201 net.cpp:156] Memory required for data: 354287744
I1024 14:29:05.475652 21201 layer_factory.hpp:77] Creating layer relu_in5b_1x1
I1024 14:29:05.475656 21201 net.cpp:91] Creating Layer relu_in5b_1x1
I1024 14:29:05.475657 21201 net.cpp:425] relu_in5b_1x1 <- bn_in5b_1x1
I1024 14:29:05.475659 21201 net.cpp:386] relu_in5b_1x1 -> bn_in5b_1x1 (in-place)
I1024 14:29:05.475667 21201 net.cpp:141] Setting up relu_in5b_1x1
I1024 14:29:05.475670 21201 net.cpp:148] Top shape: 32 176 8 8 (360448)
I1024 14:29:05.475672 21201 net.cpp:156] Memory required for data: 355729536
I1024 14:29:05.475674 21201 layer_factory.hpp:77] Creating layer conv_in5b_3x3
I1024 14:29:05.475678 21201 net.cpp:91] Creating Layer conv_in5b_3x3
I1024 14:29:05.475682 21201 net.cpp:425] conv_in5b_3x3 <- ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split_1
I1024 14:29:05.475685 21201 net.cpp:399] conv_in5b_3x3 -> conv_in5b_3x3
I1024 14:29:05.477807 21201 net.cpp:141] Setting up conv_in5b_3x3
I1024 14:29:05.477815 21201 net.cpp:148] Top shape: 32 160 8 8 (327680)
I1024 14:29:05.477818 21201 net.cpp:156] Memory required for data: 357040256
I1024 14:29:05.477820 21201 layer_factory.hpp:77] Creating layer bn_in5b_3x3
I1024 14:29:05.477824 21201 net.cpp:91] Creating Layer bn_in5b_3x3
I1024 14:29:05.477826 21201 net.cpp:425] bn_in5b_3x3 <- conv_in5b_3x3
I1024 14:29:05.477830 21201 net.cpp:399] bn_in5b_3x3 -> bn_in5b_3x3
I1024 14:29:05.477999 21201 net.cpp:141] Setting up bn_in5b_3x3
I1024 14:29:05.478003 21201 net.cpp:148] Top shape: 32 160 8 8 (327680)
I1024 14:29:05.478005 21201 net.cpp:156] Memory required for data: 358350976
I1024 14:29:05.478010 21201 layer_factory.hpp:77] Creating layer relu_in5b_3x3
I1024 14:29:05.478014 21201 net.cpp:91] Creating Layer relu_in5b_3x3
I1024 14:29:05.478018 21201 net.cpp:425] relu_in5b_3x3 <- bn_in5b_3x3
I1024 14:29:05.478019 21201 net.cpp:386] relu_in5b_3x3 -> bn_in5b_3x3 (in-place)
I1024 14:29:05.478022 21201 net.cpp:141] Setting up relu_in5b_3x3
I1024 14:29:05.478025 21201 net.cpp:148] Top shape: 32 160 8 8 (327680)
I1024 14:29:05.478027 21201 net.cpp:156] Memory required for data: 359661696
I1024 14:29:05.478029 21201 layer_factory.hpp:77] Creating layer ch_concat_in5b_chconcat
I1024 14:29:05.478032 21201 net.cpp:91] Creating Layer ch_concat_in5b_chconcat
I1024 14:29:05.478034 21201 net.cpp:425] ch_concat_in5b_chconcat <- bn_in5b_1x1
I1024 14:29:05.478037 21201 net.cpp:425] ch_concat_in5b_chconcat <- bn_in5b_3x3
I1024 14:29:05.478040 21201 net.cpp:399] ch_concat_in5b_chconcat -> ch_concat_in5b_chconcat
I1024 14:29:05.478054 21201 net.cpp:141] Setting up ch_concat_in5b_chconcat
I1024 14:29:05.478056 21201 net.cpp:148] Top shape: 32 336 8 8 (688128)
I1024 14:29:05.478058 21201 net.cpp:156] Memory required for data: 362414208
I1024 14:29:05.478060 21201 layer_factory.hpp:77] Creating layer global_pool
I1024 14:29:05.478063 21201 net.cpp:91] Creating Layer global_pool
I1024 14:29:05.478065 21201 net.cpp:425] global_pool <- ch_concat_in5b_chconcat
I1024 14:29:05.478070 21201 net.cpp:399] global_pool -> global_pool
I1024 14:29:05.478082 21201 net.cpp:141] Setting up global_pool
I1024 14:29:05.478085 21201 net.cpp:148] Top shape: 32 336 2 2 (43008)
I1024 14:29:05.478086 21201 net.cpp:156] Memory required for data: 362586240
I1024 14:29:05.478088 21201 layer_factory.hpp:77] Creating layer fc1
I1024 14:29:05.478093 21201 net.cpp:91] Creating Layer fc1
I1024 14:29:05.478096 21201 net.cpp:425] fc1 <- global_pool
I1024 14:29:05.478098 21201 net.cpp:399] fc1 -> fc1
I1024 14:29:05.478202 21201 net.cpp:141] Setting up fc1
I1024 14:29:05.478206 21201 net.cpp:148] Top shape: 32 10 (320)
I1024 14:29:05.478209 21201 net.cpp:156] Memory required for data: 362587520
I1024 14:29:05.478211 21201 layer_factory.hpp:77] Creating layer accuracy
I1024 14:29:05.478215 21201 net.cpp:91] Creating Layer accuracy
I1024 14:29:05.478217 21201 net.cpp:425] accuracy <- fc1
I1024 14:29:05.478219 21201 net.cpp:425] accuracy <- label
I1024 14:29:05.478222 21201 net.cpp:399] accuracy -> accuracy
I1024 14:29:05.478227 21201 net.cpp:141] Setting up accuracy
I1024 14:29:05.478229 21201 net.cpp:148] Top shape: (1)
I1024 14:29:05.478231 21201 net.cpp:156] Memory required for data: 362587524
I1024 14:29:05.478233 21201 net.cpp:219] accuracy does not need backward computation.
I1024 14:29:05.478235 21201 net.cpp:219] fc1 does not need backward computation.
I1024 14:29:05.478237 21201 net.cpp:219] global_pool does not need backward computation.
I1024 14:29:05.478245 21201 net.cpp:219] ch_concat_in5b_chconcat does not need backward computation.
I1024 14:29:05.478247 21201 net.cpp:219] relu_in5b_3x3 does not need backward computation.
I1024 14:29:05.478250 21201 net.cpp:219] bn_in5b_3x3 does not need backward computation.
I1024 14:29:05.478252 21201 net.cpp:219] conv_in5b_3x3 does not need backward computation.
I1024 14:29:05.478255 21201 net.cpp:219] relu_in5b_1x1 does not need backward computation.
I1024 14:29:05.478257 21201 net.cpp:219] bn_in5b_1x1 does not need backward computation.
I1024 14:29:05.478260 21201 net.cpp:219] conv_in5b_1x1 does not need backward computation.
I1024 14:29:05.478261 21201 net.cpp:219] ch_concat_in5a_chconcat_ch_concat_in5a_chconcat_0_split does not need backward computation.
I1024 14:29:05.478263 21201 net.cpp:219] ch_concat_in5a_chconcat does not need backward computation.
I1024 14:29:05.478266 21201 net.cpp:219] relu_in5a_3x3 does not need backward computation.
I1024 14:29:05.478268 21201 net.cpp:219] bn_in5a_3x3 does not need backward computation.
I1024 14:29:05.478271 21201 net.cpp:219] conv_in5a_3x3 does not need backward computation.
I1024 14:29:05.478272 21201 net.cpp:219] relu_in5a_1x1 does not need backward computation.
I1024 14:29:05.478273 21201 net.cpp:219] bn_in5a_1x1 does not need backward computation.
I1024 14:29:05.478276 21201 net.cpp:219] conv_in5a_1x1 does not need backward computation.
I1024 14:29:05.478278 21201 net.cpp:219] ch_concat_in4e_chconcat_ch_concat_in4e_chconcat_0_split does not need backward computation.
I1024 14:29:05.478281 21201 net.cpp:219] ch_concat_in4e_chconcat does not need backward computation.
I1024 14:29:05.478282 21201 net.cpp:219] max_pool_in4e_pool does not need backward computation.
I1024 14:29:05.478284 21201 net.cpp:219] relu_in4e_3x3 does not need backward computation.
I1024 14:29:05.478286 21201 net.cpp:219] bn_in4e_3x3 does not need backward computation.
I1024 14:29:05.478288 21201 net.cpp:219] conv_in4e_3x3 does not need backward computation.
I1024 14:29:05.478291 21201 net.cpp:219] ch_concat_in4d_chconcat_ch_concat_in4d_chconcat_0_split does not need backward computation.
I1024 14:29:05.478292 21201 net.cpp:219] ch_concat_in4d_chconcat does not need backward computation.
I1024 14:29:05.478296 21201 net.cpp:219] relu_in4d_3x3 does not need backward computation.
I1024 14:29:05.478296 21201 net.cpp:219] bn_in4d_3x3 does not need backward computation.
I1024 14:29:05.478298 21201 net.cpp:219] conv_in4d_3x3 does not need backward computation.
I1024 14:29:05.478302 21201 net.cpp:219] relu_in4d_1x1 does not need backward computation.
I1024 14:29:05.478303 21201 net.cpp:219] bn_in4d_1x1 does not need backward computation.
I1024 14:29:05.478305 21201 net.cpp:219] conv_in4d_1x1 does not need backward computation.
I1024 14:29:05.478307 21201 net.cpp:219] ch_concat_in4c_chconcat_ch_concat_in4c_chconcat_0_split does not need backward computation.
I1024 14:29:05.478309 21201 net.cpp:219] ch_concat_in4c_chconcat does not need backward computation.
I1024 14:29:05.478312 21201 net.cpp:219] relu_in4c_3x3 does not need backward computation.
I1024 14:29:05.478313 21201 net.cpp:219] bn_in4c_3x3 does not need backward computation.
I1024 14:29:05.478315 21201 net.cpp:219] conv_in4c_3x3 does not need backward computation.
I1024 14:29:05.478317 21201 net.cpp:219] relu_in4c_1x1 does not need backward computation.
I1024 14:29:05.478319 21201 net.cpp:219] bn_in4c_1x1 does not need backward computation.
I1024 14:29:05.478322 21201 net.cpp:219] conv_in4c_1x1 does not need backward computation.
I1024 14:29:05.478323 21201 net.cpp:219] ch_concat_in4b_chconcat_ch_concat_in4b_chconcat_0_split does not need backward computation.
I1024 14:29:05.478327 21201 net.cpp:219] ch_concat_in4b_chconcat does not need backward computation.
I1024 14:29:05.478328 21201 net.cpp:219] relu_in4b_3x3 does not need backward computation.
I1024 14:29:05.478330 21201 net.cpp:219] bn_in4b_3x3 does not need backward computation.
I1024 14:29:05.478332 21201 net.cpp:219] conv_in4b_3x3 does not need backward computation.
I1024 14:29:05.478338 21201 net.cpp:219] relu_in4b_1x1 does not need backward computation.
I1024 14:29:05.478339 21201 net.cpp:219] bn_in4b_1x1 does not need backward computation.
I1024 14:29:05.478341 21201 net.cpp:219] conv_in4b_1x1 does not need backward computation.
I1024 14:29:05.478343 21201 net.cpp:219] ch_concat_in4a_chconcat_ch_concat_in4a_chconcat_0_split does not need backward computation.
I1024 14:29:05.478346 21201 net.cpp:219] ch_concat_in4a_chconcat does not need backward computation.
I1024 14:29:05.478349 21201 net.cpp:219] relu_in4a_3x3 does not need backward computation.
I1024 14:29:05.478351 21201 net.cpp:219] bn_in4a_3x3 does not need backward computation.
I1024 14:29:05.478353 21201 net.cpp:219] conv_in4a_3x3 does not need backward computation.
I1024 14:29:05.478355 21201 net.cpp:219] relu_in4a_1x1 does not need backward computation.
I1024 14:29:05.478358 21201 net.cpp:219] bn_in4a_1x1 does not need backward computation.
I1024 14:29:05.478359 21201 net.cpp:219] conv_in4a_1x1 does not need backward computation.
I1024 14:29:05.478361 21201 net.cpp:219] ch_concat_in3c_chconcat_ch_concat_in3c_chconcat_0_split does not need backward computation.
I1024 14:29:05.478363 21201 net.cpp:219] ch_concat_in3c_chconcat does not need backward computation.
I1024 14:29:05.478366 21201 net.cpp:219] max_pool_in3c_pool does not need backward computation.
I1024 14:29:05.478368 21201 net.cpp:219] relu_in3c_3x3 does not need backward computation.
I1024 14:29:05.478370 21201 net.cpp:219] bn_in3c_3x3 does not need backward computation.
I1024 14:29:05.478372 21201 net.cpp:219] conv_in3c_3x3 does not need backward computation.
I1024 14:29:05.478374 21201 net.cpp:219] ch_concat_in3b_chconcat_ch_concat_in3b_chconcat_0_split does not need backward computation.
I1024 14:29:05.478377 21201 net.cpp:219] ch_concat_in3b_chconcat does not need backward computation.
I1024 14:29:05.478379 21201 net.cpp:219] relu_in3b_3x3 does not need backward computation.
I1024 14:29:05.478381 21201 net.cpp:219] bn_in3b_3x3 does not need backward computation.
I1024 14:29:05.478384 21201 net.cpp:219] conv_in3b_3x3 does not need backward computation.
I1024 14:29:05.478385 21201 net.cpp:219] relu_in3b_1x1 does not need backward computation.
I1024 14:29:05.478387 21201 net.cpp:219] bn_in3b_1x1 does not need backward computation.
I1024 14:29:05.478389 21201 net.cpp:219] conv_in3b_1x1 does not need backward computation.
I1024 14:29:05.478391 21201 net.cpp:219] ch_concat_in3a_chconcat_ch_concat_in3a_chconcat_0_split does not need backward computation.
I1024 14:29:05.478394 21201 net.cpp:219] ch_concat_in3a_chconcat does not need backward computation.
I1024 14:29:05.478395 21201 net.cpp:219] relu_in3a_3x3 does not need backward computation.
I1024 14:29:05.478399 21201 net.cpp:219] bn_in3a_3x3 does not need backward computation.
I1024 14:29:05.478400 21201 net.cpp:219] conv_in3a_3x3 does not need backward computation.
I1024 14:29:05.478402 21201 net.cpp:219] relu_in3a_1x1 does not need backward computation.
I1024 14:29:05.478404 21201 net.cpp:219] bn_in3a_1x1 does not need backward computation.
I1024 14:29:05.478406 21201 net.cpp:219] conv_in3a_1x1 does not need backward computation.
I1024 14:29:05.478408 21201 net.cpp:219] bn_conv1_relu_conv1_0_split does not need backward computation.
I1024 14:29:05.478410 21201 net.cpp:219] relu_conv1 does not need backward computation.
I1024 14:29:05.478412 21201 net.cpp:219] bn_conv1 does not need backward computation.
I1024 14:29:05.478415 21201 net.cpp:219] conv_conv1 does not need backward computation.
I1024 14:29:05.478417 21201 net.cpp:219] cifar does not need backward computation.
I1024 14:29:05.478418 21201 net.cpp:261] This network produces output accuracy
I1024 14:29:05.478451 21201 net.cpp:274] Network initialization done.
I1024 14:29:05.478564 21201 solver.cpp:60] Solver scaffolding done.
I1024 14:29:05.480981 21201 caffe.cpp:221] Starting Optimization
I1024 14:29:05.480988 21201 solver.cpp:279] Solving CIFAR10_quick
I1024 14:29:05.480989 21201 solver.cpp:280] Learning Rate Policy: fixed
I1024 14:29:05.666211 21201 solver.cpp:228] Iteration 0, loss = 2.34115
I1024 14:29:05.666244 21201 solver.cpp:244]     Train net output #0: loss = 2.34115 (* 1 = 2.34115 loss)
I1024 14:29:05.666249 21201 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1024 14:29:19.328162 21201 solver.cpp:228] Iteration 100, loss = 1.7188
I1024 14:29:19.328181 21201 solver.cpp:244]     Train net output #0: loss = 1.7188 (* 1 = 1.7188 loss)
I1024 14:29:19.328184 21201 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I1024 14:29:32.984652 21201 solver.cpp:228] Iteration 200, loss = 1.64358
I1024 14:29:32.984683 21201 solver.cpp:244]     Train net output #0: loss = 1.64358 (* 1 = 1.64358 loss)
I1024 14:29:32.984688 21201 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I1024 14:29:46.758730 21201 solver.cpp:228] Iteration 300, loss = 1.33278
I1024 14:29:46.758795 21201 solver.cpp:244]     Train net output #0: loss = 1.33278 (* 1 = 1.33278 loss)
I1024 14:29:46.758797 21201 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I1024 14:30:00.541503 21201 solver.cpp:228] Iteration 400, loss = 1.25588
I1024 14:30:00.541522 21201 solver.cpp:244]     Train net output #0: loss = 1.25588 (* 1 = 1.25588 loss)
I1024 14:30:00.541524 21201 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I1024 14:30:14.340389 21201 solver.cpp:228] Iteration 500, loss = 1.43634
I1024 14:30:14.340420 21201 solver.cpp:244]     Train net output #0: loss = 1.43634 (* 1 = 1.43634 loss)
I1024 14:30:14.340425 21201 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I1024 14:30:28.153734 21201 solver.cpp:228] Iteration 600, loss = 1.20581
I1024 14:30:28.153821 21201 solver.cpp:244]     Train net output #0: loss = 1.20581 (* 1 = 1.20581 loss)
I1024 14:30:28.153825 21201 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I1024 14:30:41.971092 21201 solver.cpp:228] Iteration 700, loss = 1.25355
I1024 14:30:41.971110 21201 solver.cpp:244]     Train net output #0: loss = 1.25355 (* 1 = 1.25355 loss)
I1024 14:30:41.971128 21201 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I1024 14:30:55.791332 21201 solver.cpp:228] Iteration 800, loss = 1.02021
I1024 14:30:55.791349 21201 solver.cpp:244]     Train net output #0: loss = 1.02021 (* 1 = 1.02021 loss)
I1024 14:30:55.791353 21201 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I1024 14:31:09.611222 21201 solver.cpp:228] Iteration 900, loss = 0.967674
I1024 14:31:09.611310 21201 solver.cpp:244]     Train net output #0: loss = 0.967674 (* 1 = 0.967674 loss)
I1024 14:31:09.611315 21201 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I1024 14:31:23.293992 21201 solver.cpp:337] Iteration 1000, Testing net (#0)
I1024 14:31:23.297152 21201 net.cpp:691] Ignoring source layer loss
I1024 14:31:26.098652 21201 solver.cpp:404]     Test net output #0: accuracy = 0.608373
I1024 14:31:26.235021 21201 solver.cpp:228] Iteration 1000, loss = 1.20183
I1024 14:31:26.235033 21201 solver.cpp:244]     Train net output #0: loss = 1.20183 (* 1 = 1.20183 loss)
I1024 14:31:26.235038 21201 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I1024 14:31:40.082634 21201 solver.cpp:228] Iteration 1100, loss = 1.01589
I1024 14:31:40.082695 21201 solver.cpp:244]     Train net output #0: loss = 1.01589 (* 1 = 1.01589 loss)
I1024 14:31:40.082698 21201 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I1024 14:31:53.924535 21201 solver.cpp:228] Iteration 1200, loss = 1.09488
I1024 14:31:53.924568 21201 solver.cpp:244]     Train net output #0: loss = 1.09488 (* 1 = 1.09488 loss)
I1024 14:31:53.924572 21201 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I1024 14:32:07.770833 21201 solver.cpp:228] Iteration 1300, loss = 0.875257
I1024 14:32:07.770865 21201 solver.cpp:244]     Train net output #0: loss = 0.875257 (* 1 = 0.875257 loss)
I1024 14:32:07.770869 21201 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I1024 14:32:21.612529 21201 solver.cpp:228] Iteration 1400, loss = 0.805741
I1024 14:32:21.612612 21201 solver.cpp:244]     Train net output #0: loss = 0.805741 (* 1 = 0.805741 loss)
I1024 14:32:21.612617 21201 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I1024 14:32:35.453442 21201 solver.cpp:228] Iteration 1500, loss = 1.04184
I1024 14:32:35.453459 21201 solver.cpp:244]     Train net output #0: loss = 1.04184 (* 1 = 1.04184 loss)
I1024 14:32:35.453478 21201 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I1024 14:32:49.291137 21201 solver.cpp:228] Iteration 1600, loss = 0.874285
I1024 14:32:49.291172 21201 solver.cpp:244]     Train net output #0: loss = 0.874285 (* 1 = 0.874285 loss)
I1024 14:32:49.291174 21201 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I1024 14:33:03.130517 21201 solver.cpp:228] Iteration 1700, loss = 0.977162
I1024 14:33:03.130609 21201 solver.cpp:244]     Train net output #0: loss = 0.977162 (* 1 = 0.977162 loss)
I1024 14:33:03.130614 21201 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I1024 14:33:16.971853 21201 solver.cpp:228] Iteration 1800, loss = 0.758654
I1024 14:33:16.971886 21201 solver.cpp:244]     Train net output #0: loss = 0.758654 (* 1 = 0.758654 loss)
I1024 14:33:16.971890 21201 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I1024 14:33:30.817865 21201 solver.cpp:228] Iteration 1900, loss = 0.710906
I1024 14:33:30.817883 21201 solver.cpp:244]     Train net output #0: loss = 0.710906 (* 1 = 0.710906 loss)
I1024 14:33:30.817888 21201 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I1024 14:33:44.522192 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_2000.caffemodel
I1024 14:33:44.540791 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_2000.solverstate
I1024 14:33:44.546713 21201 solver.cpp:337] Iteration 2000, Testing net (#0)
I1024 14:33:44.546766 21201 net.cpp:691] Ignoring source layer loss
I1024 14:33:47.343467 21201 solver.cpp:404]     Test net output #0: accuracy = 0.665264
I1024 14:33:47.479836 21201 solver.cpp:228] Iteration 2000, loss = 0.894057
I1024 14:33:47.479864 21201 solver.cpp:244]     Train net output #0: loss = 0.894057 (* 1 = 0.894057 loss)
I1024 14:33:47.479869 21201 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I1024 14:34:01.338135 21201 solver.cpp:228] Iteration 2100, loss = 0.725341
I1024 14:34:01.338153 21201 solver.cpp:244]     Train net output #0: loss = 0.725341 (* 1 = 0.725341 loss)
I1024 14:34:01.338157 21201 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I1024 14:34:15.197906 21201 solver.cpp:228] Iteration 2200, loss = 0.874276
I1024 14:34:15.197985 21201 solver.cpp:244]     Train net output #0: loss = 0.874276 (* 1 = 0.874276 loss)
I1024 14:34:15.197989 21201 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I1024 14:34:29.061262 21201 solver.cpp:228] Iteration 2300, loss = 0.667007
I1024 14:34:29.061281 21201 solver.cpp:244]     Train net output #0: loss = 0.667007 (* 1 = 0.667007 loss)
I1024 14:34:29.061285 21201 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I1024 14:34:42.917281 21201 solver.cpp:228] Iteration 2400, loss = 0.633433
I1024 14:34:42.917299 21201 solver.cpp:244]     Train net output #0: loss = 0.633433 (* 1 = 0.633433 loss)
I1024 14:34:42.917302 21201 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I1024 14:34:56.775305 21201 solver.cpp:228] Iteration 2500, loss = 0.772487
I1024 14:34:56.775378 21201 solver.cpp:244]     Train net output #0: loss = 0.772487 (* 1 = 0.772487 loss)
I1024 14:34:56.775382 21201 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I1024 14:35:10.635272 21201 solver.cpp:228] Iteration 2600, loss = 0.613383
I1024 14:35:10.635290 21201 solver.cpp:244]     Train net output #0: loss = 0.613383 (* 1 = 0.613383 loss)
I1024 14:35:10.635294 21201 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I1024 14:35:24.489389 21201 solver.cpp:228] Iteration 2700, loss = 0.758813
I1024 14:35:24.489408 21201 solver.cpp:244]     Train net output #0: loss = 0.758813 (* 1 = 0.758813 loss)
I1024 14:35:24.489411 21201 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I1024 14:35:38.346521 21201 solver.cpp:228] Iteration 2800, loss = 0.591231
I1024 14:35:38.346622 21201 solver.cpp:244]     Train net output #0: loss = 0.591231 (* 1 = 0.591231 loss)
I1024 14:35:38.346640 21201 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I1024 14:35:52.211607 21201 solver.cpp:228] Iteration 2900, loss = 0.574359
I1024 14:35:52.211628 21201 solver.cpp:244]     Train net output #0: loss = 0.574359 (* 1 = 0.574359 loss)
I1024 14:35:52.211632 21201 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I1024 14:36:05.938186 21201 solver.cpp:337] Iteration 3000, Testing net (#0)
I1024 14:36:05.938225 21201 net.cpp:691] Ignoring source layer loss
I1024 14:36:08.737704 21201 solver.cpp:404]     Test net output #0: accuracy = 0.708934
I1024 14:36:08.874045 21201 solver.cpp:228] Iteration 3000, loss = 0.673595
I1024 14:36:08.874071 21201 solver.cpp:244]     Train net output #0: loss = 0.673595 (* 1 = 0.673595 loss)
I1024 14:36:08.874075 21201 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I1024 14:36:22.736441 21201 solver.cpp:228] Iteration 3100, loss = 0.51171
I1024 14:36:22.736474 21201 solver.cpp:244]     Train net output #0: loss = 0.51171 (* 1 = 0.51171 loss)
I1024 14:36:22.736477 21201 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I1024 14:36:36.593118 21201 solver.cpp:228] Iteration 3200, loss = 0.65965
I1024 14:36:36.593138 21201 solver.cpp:244]     Train net output #0: loss = 0.65965 (* 1 = 0.65965 loss)
I1024 14:36:36.593142 21201 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I1024 14:36:50.453975 21201 solver.cpp:228] Iteration 3300, loss = 0.524259
I1024 14:36:50.454061 21201 solver.cpp:244]     Train net output #0: loss = 0.524259 (* 1 = 0.524259 loss)
I1024 14:36:50.454066 21201 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I1024 14:37:04.318105 21201 solver.cpp:228] Iteration 3400, loss = 0.503806
I1024 14:37:04.318127 21201 solver.cpp:244]     Train net output #0: loss = 0.503806 (* 1 = 0.503806 loss)
I1024 14:37:04.318131 21201 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I1024 14:37:18.170861 21201 solver.cpp:228] Iteration 3500, loss = 0.586139
I1024 14:37:18.170879 21201 solver.cpp:244]     Train net output #0: loss = 0.586139 (* 1 = 0.586139 loss)
I1024 14:37:18.170898 21201 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I1024 14:37:32.021479 21201 solver.cpp:228] Iteration 3600, loss = 0.447657
I1024 14:37:32.021551 21201 solver.cpp:244]     Train net output #0: loss = 0.447657 (* 1 = 0.447657 loss)
I1024 14:37:32.021555 21201 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I1024 14:37:45.875437 21201 solver.cpp:228] Iteration 3700, loss = 0.571538
I1024 14:37:45.875470 21201 solver.cpp:244]     Train net output #0: loss = 0.571538 (* 1 = 0.571538 loss)
I1024 14:37:45.875473 21201 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I1024 14:37:59.728170 21201 solver.cpp:228] Iteration 3800, loss = 0.447984
I1024 14:37:59.728204 21201 solver.cpp:244]     Train net output #0: loss = 0.447984 (* 1 = 0.447984 loss)
I1024 14:37:59.728209 21201 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I1024 14:38:13.580348 21201 solver.cpp:228] Iteration 3900, loss = 0.415054
I1024 14:38:13.580435 21201 solver.cpp:244]     Train net output #0: loss = 0.415054 (* 1 = 0.415054 loss)
I1024 14:38:13.580438 21201 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I1024 14:38:27.288101 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_4000.caffemodel
I1024 14:38:27.301564 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_4000.solverstate
I1024 14:38:27.307713 21201 solver.cpp:337] Iteration 4000, Testing net (#0)
I1024 14:38:27.307767 21201 net.cpp:691] Ignoring source layer loss
I1024 14:38:30.100404 21201 solver.cpp:404]     Test net output #0: accuracy = 0.717949
I1024 14:38:30.236510 21201 solver.cpp:228] Iteration 4000, loss = 0.484357
I1024 14:38:30.236521 21201 solver.cpp:244]     Train net output #0: loss = 0.484357 (* 1 = 0.484357 loss)
I1024 14:38:30.236526 21201 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I1024 14:38:44.088320 21201 solver.cpp:228] Iteration 4100, loss = 0.356262
I1024 14:38:44.088443 21201 solver.cpp:244]     Train net output #0: loss = 0.356262 (* 1 = 0.356262 loss)
I1024 14:38:44.088448 21201 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I1024 14:38:57.947496 21201 solver.cpp:228] Iteration 4200, loss = 0.492989
I1024 14:38:57.947515 21201 solver.cpp:244]     Train net output #0: loss = 0.492989 (* 1 = 0.492989 loss)
I1024 14:38:57.947518 21201 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I1024 14:39:11.800451 21201 solver.cpp:228] Iteration 4300, loss = 0.387948
I1024 14:39:11.800468 21201 solver.cpp:244]     Train net output #0: loss = 0.387948 (* 1 = 0.387948 loss)
I1024 14:39:11.800472 21201 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I1024 14:39:25.652957 21201 solver.cpp:228] Iteration 4400, loss = 0.323411
I1024 14:39:25.653030 21201 solver.cpp:244]     Train net output #0: loss = 0.323411 (* 1 = 0.323411 loss)
I1024 14:39:25.653034 21201 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I1024 14:39:39.508898 21201 solver.cpp:228] Iteration 4500, loss = 0.362446
I1024 14:39:39.508918 21201 solver.cpp:244]     Train net output #0: loss = 0.362446 (* 1 = 0.362446 loss)
I1024 14:39:39.508920 21201 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I1024 14:39:53.362687 21201 solver.cpp:228] Iteration 4600, loss = 0.278693
I1024 14:39:53.362706 21201 solver.cpp:244]     Train net output #0: loss = 0.278693 (* 1 = 0.278693 loss)
I1024 14:39:53.362710 21201 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I1024 14:40:07.218037 21201 solver.cpp:228] Iteration 4700, loss = 0.43073
I1024 14:40:07.218142 21201 solver.cpp:244]     Train net output #0: loss = 0.43073 (* 1 = 0.43073 loss)
I1024 14:40:07.218147 21201 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I1024 14:40:21.072819 21201 solver.cpp:228] Iteration 4800, loss = 0.327227
I1024 14:40:21.072852 21201 solver.cpp:244]     Train net output #0: loss = 0.327227 (* 1 = 0.327227 loss)
I1024 14:40:21.072856 21201 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I1024 14:40:34.930842 21201 solver.cpp:228] Iteration 4900, loss = 0.258893
I1024 14:40:34.930860 21201 solver.cpp:244]     Train net output #0: loss = 0.258893 (* 1 = 0.258893 loss)
I1024 14:40:34.930865 21201 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I1024 14:40:48.649118 21201 solver.cpp:337] Iteration 5000, Testing net (#0)
I1024 14:40:48.649235 21201 net.cpp:691] Ignoring source layer loss
I1024 14:40:51.446270 21201 solver.cpp:404]     Test net output #0: accuracy = 0.729167
I1024 14:40:51.582581 21201 solver.cpp:228] Iteration 5000, loss = 0.288094
I1024 14:40:51.582607 21201 solver.cpp:244]     Train net output #0: loss = 0.288094 (* 1 = 0.288094 loss)
I1024 14:40:51.582612 21201 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I1024 14:41:05.427569 21201 solver.cpp:228] Iteration 5100, loss = 0.241222
I1024 14:41:05.427587 21201 solver.cpp:244]     Train net output #0: loss = 0.241222 (* 1 = 0.241222 loss)
I1024 14:41:05.427592 21201 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
I1024 14:41:19.275167 21201 solver.cpp:228] Iteration 5200, loss = 0.329311
I1024 14:41:19.275250 21201 solver.cpp:244]     Train net output #0: loss = 0.329311 (* 1 = 0.329311 loss)
I1024 14:41:19.275267 21201 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I1024 14:41:33.128527 21201 solver.cpp:228] Iteration 5300, loss = 0.286704
I1024 14:41:33.128546 21201 solver.cpp:244]     Train net output #0: loss = 0.286704 (* 1 = 0.286704 loss)
I1024 14:41:33.128549 21201 sgd_solver.cpp:106] Iteration 5300, lr = 0.001
I1024 14:41:46.975867 21201 solver.cpp:228] Iteration 5400, loss = 0.193361
I1024 14:41:46.975885 21201 solver.cpp:244]     Train net output #0: loss = 0.193361 (* 1 = 0.193361 loss)
I1024 14:41:46.975888 21201 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I1024 14:42:00.831945 21201 solver.cpp:228] Iteration 5500, loss = 0.221469
I1024 14:42:00.832044 21201 solver.cpp:244]     Train net output #0: loss = 0.221469 (* 1 = 0.221469 loss)
I1024 14:42:00.832062 21201 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
I1024 14:42:14.687839 21201 solver.cpp:228] Iteration 5600, loss = 0.168269
I1024 14:42:14.687858 21201 solver.cpp:244]     Train net output #0: loss = 0.168269 (* 1 = 0.168269 loss)
I1024 14:42:14.687861 21201 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I1024 14:42:28.543954 21201 solver.cpp:228] Iteration 5700, loss = 0.293192
I1024 14:42:28.543972 21201 solver.cpp:244]     Train net output #0: loss = 0.293192 (* 1 = 0.293192 loss)
I1024 14:42:28.543977 21201 sgd_solver.cpp:106] Iteration 5700, lr = 0.001
I1024 14:42:42.400812 21201 solver.cpp:228] Iteration 5800, loss = 0.237319
I1024 14:42:42.400912 21201 solver.cpp:244]     Train net output #0: loss = 0.237319 (* 1 = 0.237319 loss)
I1024 14:42:42.400915 21201 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I1024 14:42:56.257462 21201 solver.cpp:228] Iteration 5900, loss = 0.156674
I1024 14:42:56.257481 21201 solver.cpp:244]     Train net output #0: loss = 0.156674 (* 1 = 0.156674 loss)
I1024 14:42:56.257484 21201 sgd_solver.cpp:106] Iteration 5900, lr = 0.001
I1024 14:43:09.977031 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_6000.caffemodel
I1024 14:43:09.990177 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_6000.solverstate
I1024 14:43:09.996162 21201 solver.cpp:337] Iteration 6000, Testing net (#0)
I1024 14:43:09.996248 21201 net.cpp:691] Ignoring source layer loss
I1024 14:43:12.790335 21201 solver.cpp:404]     Test net output #0: accuracy = 0.710737
I1024 14:43:12.926846 21201 solver.cpp:228] Iteration 6000, loss = 0.189916
I1024 14:43:12.926862 21201 solver.cpp:244]     Train net output #0: loss = 0.189916 (* 1 = 0.189916 loss)
I1024 14:43:12.926865 21201 sgd_solver.cpp:106] Iteration 6000, lr = 0.001
I1024 14:43:26.782935 21201 solver.cpp:228] Iteration 6100, loss = 0.164094
I1024 14:43:26.782953 21201 solver.cpp:244]     Train net output #0: loss = 0.164094 (* 1 = 0.164094 loss)
I1024 14:43:26.782958 21201 sgd_solver.cpp:106] Iteration 6100, lr = 0.001
I1024 14:43:40.640053 21201 solver.cpp:228] Iteration 6200, loss = 0.274159
I1024 14:43:40.640071 21201 solver.cpp:244]     Train net output #0: loss = 0.274159 (* 1 = 0.274159 loss)
I1024 14:43:40.640074 21201 sgd_solver.cpp:106] Iteration 6200, lr = 0.001
I1024 14:43:54.499574 21201 solver.cpp:228] Iteration 6300, loss = 0.217375
I1024 14:43:54.499691 21201 solver.cpp:244]     Train net output #0: loss = 0.217375 (* 1 = 0.217375 loss)
I1024 14:43:54.499694 21201 sgd_solver.cpp:106] Iteration 6300, lr = 0.001
I1024 14:44:08.357501 21201 solver.cpp:228] Iteration 6400, loss = 0.105554
I1024 14:44:08.357520 21201 solver.cpp:244]     Train net output #0: loss = 0.105554 (* 1 = 0.105554 loss)
I1024 14:44:08.357524 21201 sgd_solver.cpp:106] Iteration 6400, lr = 0.001
I1024 14:44:22.215135 21201 solver.cpp:228] Iteration 6500, loss = 0.191003
I1024 14:44:22.215153 21201 solver.cpp:244]     Train net output #0: loss = 0.191003 (* 1 = 0.191003 loss)
I1024 14:44:22.215157 21201 sgd_solver.cpp:106] Iteration 6500, lr = 0.001
I1024 14:44:36.073047 21201 solver.cpp:228] Iteration 6600, loss = 0.124188
I1024 14:44:36.073137 21201 solver.cpp:244]     Train net output #0: loss = 0.124188 (* 1 = 0.124188 loss)
I1024 14:44:36.073141 21201 sgd_solver.cpp:106] Iteration 6600, lr = 0.001
I1024 14:44:49.919766 21201 solver.cpp:228] Iteration 6700, loss = 0.381637
I1024 14:44:49.919785 21201 solver.cpp:244]     Train net output #0: loss = 0.381637 (* 1 = 0.381637 loss)
I1024 14:44:49.919788 21201 sgd_solver.cpp:106] Iteration 6700, lr = 0.001
I1024 14:45:03.773231 21201 solver.cpp:228] Iteration 6800, loss = 0.148399
I1024 14:45:03.773267 21201 solver.cpp:244]     Train net output #0: loss = 0.148399 (* 1 = 0.148399 loss)
I1024 14:45:03.773272 21201 sgd_solver.cpp:106] Iteration 6800, lr = 0.001
I1024 14:45:17.641551 21201 solver.cpp:228] Iteration 6900, loss = 0.131479
I1024 14:45:17.641621 21201 solver.cpp:244]     Train net output #0: loss = 0.131479 (* 1 = 0.131479 loss)
I1024 14:45:17.641625 21201 sgd_solver.cpp:106] Iteration 6900, lr = 0.001
I1024 14:45:31.365207 21201 solver.cpp:337] Iteration 7000, Testing net (#0)
I1024 14:45:31.365262 21201 net.cpp:691] Ignoring source layer loss
I1024 14:45:34.164963 21201 solver.cpp:404]     Test net output #0: accuracy = 0.729567
I1024 14:45:34.301379 21201 solver.cpp:228] Iteration 7000, loss = 0.171918
I1024 14:45:34.301393 21201 solver.cpp:244]     Train net output #0: loss = 0.171918 (* 1 = 0.171918 loss)
I1024 14:45:34.301396 21201 sgd_solver.cpp:106] Iteration 7000, lr = 0.001
I1024 14:45:48.165500 21201 solver.cpp:228] Iteration 7100, loss = 0.11513
I1024 14:45:48.165598 21201 solver.cpp:244]     Train net output #0: loss = 0.11513 (* 1 = 0.11513 loss)
I1024 14:45:48.165602 21201 sgd_solver.cpp:106] Iteration 7100, lr = 0.001
I1024 14:46:02.015462 21201 solver.cpp:228] Iteration 7200, loss = 0.136112
I1024 14:46:02.015480 21201 solver.cpp:244]     Train net output #0: loss = 0.136112 (* 1 = 0.136112 loss)
I1024 14:46:02.015483 21201 sgd_solver.cpp:106] Iteration 7200, lr = 0.001
I1024 14:46:15.868943 21201 solver.cpp:228] Iteration 7300, loss = 0.159263
I1024 14:46:15.868964 21201 solver.cpp:244]     Train net output #0: loss = 0.159263 (* 1 = 0.159263 loss)
I1024 14:46:15.868968 21201 sgd_solver.cpp:106] Iteration 7300, lr = 0.001
I1024 14:46:29.732131 21201 solver.cpp:228] Iteration 7400, loss = 0.0898467
I1024 14:46:29.732228 21201 solver.cpp:244]     Train net output #0: loss = 0.0898466 (* 1 = 0.0898466 loss)
I1024 14:46:29.732245 21201 sgd_solver.cpp:106] Iteration 7400, lr = 0.001
I1024 14:46:43.596222 21201 solver.cpp:228] Iteration 7500, loss = 0.111789
I1024 14:46:43.596240 21201 solver.cpp:244]     Train net output #0: loss = 0.111788 (* 1 = 0.111788 loss)
I1024 14:46:43.596243 21201 sgd_solver.cpp:106] Iteration 7500, lr = 0.001
I1024 14:46:57.457449 21201 solver.cpp:228] Iteration 7600, loss = 0.116311
I1024 14:46:57.457468 21201 solver.cpp:244]     Train net output #0: loss = 0.116311 (* 1 = 0.116311 loss)
I1024 14:46:57.457471 21201 sgd_solver.cpp:106] Iteration 7600, lr = 0.001
I1024 14:47:11.323966 21201 solver.cpp:228] Iteration 7700, loss = 0.230789
I1024 14:47:11.324064 21201 solver.cpp:244]     Train net output #0: loss = 0.230789 (* 1 = 0.230789 loss)
I1024 14:47:11.324069 21201 sgd_solver.cpp:106] Iteration 7700, lr = 0.001
I1024 14:47:25.178442 21201 solver.cpp:228] Iteration 7800, loss = 0.192167
I1024 14:47:25.178462 21201 solver.cpp:244]     Train net output #0: loss = 0.192167 (* 1 = 0.192167 loss)
I1024 14:47:25.178464 21201 sgd_solver.cpp:106] Iteration 7800, lr = 0.001
I1024 14:47:39.025522 21201 solver.cpp:228] Iteration 7900, loss = 0.141419
I1024 14:47:39.025542 21201 solver.cpp:244]     Train net output #0: loss = 0.141419 (* 1 = 0.141419 loss)
I1024 14:47:39.025544 21201 sgd_solver.cpp:106] Iteration 7900, lr = 0.001
I1024 14:47:52.740907 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_8000.caffemodel
I1024 14:47:52.754125 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_8000.solverstate
I1024 14:47:52.760109 21201 solver.cpp:337] Iteration 8000, Testing net (#0)
I1024 14:47:52.760193 21201 net.cpp:691] Ignoring source layer loss
I1024 14:47:55.554654 21201 solver.cpp:404]     Test net output #0: accuracy = 0.708333
I1024 14:47:55.690714 21201 solver.cpp:228] Iteration 8000, loss = 0.0926119
I1024 14:47:55.690727 21201 solver.cpp:244]     Train net output #0: loss = 0.0926118 (* 1 = 0.0926118 loss)
I1024 14:47:55.690732 21201 sgd_solver.cpp:106] Iteration 8000, lr = 0.001
I1024 14:48:09.542860 21201 solver.cpp:228] Iteration 8100, loss = 0.14297
I1024 14:48:09.542894 21201 solver.cpp:244]     Train net output #0: loss = 0.14297 (* 1 = 0.14297 loss)
I1024 14:48:09.542897 21201 sgd_solver.cpp:106] Iteration 8100, lr = 0.001
I1024 14:48:23.389784 21201 solver.cpp:228] Iteration 8200, loss = 0.0603216
I1024 14:48:23.389873 21201 solver.cpp:244]     Train net output #0: loss = 0.0603215 (* 1 = 0.0603215 loss)
I1024 14:48:23.389878 21201 sgd_solver.cpp:106] Iteration 8200, lr = 0.001
I1024 14:48:37.239011 21201 solver.cpp:228] Iteration 8300, loss = 0.220421
I1024 14:48:37.239029 21201 solver.cpp:244]     Train net output #0: loss = 0.220421 (* 1 = 0.220421 loss)
I1024 14:48:37.239032 21201 sgd_solver.cpp:106] Iteration 8300, lr = 0.001
I1024 14:48:51.090037 21201 solver.cpp:228] Iteration 8400, loss = 0.0537411
I1024 14:48:51.090070 21201 solver.cpp:244]     Train net output #0: loss = 0.0537411 (* 1 = 0.0537411 loss)
I1024 14:48:51.090075 21201 sgd_solver.cpp:106] Iteration 8400, lr = 0.001
I1024 14:49:04.940345 21201 solver.cpp:228] Iteration 8500, loss = 0.0710881
I1024 14:49:04.940454 21201 solver.cpp:244]     Train net output #0: loss = 0.0710881 (* 1 = 0.0710881 loss)
I1024 14:49:04.940470 21201 sgd_solver.cpp:106] Iteration 8500, lr = 0.001
I1024 14:49:18.789460 21201 solver.cpp:228] Iteration 8600, loss = 0.0624653
I1024 14:49:18.789479 21201 solver.cpp:244]     Train net output #0: loss = 0.0624652 (* 1 = 0.0624652 loss)
I1024 14:49:18.789481 21201 sgd_solver.cpp:106] Iteration 8600, lr = 0.001
I1024 14:49:32.642709 21201 solver.cpp:228] Iteration 8700, loss = 0.0908791
I1024 14:49:32.642743 21201 solver.cpp:244]     Train net output #0: loss = 0.090879 (* 1 = 0.090879 loss)
I1024 14:49:32.642747 21201 sgd_solver.cpp:106] Iteration 8700, lr = 0.001
I1024 14:49:46.502012 21201 solver.cpp:228] Iteration 8800, loss = 0.124421
I1024 14:49:46.502113 21201 solver.cpp:244]     Train net output #0: loss = 0.124421 (* 1 = 0.124421 loss)
I1024 14:49:46.502117 21201 sgd_solver.cpp:106] Iteration 8800, lr = 0.001
I1024 14:50:00.360723 21201 solver.cpp:228] Iteration 8900, loss = 0.0562226
I1024 14:50:00.360757 21201 solver.cpp:244]     Train net output #0: loss = 0.0562226 (* 1 = 0.0562226 loss)
I1024 14:50:00.360760 21201 sgd_solver.cpp:106] Iteration 8900, lr = 0.001
I1024 14:50:14.074348 21201 solver.cpp:337] Iteration 9000, Testing net (#0)
I1024 14:50:14.074401 21201 net.cpp:691] Ignoring source layer loss
I1024 14:50:16.875088 21201 solver.cpp:404]     Test net output #0: accuracy = 0.732372
I1024 14:50:17.011404 21201 solver.cpp:228] Iteration 9000, loss = 0.0450381
I1024 14:50:17.011417 21201 solver.cpp:244]     Train net output #0: loss = 0.045038 (* 1 = 0.045038 loss)
I1024 14:50:17.011422 21201 sgd_solver.cpp:106] Iteration 9000, lr = 0.001
I1024 14:50:30.868417 21201 solver.cpp:228] Iteration 9100, loss = 0.0618493
I1024 14:50:30.868435 21201 solver.cpp:244]     Train net output #0: loss = 0.0618492 (* 1 = 0.0618492 loss)
I1024 14:50:30.868438 21201 sgd_solver.cpp:106] Iteration 9100, lr = 0.001
I1024 14:50:44.727514 21201 solver.cpp:228] Iteration 9200, loss = 0.0646373
I1024 14:50:44.727532 21201 solver.cpp:244]     Train net output #0: loss = 0.0646372 (* 1 = 0.0646372 loss)
I1024 14:50:44.727535 21201 sgd_solver.cpp:106] Iteration 9200, lr = 0.001
I1024 14:50:58.586671 21201 solver.cpp:228] Iteration 9300, loss = 0.140045
I1024 14:50:58.586771 21201 solver.cpp:244]     Train net output #0: loss = 0.140045 (* 1 = 0.140045 loss)
I1024 14:50:58.586787 21201 sgd_solver.cpp:106] Iteration 9300, lr = 0.001
I1024 14:51:12.449833 21201 solver.cpp:228] Iteration 9400, loss = 0.0405349
I1024 14:51:12.449851 21201 solver.cpp:244]     Train net output #0: loss = 0.0405348 (* 1 = 0.0405348 loss)
I1024 14:51:12.449854 21201 sgd_solver.cpp:106] Iteration 9400, lr = 0.001
I1024 14:51:26.310256 21201 solver.cpp:228] Iteration 9500, loss = 0.0418854
I1024 14:51:26.310273 21201 solver.cpp:244]     Train net output #0: loss = 0.0418853 (* 1 = 0.0418853 loss)
I1024 14:51:26.310276 21201 sgd_solver.cpp:106] Iteration 9500, lr = 0.001
I1024 14:51:40.171095 21201 solver.cpp:228] Iteration 9600, loss = 0.0256664
I1024 14:51:40.171183 21201 solver.cpp:244]     Train net output #0: loss = 0.0256663 (* 1 = 0.0256663 loss)
I1024 14:51:40.171187 21201 sgd_solver.cpp:106] Iteration 9600, lr = 0.001
I1024 14:51:54.029644 21201 solver.cpp:228] Iteration 9700, loss = 0.0498008
I1024 14:51:54.029662 21201 solver.cpp:244]     Train net output #0: loss = 0.0498007 (* 1 = 0.0498007 loss)
I1024 14:51:54.029666 21201 sgd_solver.cpp:106] Iteration 9700, lr = 0.001
I1024 14:52:07.891067 21201 solver.cpp:228] Iteration 9800, loss = 0.0823013
I1024 14:52:07.891088 21201 solver.cpp:244]     Train net output #0: loss = 0.0823012 (* 1 = 0.0823012 loss)
I1024 14:52:07.891090 21201 sgd_solver.cpp:106] Iteration 9800, lr = 0.001
I1024 14:52:21.743644 21201 solver.cpp:228] Iteration 9900, loss = 0.0268519
I1024 14:52:21.743711 21201 solver.cpp:244]     Train net output #0: loss = 0.0268518 (* 1 = 0.0268518 loss)
I1024 14:52:21.743716 21201 sgd_solver.cpp:106] Iteration 9900, lr = 0.001
I1024 14:52:35.464888 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_10000.caffemodel
I1024 14:52:35.478199 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_10000.solverstate
I1024 14:52:35.484246 21201 solver.cpp:337] Iteration 10000, Testing net (#0)
I1024 14:52:35.484313 21201 net.cpp:691] Ignoring source layer loss
I1024 14:52:38.285362 21201 solver.cpp:404]     Test net output #0: accuracy = 0.727965
I1024 14:52:38.421731 21201 solver.cpp:228] Iteration 10000, loss = 0.0393795
I1024 14:52:38.421747 21201 solver.cpp:244]     Train net output #0: loss = 0.0393794 (* 1 = 0.0393794 loss)
I1024 14:52:38.421751 21201 sgd_solver.cpp:106] Iteration 10000, lr = 0.001
I1024 14:52:52.279114 21201 solver.cpp:228] Iteration 10100, loss = 0.0272409
I1024 14:52:52.279191 21201 solver.cpp:244]     Train net output #0: loss = 0.0272408 (* 1 = 0.0272408 loss)
I1024 14:52:52.279208 21201 sgd_solver.cpp:106] Iteration 10100, lr = 0.001
I1024 14:53:06.132020 21201 solver.cpp:228] Iteration 10200, loss = 0.0401741
I1024 14:53:06.132040 21201 solver.cpp:244]     Train net output #0: loss = 0.040174 (* 1 = 0.040174 loss)
I1024 14:53:06.132042 21201 sgd_solver.cpp:106] Iteration 10200, lr = 0.001
I1024 14:53:19.979200 21201 solver.cpp:228] Iteration 10300, loss = 0.0642397
I1024 14:53:19.979219 21201 solver.cpp:244]     Train net output #0: loss = 0.0642396 (* 1 = 0.0642396 loss)
I1024 14:53:19.979223 21201 sgd_solver.cpp:106] Iteration 10300, lr = 0.001
I1024 14:53:33.829771 21201 solver.cpp:228] Iteration 10400, loss = 0.0242527
I1024 14:53:33.829845 21201 solver.cpp:244]     Train net output #0: loss = 0.0242526 (* 1 = 0.0242526 loss)
I1024 14:53:33.829849 21201 sgd_solver.cpp:106] Iteration 10400, lr = 0.001
I1024 14:53:47.689364 21201 solver.cpp:228] Iteration 10500, loss = 0.0235418
I1024 14:53:47.689383 21201 solver.cpp:244]     Train net output #0: loss = 0.0235417 (* 1 = 0.0235417 loss)
I1024 14:53:47.689385 21201 sgd_solver.cpp:106] Iteration 10500, lr = 0.001
I1024 14:54:01.551971 21201 solver.cpp:228] Iteration 10600, loss = 0.0166985
I1024 14:54:01.551990 21201 solver.cpp:244]     Train net output #0: loss = 0.0166984 (* 1 = 0.0166984 loss)
I1024 14:54:01.551993 21201 sgd_solver.cpp:106] Iteration 10600, lr = 0.001
I1024 14:54:15.410921 21201 solver.cpp:228] Iteration 10700, loss = 0.0280423
I1024 14:54:15.411020 21201 solver.cpp:244]     Train net output #0: loss = 0.0280422 (* 1 = 0.0280422 loss)
I1024 14:54:15.411025 21201 sgd_solver.cpp:106] Iteration 10700, lr = 0.001
I1024 14:54:29.269706 21201 solver.cpp:228] Iteration 10800, loss = 0.0381803
I1024 14:54:29.269727 21201 solver.cpp:244]     Train net output #0: loss = 0.0381802 (* 1 = 0.0381802 loss)
I1024 14:54:29.269731 21201 sgd_solver.cpp:106] Iteration 10800, lr = 0.001
I1024 14:54:43.131553 21201 solver.cpp:228] Iteration 10900, loss = 0.018248
I1024 14:54:43.131570 21201 solver.cpp:244]     Train net output #0: loss = 0.0182479 (* 1 = 0.0182479 loss)
I1024 14:54:43.131573 21201 sgd_solver.cpp:106] Iteration 10900, lr = 0.001
I1024 14:54:56.851063 21201 solver.cpp:337] Iteration 11000, Testing net (#0)
I1024 14:54:56.851152 21201 net.cpp:691] Ignoring source layer loss
I1024 14:54:59.648716 21201 solver.cpp:404]     Test net output #0: accuracy = 0.748798
I1024 14:54:59.784799 21201 solver.cpp:228] Iteration 11000, loss = 0.00947955
I1024 14:54:59.784811 21201 solver.cpp:244]     Train net output #0: loss = 0.00947946 (* 1 = 0.00947946 loss)
I1024 14:54:59.784816 21201 sgd_solver.cpp:106] Iteration 11000, lr = 0.001
I1024 14:55:13.639888 21201 solver.cpp:228] Iteration 11100, loss = 0.0123489
I1024 14:55:13.639905 21201 solver.cpp:244]     Train net output #0: loss = 0.0123488 (* 1 = 0.0123488 loss)
I1024 14:55:13.639909 21201 sgd_solver.cpp:106] Iteration 11100, lr = 0.001
I1024 14:55:27.489130 21201 solver.cpp:228] Iteration 11200, loss = 0.0158156
I1024 14:55:27.489240 21201 solver.cpp:244]     Train net output #0: loss = 0.0158155 (* 1 = 0.0158155 loss)
I1024 14:55:27.489244 21201 sgd_solver.cpp:106] Iteration 11200, lr = 0.001
I1024 14:55:41.349889 21201 solver.cpp:228] Iteration 11300, loss = 0.0214653
I1024 14:55:41.349907 21201 solver.cpp:244]     Train net output #0: loss = 0.0214652 (* 1 = 0.0214652 loss)
I1024 14:55:41.349910 21201 sgd_solver.cpp:106] Iteration 11300, lr = 0.001
I1024 14:55:55.212103 21201 solver.cpp:228] Iteration 11400, loss = 0.00836201
I1024 14:55:55.212121 21201 solver.cpp:244]     Train net output #0: loss = 0.00836192 (* 1 = 0.00836192 loss)
I1024 14:55:55.212126 21201 sgd_solver.cpp:106] Iteration 11400, lr = 0.001
I1024 14:56:09.062656 21201 solver.cpp:228] Iteration 11500, loss = 0.00817928
I1024 14:56:09.062770 21201 solver.cpp:244]     Train net output #0: loss = 0.00817919 (* 1 = 0.00817919 loss)
I1024 14:56:09.062774 21201 sgd_solver.cpp:106] Iteration 11500, lr = 0.001
I1024 14:56:22.912600 21201 solver.cpp:228] Iteration 11600, loss = 0.00936867
I1024 14:56:22.912632 21201 solver.cpp:244]     Train net output #0: loss = 0.00936859 (* 1 = 0.00936859 loss)
I1024 14:56:22.912636 21201 sgd_solver.cpp:106] Iteration 11600, lr = 0.001
I1024 14:56:36.766034 21201 solver.cpp:228] Iteration 11700, loss = 0.0079359
I1024 14:56:36.766052 21201 solver.cpp:244]     Train net output #0: loss = 0.00793581 (* 1 = 0.00793581 loss)
I1024 14:56:36.766054 21201 sgd_solver.cpp:106] Iteration 11700, lr = 0.001
I1024 14:56:50.626220 21201 solver.cpp:228] Iteration 11800, loss = 0.0112555
I1024 14:56:50.626293 21201 solver.cpp:244]     Train net output #0: loss = 0.0112555 (* 1 = 0.0112555 loss)
I1024 14:56:50.626297 21201 sgd_solver.cpp:106] Iteration 11800, lr = 0.001
I1024 14:57:04.484773 21201 solver.cpp:228] Iteration 11900, loss = 0.00785889
I1024 14:57:04.484791 21201 solver.cpp:244]     Train net output #0: loss = 0.0078588 (* 1 = 0.0078588 loss)
I1024 14:57:04.484794 21201 sgd_solver.cpp:106] Iteration 11900, lr = 0.001
I1024 14:57:18.207530 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_12000.caffemodel
I1024 14:57:18.220896 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_12000.solverstate
I1024 14:57:18.226965 21201 solver.cpp:337] Iteration 12000, Testing net (#0)
I1024 14:57:18.227032 21201 net.cpp:691] Ignoring source layer loss
I1024 14:57:21.027045 21201 solver.cpp:404]     Test net output #0: accuracy = 0.742588
I1024 14:57:21.163264 21201 solver.cpp:228] Iteration 12000, loss = 0.00821473
I1024 14:57:21.163276 21201 solver.cpp:244]     Train net output #0: loss = 0.00821464 (* 1 = 0.00821464 loss)
I1024 14:57:21.163280 21201 sgd_solver.cpp:106] Iteration 12000, lr = 0.001
I1024 14:57:35.028182 21201 solver.cpp:228] Iteration 12100, loss = 0.0069156
I1024 14:57:35.028199 21201 solver.cpp:244]     Train net output #0: loss = 0.00691552 (* 1 = 0.00691552 loss)
I1024 14:57:35.028203 21201 sgd_solver.cpp:106] Iteration 12100, lr = 0.001
I1024 14:57:48.890220 21201 solver.cpp:228] Iteration 12200, loss = 0.00708895
I1024 14:57:48.890239 21201 solver.cpp:244]     Train net output #0: loss = 0.00708886 (* 1 = 0.00708886 loss)
I1024 14:57:48.890241 21201 sgd_solver.cpp:106] Iteration 12200, lr = 0.001
I1024 14:58:02.747730 21201 solver.cpp:228] Iteration 12300, loss = 0.00765063
I1024 14:58:02.747812 21201 solver.cpp:244]     Train net output #0: loss = 0.00765054 (* 1 = 0.00765054 loss)
I1024 14:58:02.747817 21201 sgd_solver.cpp:106] Iteration 12300, lr = 0.001
I1024 14:58:16.607957 21201 solver.cpp:228] Iteration 12400, loss = 0.00664679
I1024 14:58:16.607975 21201 solver.cpp:244]     Train net output #0: loss = 0.00664671 (* 1 = 0.00664671 loss)
I1024 14:58:16.607978 21201 sgd_solver.cpp:106] Iteration 12400, lr = 0.001
I1024 14:58:30.466405 21201 solver.cpp:228] Iteration 12500, loss = 0.00545342
I1024 14:58:30.466423 21201 solver.cpp:244]     Train net output #0: loss = 0.00545333 (* 1 = 0.00545333 loss)
I1024 14:58:30.466426 21201 sgd_solver.cpp:106] Iteration 12500, lr = 0.001
I1024 14:58:44.325119 21201 solver.cpp:228] Iteration 12600, loss = 0.00622415
I1024 14:58:44.325209 21201 solver.cpp:244]     Train net output #0: loss = 0.00622406 (* 1 = 0.00622406 loss)
I1024 14:58:44.325213 21201 sgd_solver.cpp:106] Iteration 12600, lr = 0.001
I1024 14:58:58.181321 21201 solver.cpp:228] Iteration 12700, loss = 0.00666802
I1024 14:58:58.181339 21201 solver.cpp:244]     Train net output #0: loss = 0.00666793 (* 1 = 0.00666793 loss)
I1024 14:58:58.181342 21201 sgd_solver.cpp:106] Iteration 12700, lr = 0.001
I1024 14:59:12.033476 21201 solver.cpp:228] Iteration 12800, loss = 0.00660217
I1024 14:59:12.033494 21201 solver.cpp:244]     Train net output #0: loss = 0.00660208 (* 1 = 0.00660208 loss)
I1024 14:59:12.033498 21201 sgd_solver.cpp:106] Iteration 12800, lr = 0.001
I1024 14:59:25.894392 21201 solver.cpp:228] Iteration 12900, loss = 0.00611779
I1024 14:59:25.894469 21201 solver.cpp:244]     Train net output #0: loss = 0.0061177 (* 1 = 0.0061177 loss)
I1024 14:59:25.894474 21201 sgd_solver.cpp:106] Iteration 12900, lr = 0.001
I1024 14:59:39.614524 21201 solver.cpp:337] Iteration 13000, Testing net (#0)
I1024 14:59:39.614576 21201 net.cpp:691] Ignoring source layer loss
I1024 14:59:42.412748 21201 solver.cpp:404]     Test net output #0: accuracy = 0.760417
I1024 14:59:42.549123 21201 solver.cpp:228] Iteration 13000, loss = 0.0051219
I1024 14:59:42.549134 21201 solver.cpp:244]     Train net output #0: loss = 0.00512181 (* 1 = 0.00512181 loss)
I1024 14:59:42.549139 21201 sgd_solver.cpp:106] Iteration 13000, lr = 0.001
I1024 14:59:56.407304 21201 solver.cpp:228] Iteration 13100, loss = 0.00595907
I1024 14:59:56.407385 21201 solver.cpp:244]     Train net output #0: loss = 0.00595899 (* 1 = 0.00595899 loss)
I1024 14:59:56.407403 21201 sgd_solver.cpp:106] Iteration 13100, lr = 0.001
I1024 15:00:10.267817 21201 solver.cpp:228] Iteration 13200, loss = 0.00647512
I1024 15:00:10.267835 21201 solver.cpp:244]     Train net output #0: loss = 0.00647503 (* 1 = 0.00647503 loss)
I1024 15:00:10.267838 21201 sgd_solver.cpp:106] Iteration 13200, lr = 0.001
I1024 15:00:24.128427 21201 solver.cpp:228] Iteration 13300, loss = 0.00619878
I1024 15:00:24.128445 21201 solver.cpp:244]     Train net output #0: loss = 0.00619869 (* 1 = 0.00619869 loss)
I1024 15:00:24.128449 21201 sgd_solver.cpp:106] Iteration 13300, lr = 0.001
I1024 15:00:37.987001 21201 solver.cpp:228] Iteration 13400, loss = 0.00586182
I1024 15:00:37.987097 21201 solver.cpp:244]     Train net output #0: loss = 0.00586173 (* 1 = 0.00586173 loss)
I1024 15:00:37.987114 21201 sgd_solver.cpp:106] Iteration 13400, lr = 0.001
I1024 15:00:51.847117 21201 solver.cpp:228] Iteration 13500, loss = 0.0050894
I1024 15:00:51.847149 21201 solver.cpp:244]     Train net output #0: loss = 0.00508932 (* 1 = 0.00508932 loss)
I1024 15:00:51.847152 21201 sgd_solver.cpp:106] Iteration 13500, lr = 0.001
I1024 15:01:05.709794 21201 solver.cpp:228] Iteration 13600, loss = 0.00587023
I1024 15:01:05.709812 21201 solver.cpp:244]     Train net output #0: loss = 0.00587015 (* 1 = 0.00587015 loss)
I1024 15:01:05.709816 21201 sgd_solver.cpp:106] Iteration 13600, lr = 0.001
I1024 15:01:19.569264 21201 solver.cpp:228] Iteration 13700, loss = 0.00637211
I1024 15:01:19.569334 21201 solver.cpp:244]     Train net output #0: loss = 0.00637202 (* 1 = 0.00637202 loss)
I1024 15:01:19.569339 21201 sgd_solver.cpp:106] Iteration 13700, lr = 0.001
I1024 15:01:33.432941 21201 solver.cpp:228] Iteration 13800, loss = 0.0059663
I1024 15:01:33.432960 21201 solver.cpp:244]     Train net output #0: loss = 0.00596621 (* 1 = 0.00596621 loss)
I1024 15:01:33.432965 21201 sgd_solver.cpp:106] Iteration 13800, lr = 0.001
I1024 15:01:47.289636 21201 solver.cpp:228] Iteration 13900, loss = 0.00578663
I1024 15:01:47.289654 21201 solver.cpp:244]     Train net output #0: loss = 0.00578655 (* 1 = 0.00578655 loss)
I1024 15:01:47.289657 21201 sgd_solver.cpp:106] Iteration 13900, lr = 0.001
I1024 15:02:01.008252 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_14000.caffemodel
I1024 15:02:01.021901 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_14000.solverstate
I1024 15:02:01.028077 21201 solver.cpp:337] Iteration 14000, Testing net (#0)
I1024 15:02:01.028131 21201 net.cpp:691] Ignoring source layer loss
I1024 15:02:03.825548 21201 solver.cpp:404]     Test net output #0: accuracy = 0.741186
I1024 15:02:03.961784 21201 solver.cpp:228] Iteration 14000, loss = 0.00511812
I1024 15:02:03.961797 21201 solver.cpp:244]     Train net output #0: loss = 0.00511803 (* 1 = 0.00511803 loss)
I1024 15:02:03.961802 21201 sgd_solver.cpp:106] Iteration 14000, lr = 0.001
I1024 15:02:17.819897 21201 solver.cpp:228] Iteration 14100, loss = 0.00587012
I1024 15:02:17.819914 21201 solver.cpp:244]     Train net output #0: loss = 0.00587003 (* 1 = 0.00587003 loss)
I1024 15:02:17.819918 21201 sgd_solver.cpp:106] Iteration 14100, lr = 0.001
I1024 15:02:31.678118 21201 solver.cpp:228] Iteration 14200, loss = 0.00638135
I1024 15:02:31.678189 21201 solver.cpp:244]     Train net output #0: loss = 0.00638127 (* 1 = 0.00638127 loss)
I1024 15:02:31.678194 21201 sgd_solver.cpp:106] Iteration 14200, lr = 0.001
I1024 15:02:45.534868 21201 solver.cpp:228] Iteration 14300, loss = 0.00592073
I1024 15:02:45.534886 21201 solver.cpp:244]     Train net output #0: loss = 0.00592064 (* 1 = 0.00592064 loss)
I1024 15:02:45.534889 21201 sgd_solver.cpp:106] Iteration 14300, lr = 0.001
I1024 15:02:59.394562 21201 solver.cpp:228] Iteration 14400, loss = 0.00581358
I1024 15:02:59.394579 21201 solver.cpp:244]     Train net output #0: loss = 0.00581349 (* 1 = 0.00581349 loss)
I1024 15:02:59.394583 21201 sgd_solver.cpp:106] Iteration 14400, lr = 0.001
I1024 15:03:13.249837 21201 solver.cpp:228] Iteration 14500, loss = 0.00523673
I1024 15:03:13.249907 21201 solver.cpp:244]     Train net output #0: loss = 0.00523664 (* 1 = 0.00523664 loss)
I1024 15:03:13.249912 21201 sgd_solver.cpp:106] Iteration 14500, lr = 0.001
I1024 15:03:27.108402 21201 solver.cpp:228] Iteration 14600, loss = 0.00595408
I1024 15:03:27.108419 21201 solver.cpp:244]     Train net output #0: loss = 0.00595399 (* 1 = 0.00595399 loss)
I1024 15:03:27.108423 21201 sgd_solver.cpp:106] Iteration 14600, lr = 0.001
I1024 15:03:40.966876 21201 solver.cpp:228] Iteration 14700, loss = 0.00644988
I1024 15:03:40.966894 21201 solver.cpp:244]     Train net output #0: loss = 0.00644979 (* 1 = 0.00644979 loss)
I1024 15:03:40.966897 21201 sgd_solver.cpp:106] Iteration 14700, lr = 0.001
I1024 15:03:54.825947 21201 solver.cpp:228] Iteration 14800, loss = 0.0059623
I1024 15:03:54.826035 21201 solver.cpp:244]     Train net output #0: loss = 0.00596222 (* 1 = 0.00596222 loss)
I1024 15:03:54.826040 21201 sgd_solver.cpp:106] Iteration 14800, lr = 0.001
I1024 15:04:08.686472 21201 solver.cpp:228] Iteration 14900, loss = 0.00582337
I1024 15:04:08.686491 21201 solver.cpp:244]     Train net output #0: loss = 0.00582328 (* 1 = 0.00582328 loss)
I1024 15:04:08.686493 21201 sgd_solver.cpp:106] Iteration 14900, lr = 0.001
I1024 15:04:22.409742 21201 solver.cpp:337] Iteration 15000, Testing net (#0)
I1024 15:04:22.409792 21201 net.cpp:691] Ignoring source layer loss
I1024 15:04:25.211367 21201 solver.cpp:404]     Test net output #0: accuracy = 0.755409
I1024 15:04:25.347525 21201 solver.cpp:228] Iteration 15000, loss = 0.00536339
I1024 15:04:25.347537 21201 solver.cpp:244]     Train net output #0: loss = 0.0053633 (* 1 = 0.0053633 loss)
I1024 15:04:25.347542 21201 sgd_solver.cpp:106] Iteration 15000, lr = 0.001
I1024 15:04:39.204125 21201 solver.cpp:228] Iteration 15100, loss = 0.00601531
I1024 15:04:39.204144 21201 solver.cpp:244]     Train net output #0: loss = 0.00601522 (* 1 = 0.00601522 loss)
I1024 15:04:39.204147 21201 sgd_solver.cpp:106] Iteration 15100, lr = 0.001
I1024 15:04:53.064770 21201 solver.cpp:228] Iteration 15200, loss = 0.00655328
I1024 15:04:53.064788 21201 solver.cpp:244]     Train net output #0: loss = 0.00655319 (* 1 = 0.00655319 loss)
I1024 15:04:53.064791 21201 sgd_solver.cpp:106] Iteration 15200, lr = 0.001
I1024 15:05:06.923817 21201 solver.cpp:228] Iteration 15300, loss = 0.00601082
I1024 15:05:06.923908 21201 solver.cpp:244]     Train net output #0: loss = 0.00601073 (* 1 = 0.00601073 loss)
I1024 15:05:06.923913 21201 sgd_solver.cpp:106] Iteration 15300, lr = 0.001
I1024 15:05:20.777415 21201 solver.cpp:228] Iteration 15400, loss = 0.00587749
I1024 15:05:20.777436 21201 solver.cpp:244]     Train net output #0: loss = 0.0058774 (* 1 = 0.0058774 loss)
I1024 15:05:20.777438 21201 sgd_solver.cpp:106] Iteration 15400, lr = 0.001
I1024 15:05:34.632414 21201 solver.cpp:228] Iteration 15500, loss = 0.00549416
I1024 15:05:34.632434 21201 solver.cpp:244]     Train net output #0: loss = 0.00549407 (* 1 = 0.00549407 loss)
I1024 15:05:34.632437 21201 sgd_solver.cpp:106] Iteration 15500, lr = 0.001
I1024 15:05:48.487783 21201 solver.cpp:228] Iteration 15600, loss = 0.00610744
I1024 15:05:48.487874 21201 solver.cpp:244]     Train net output #0: loss = 0.00610735 (* 1 = 0.00610735 loss)
I1024 15:05:48.487879 21201 sgd_solver.cpp:106] Iteration 15600, lr = 0.001
I1024 15:06:02.343253 21201 solver.cpp:228] Iteration 15700, loss = 0.00664969
I1024 15:06:02.343272 21201 solver.cpp:244]     Train net output #0: loss = 0.0066496 (* 1 = 0.0066496 loss)
I1024 15:06:02.343291 21201 sgd_solver.cpp:106] Iteration 15700, lr = 0.001
I1024 15:06:16.198781 21201 solver.cpp:228] Iteration 15800, loss = 0.00610151
I1024 15:06:16.198799 21201 solver.cpp:244]     Train net output #0: loss = 0.00610142 (* 1 = 0.00610142 loss)
I1024 15:06:16.198818 21201 sgd_solver.cpp:106] Iteration 15800, lr = 0.001
I1024 15:06:30.046962 21201 solver.cpp:228] Iteration 15900, loss = 0.00595588
I1024 15:06:30.047037 21201 solver.cpp:244]     Train net output #0: loss = 0.00595579 (* 1 = 0.00595579 loss)
I1024 15:06:30.047042 21201 sgd_solver.cpp:106] Iteration 15900, lr = 0.001
I1024 15:06:43.763456 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_16000.caffemodel
I1024 15:06:43.776872 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_16000.solverstate
I1024 15:06:43.782935 21201 solver.cpp:337] Iteration 16000, Testing net (#0)
I1024 15:06:43.783006 21201 net.cpp:691] Ignoring source layer loss
I1024 15:06:46.578764 21201 solver.cpp:404]     Test net output #0: accuracy = 0.739984
I1024 15:06:46.714982 21201 solver.cpp:228] Iteration 16000, loss = 0.00564724
I1024 15:06:46.714995 21201 solver.cpp:244]     Train net output #0: loss = 0.00564715 (* 1 = 0.00564715 loss)
I1024 15:06:46.714999 21201 sgd_solver.cpp:106] Iteration 16000, lr = 0.001
I1024 15:07:00.578434 21201 solver.cpp:228] Iteration 16100, loss = 0.00618631
I1024 15:07:00.578507 21201 solver.cpp:244]     Train net output #0: loss = 0.00618623 (* 1 = 0.00618623 loss)
I1024 15:07:00.578510 21201 sgd_solver.cpp:106] Iteration 16100, lr = 0.001
I1024 15:07:14.437582 21201 solver.cpp:228] Iteration 16200, loss = 0.00673837
I1024 15:07:14.437600 21201 solver.cpp:244]     Train net output #0: loss = 0.00673828 (* 1 = 0.00673828 loss)
I1024 15:07:14.437604 21201 sgd_solver.cpp:106] Iteration 16200, lr = 0.001
I1024 15:07:28.304010 21201 solver.cpp:228] Iteration 16300, loss = 0.00619482
I1024 15:07:28.304030 21201 solver.cpp:244]     Train net output #0: loss = 0.00619473 (* 1 = 0.00619473 loss)
I1024 15:07:28.304034 21201 sgd_solver.cpp:106] Iteration 16300, lr = 0.001
I1024 15:07:42.163697 21201 solver.cpp:228] Iteration 16400, loss = 0.00604569
I1024 15:07:42.163785 21201 solver.cpp:244]     Train net output #0: loss = 0.0060456 (* 1 = 0.0060456 loss)
I1024 15:07:42.163790 21201 sgd_solver.cpp:106] Iteration 16400, lr = 0.001
I1024 15:07:56.027469 21201 solver.cpp:228] Iteration 16500, loss = 0.00582401
I1024 15:07:56.027487 21201 solver.cpp:244]     Train net output #0: loss = 0.00582392 (* 1 = 0.00582392 loss)
I1024 15:07:56.027490 21201 sgd_solver.cpp:106] Iteration 16500, lr = 0.001
I1024 15:08:09.891141 21201 solver.cpp:228] Iteration 16600, loss = 0.00628066
I1024 15:08:09.891160 21201 solver.cpp:244]     Train net output #0: loss = 0.00628057 (* 1 = 0.00628057 loss)
I1024 15:08:09.891163 21201 sgd_solver.cpp:106] Iteration 16600, lr = 0.001
I1024 15:08:23.751209 21201 solver.cpp:228] Iteration 16700, loss = 0.00685299
I1024 15:08:23.751302 21201 solver.cpp:244]     Train net output #0: loss = 0.00685291 (* 1 = 0.00685291 loss)
I1024 15:08:23.751307 21201 sgd_solver.cpp:106] Iteration 16700, lr = 0.001
I1024 15:08:37.610229 21201 solver.cpp:228] Iteration 16800, loss = 0.00626771
I1024 15:08:37.610246 21201 solver.cpp:244]     Train net output #0: loss = 0.00626762 (* 1 = 0.00626762 loss)
I1024 15:08:37.610250 21201 sgd_solver.cpp:106] Iteration 16800, lr = 0.001
I1024 15:08:51.479187 21201 solver.cpp:228] Iteration 16900, loss = 0.00614037
I1024 15:08:51.479204 21201 solver.cpp:244]     Train net output #0: loss = 0.00614028 (* 1 = 0.00614028 loss)
I1024 15:08:51.479208 21201 sgd_solver.cpp:106] Iteration 16900, lr = 0.001
I1024 15:09:05.200193 21201 solver.cpp:337] Iteration 17000, Testing net (#0)
I1024 15:09:05.200289 21201 net.cpp:691] Ignoring source layer loss
I1024 15:09:08.004829 21201 solver.cpp:404]     Test net output #0: accuracy = 0.753205
I1024 15:09:08.140916 21201 solver.cpp:228] Iteration 17000, loss = 0.00596372
I1024 15:09:08.140930 21201 solver.cpp:244]     Train net output #0: loss = 0.00596363 (* 1 = 0.00596363 loss)
I1024 15:09:08.140933 21201 sgd_solver.cpp:106] Iteration 17000, lr = 0.001
I1024 15:09:22.001420 21201 solver.cpp:228] Iteration 17100, loss = 0.00636442
I1024 15:09:22.001440 21201 solver.cpp:244]     Train net output #0: loss = 0.00636433 (* 1 = 0.00636433 loss)
I1024 15:09:22.001443 21201 sgd_solver.cpp:106] Iteration 17100, lr = 0.001
I1024 15:09:35.864883 21201 solver.cpp:228] Iteration 17200, loss = 0.00691813
I1024 15:09:35.864989 21201 solver.cpp:244]     Train net output #0: loss = 0.00691804 (* 1 = 0.00691804 loss)
I1024 15:09:35.864994 21201 sgd_solver.cpp:106] Iteration 17200, lr = 0.001
I1024 15:09:49.722416 21201 solver.cpp:228] Iteration 17300, loss = 0.00630458
I1024 15:09:49.722435 21201 solver.cpp:244]     Train net output #0: loss = 0.0063045 (* 1 = 0.0063045 loss)
I1024 15:09:49.722438 21201 sgd_solver.cpp:106] Iteration 17300, lr = 0.001
I1024 15:10:03.584085 21201 solver.cpp:228] Iteration 17400, loss = 0.00624426
I1024 15:10:03.584105 21201 solver.cpp:244]     Train net output #0: loss = 0.00624417 (* 1 = 0.00624417 loss)
I1024 15:10:03.584108 21201 sgd_solver.cpp:106] Iteration 17400, lr = 0.001
I1024 15:10:17.443162 21201 solver.cpp:228] Iteration 17500, loss = 0.00608537
I1024 15:10:17.443259 21201 solver.cpp:244]     Train net output #0: loss = 0.00608528 (* 1 = 0.00608528 loss)
I1024 15:10:17.443264 21201 sgd_solver.cpp:106] Iteration 17500, lr = 0.001
I1024 15:10:31.303117 21201 solver.cpp:228] Iteration 17600, loss = 0.00642662
I1024 15:10:31.303134 21201 solver.cpp:244]     Train net output #0: loss = 0.00642653 (* 1 = 0.00642653 loss)
I1024 15:10:31.303138 21201 sgd_solver.cpp:106] Iteration 17600, lr = 0.001
I1024 15:10:45.162051 21201 solver.cpp:228] Iteration 17700, loss = 0.00701023
I1024 15:10:45.162070 21201 solver.cpp:244]     Train net output #0: loss = 0.00701014 (* 1 = 0.00701014 loss)
I1024 15:10:45.162072 21201 sgd_solver.cpp:106] Iteration 17700, lr = 0.001
I1024 15:10:59.019101 21201 solver.cpp:228] Iteration 17800, loss = 0.00638276
I1024 15:10:59.019191 21201 solver.cpp:244]     Train net output #0: loss = 0.00638268 (* 1 = 0.00638268 loss)
I1024 15:10:59.019208 21201 sgd_solver.cpp:106] Iteration 17800, lr = 0.001
I1024 15:11:12.878067 21201 solver.cpp:228] Iteration 17900, loss = 0.00630367
I1024 15:11:12.878085 21201 solver.cpp:244]     Train net output #0: loss = 0.00630358 (* 1 = 0.00630358 loss)
I1024 15:11:12.878088 21201 sgd_solver.cpp:106] Iteration 17900, lr = 0.001
I1024 15:11:26.602908 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_18000.caffemodel
I1024 15:11:26.616317 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_18000.solverstate
I1024 15:11:26.622567 21201 solver.cpp:337] Iteration 18000, Testing net (#0)
I1024 15:11:26.622637 21201 net.cpp:691] Ignoring source layer loss
I1024 15:11:29.438469 21201 solver.cpp:404]     Test net output #0: accuracy = 0.736779
I1024 15:11:29.574815 21201 solver.cpp:228] Iteration 18000, loss = 0.00624964
I1024 15:11:29.574826 21201 solver.cpp:244]     Train net output #0: loss = 0.00624955 (* 1 = 0.00624955 loss)
I1024 15:11:29.574831 21201 sgd_solver.cpp:106] Iteration 18000, lr = 0.001
I1024 15:11:43.433444 21201 solver.cpp:228] Iteration 18100, loss = 0.00646787
I1024 15:11:43.433463 21201 solver.cpp:244]     Train net output #0: loss = 0.00646778 (* 1 = 0.00646778 loss)
I1024 15:11:43.433466 21201 sgd_solver.cpp:106] Iteration 18100, lr = 0.001
I1024 15:11:57.291345 21201 solver.cpp:228] Iteration 18200, loss = 0.007084
I1024 15:11:57.291363 21201 solver.cpp:244]     Train net output #0: loss = 0.00708391 (* 1 = 0.00708391 loss)
I1024 15:11:57.291368 21201 sgd_solver.cpp:106] Iteration 18200, lr = 0.001
I1024 15:12:11.143231 21201 solver.cpp:228] Iteration 18300, loss = 0.00643703
I1024 15:12:11.143296 21201 solver.cpp:244]     Train net output #0: loss = 0.00643694 (* 1 = 0.00643694 loss)
I1024 15:12:11.143299 21201 sgd_solver.cpp:106] Iteration 18300, lr = 0.001
I1024 15:12:24.992388 21201 solver.cpp:228] Iteration 18400, loss = 0.00637731
I1024 15:12:24.992405 21201 solver.cpp:244]     Train net output #0: loss = 0.00637722 (* 1 = 0.00637722 loss)
I1024 15:12:24.992409 21201 sgd_solver.cpp:106] Iteration 18400, lr = 0.001
I1024 15:12:38.840276 21201 solver.cpp:228] Iteration 18500, loss = 0.00639092
I1024 15:12:38.840296 21201 solver.cpp:244]     Train net output #0: loss = 0.00639083 (* 1 = 0.00639083 loss)
I1024 15:12:38.840298 21201 sgd_solver.cpp:106] Iteration 18500, lr = 0.001
I1024 15:12:52.692661 21201 solver.cpp:228] Iteration 18600, loss = 0.00650139
I1024 15:12:52.692734 21201 solver.cpp:244]     Train net output #0: loss = 0.0065013 (* 1 = 0.0065013 loss)
I1024 15:12:52.692751 21201 sgd_solver.cpp:106] Iteration 18600, lr = 0.001
I1024 15:13:06.547920 21201 solver.cpp:228] Iteration 18700, loss = 0.007163
I1024 15:13:06.547940 21201 solver.cpp:244]     Train net output #0: loss = 0.00716291 (* 1 = 0.00716291 loss)
I1024 15:13:06.547943 21201 sgd_solver.cpp:106] Iteration 18700, lr = 0.001
I1024 15:13:20.403929 21201 solver.cpp:228] Iteration 18800, loss = 0.00648661
I1024 15:13:20.403947 21201 solver.cpp:244]     Train net output #0: loss = 0.00648652 (* 1 = 0.00648652 loss)
I1024 15:13:20.403950 21201 sgd_solver.cpp:106] Iteration 18800, lr = 0.001
I1024 15:13:34.259253 21201 solver.cpp:228] Iteration 18900, loss = 0.0064417
I1024 15:13:34.259292 21201 solver.cpp:244]     Train net output #0: loss = 0.00644162 (* 1 = 0.00644162 loss)
I1024 15:13:34.259296 21201 sgd_solver.cpp:106] Iteration 18900, lr = 0.001
I1024 15:13:47.977874 21201 solver.cpp:337] Iteration 19000, Testing net (#0)
I1024 15:13:47.977941 21201 net.cpp:691] Ignoring source layer loss
I1024 15:13:50.773881 21201 solver.cpp:404]     Test net output #0: accuracy = 0.752204
I1024 15:13:50.909979 21201 solver.cpp:228] Iteration 19000, loss = 0.00653195
I1024 15:13:50.910007 21201 solver.cpp:244]     Train net output #0: loss = 0.00653186 (* 1 = 0.00653186 loss)
I1024 15:13:50.910012 21201 sgd_solver.cpp:106] Iteration 19000, lr = 0.001
I1024 15:14:04.768187 21201 solver.cpp:228] Iteration 19100, loss = 0.00651562
I1024 15:14:04.768242 21201 solver.cpp:244]     Train net output #0: loss = 0.00651553 (* 1 = 0.00651553 loss)
I1024 15:14:04.768247 21201 sgd_solver.cpp:106] Iteration 19100, lr = 0.001
I1024 15:14:18.627285 21201 solver.cpp:228] Iteration 19200, loss = 0.00722054
I1024 15:14:18.627305 21201 solver.cpp:244]     Train net output #0: loss = 0.00722045 (* 1 = 0.00722045 loss)
I1024 15:14:18.627307 21201 sgd_solver.cpp:106] Iteration 19200, lr = 0.001
I1024 15:14:32.486650 21201 solver.cpp:228] Iteration 19300, loss = 0.00657726
I1024 15:14:32.486668 21201 solver.cpp:244]     Train net output #0: loss = 0.00657717 (* 1 = 0.00657717 loss)
I1024 15:14:32.486672 21201 sgd_solver.cpp:106] Iteration 19300, lr = 0.001
I1024 15:14:46.347213 21201 solver.cpp:228] Iteration 19400, loss = 0.00654449
I1024 15:14:46.347285 21201 solver.cpp:244]     Train net output #0: loss = 0.00654441 (* 1 = 0.00654441 loss)
I1024 15:14:46.347290 21201 sgd_solver.cpp:106] Iteration 19400, lr = 0.001
I1024 15:15:00.203256 21201 solver.cpp:228] Iteration 19500, loss = 0.00667573
I1024 15:15:00.203274 21201 solver.cpp:244]     Train net output #0: loss = 0.00667565 (* 1 = 0.00667565 loss)
I1024 15:15:00.203279 21201 sgd_solver.cpp:106] Iteration 19500, lr = 0.001
I1024 15:15:14.064038 21201 solver.cpp:228] Iteration 19600, loss = 0.00652588
I1024 15:15:14.064055 21201 solver.cpp:244]     Train net output #0: loss = 0.00652579 (* 1 = 0.00652579 loss)
I1024 15:15:14.064059 21201 sgd_solver.cpp:106] Iteration 19600, lr = 0.001
I1024 15:15:27.924623 21201 solver.cpp:228] Iteration 19700, loss = 0.00726002
I1024 15:15:27.924687 21201 solver.cpp:244]     Train net output #0: loss = 0.00725994 (* 1 = 0.00725994 loss)
I1024 15:15:27.924691 21201 sgd_solver.cpp:106] Iteration 19700, lr = 0.001
I1024 15:15:41.785259 21201 solver.cpp:228] Iteration 19800, loss = 0.00666463
I1024 15:15:41.785277 21201 solver.cpp:244]     Train net output #0: loss = 0.00666454 (* 1 = 0.00666454 loss)
I1024 15:15:41.785280 21201 sgd_solver.cpp:106] Iteration 19800, lr = 0.001
I1024 15:15:55.642122 21201 solver.cpp:228] Iteration 19900, loss = 0.00660681
I1024 15:15:55.642140 21201 solver.cpp:244]     Train net output #0: loss = 0.00660672 (* 1 = 0.00660672 loss)
I1024 15:15:55.642144 21201 sgd_solver.cpp:106] Iteration 19900, lr = 0.001
I1024 15:16:09.364284 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_20000.caffemodel
I1024 15:16:09.377705 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_20000.solverstate
I1024 15:16:09.383884 21201 solver.cpp:337] Iteration 20000, Testing net (#0)
I1024 15:16:09.383939 21201 net.cpp:691] Ignoring source layer loss
I1024 15:16:12.185497 21201 solver.cpp:404]     Test net output #0: accuracy = 0.739784
I1024 15:16:12.321720 21201 solver.cpp:228] Iteration 20000, loss = 0.00679606
I1024 15:16:12.321732 21201 solver.cpp:244]     Train net output #0: loss = 0.00679597 (* 1 = 0.00679597 loss)
I1024 15:16:12.321736 21201 sgd_solver.cpp:106] Iteration 20000, lr = 0.001
I1024 15:16:26.181777 21201 solver.cpp:228] Iteration 20100, loss = 0.00653712
I1024 15:16:26.181794 21201 solver.cpp:244]     Train net output #0: loss = 0.00653703 (* 1 = 0.00653703 loss)
I1024 15:16:26.181797 21201 sgd_solver.cpp:106] Iteration 20100, lr = 0.001
I1024 15:16:40.044684 21201 solver.cpp:228] Iteration 20200, loss = 0.00729244
I1024 15:16:40.044756 21201 solver.cpp:244]     Train net output #0: loss = 0.00729235 (* 1 = 0.00729235 loss)
I1024 15:16:40.044760 21201 sgd_solver.cpp:106] Iteration 20200, lr = 0.001
I1024 15:16:53.899210 21201 solver.cpp:228] Iteration 20300, loss = 0.0067504
I1024 15:16:53.899230 21201 solver.cpp:244]     Train net output #0: loss = 0.00675031 (* 1 = 0.00675031 loss)
I1024 15:16:53.899232 21201 sgd_solver.cpp:106] Iteration 20300, lr = 0.001
I1024 15:17:07.757225 21201 solver.cpp:228] Iteration 20400, loss = 0.00665663
I1024 15:17:07.757244 21201 solver.cpp:244]     Train net output #0: loss = 0.00665654 (* 1 = 0.00665654 loss)
I1024 15:17:07.757248 21201 sgd_solver.cpp:106] Iteration 20400, lr = 0.001
I1024 15:17:21.606359 21201 solver.cpp:228] Iteration 20500, loss = 0.0069048
I1024 15:17:21.606487 21201 solver.cpp:244]     Train net output #0: loss = 0.00690471 (* 1 = 0.00690471 loss)
I1024 15:17:21.606492 21201 sgd_solver.cpp:106] Iteration 20500, lr = 0.001
I1024 15:17:35.456781 21201 solver.cpp:228] Iteration 20600, loss = 0.00654734
I1024 15:17:35.456799 21201 solver.cpp:244]     Train net output #0: loss = 0.00654725 (* 1 = 0.00654725 loss)
I1024 15:17:35.456802 21201 sgd_solver.cpp:106] Iteration 20600, lr = 0.001
I1024 15:17:49.306787 21201 solver.cpp:228] Iteration 20700, loss = 0.00731897
I1024 15:17:49.306804 21201 solver.cpp:244]     Train net output #0: loss = 0.00731888 (* 1 = 0.00731888 loss)
I1024 15:17:49.306807 21201 sgd_solver.cpp:106] Iteration 20700, lr = 0.001
I1024 15:18:03.153439 21201 solver.cpp:228] Iteration 20800, loss = 0.00679669
I1024 15:18:03.153525 21201 solver.cpp:244]     Train net output #0: loss = 0.0067966 (* 1 = 0.0067966 loss)
I1024 15:18:03.153529 21201 sgd_solver.cpp:106] Iteration 20800, lr = 0.001
I1024 15:18:17.010532 21201 solver.cpp:228] Iteration 20900, loss = 0.00669392
I1024 15:18:17.010550 21201 solver.cpp:244]     Train net output #0: loss = 0.00669384 (* 1 = 0.00669384 loss)
I1024 15:18:17.010555 21201 sgd_solver.cpp:106] Iteration 20900, lr = 0.001
I1024 15:18:30.727118 21201 solver.cpp:337] Iteration 21000, Testing net (#0)
I1024 15:18:30.727170 21201 net.cpp:691] Ignoring source layer loss
I1024 15:18:33.532737 21201 solver.cpp:404]     Test net output #0: accuracy = 0.746394
I1024 15:18:33.668937 21201 solver.cpp:228] Iteration 21000, loss = 0.00698765
I1024 15:18:33.668948 21201 solver.cpp:244]     Train net output #0: loss = 0.00698756 (* 1 = 0.00698756 loss)
I1024 15:18:33.668952 21201 sgd_solver.cpp:106] Iteration 21000, lr = 0.001
I1024 15:18:47.525679 21201 solver.cpp:228] Iteration 21100, loss = 0.00656937
I1024 15:18:47.525698 21201 solver.cpp:244]     Train net output #0: loss = 0.00656929 (* 1 = 0.00656929 loss)
I1024 15:18:47.525701 21201 sgd_solver.cpp:106] Iteration 21100, lr = 0.001
I1024 15:19:01.381960 21201 solver.cpp:228] Iteration 21200, loss = 0.00735346
I1024 15:19:01.381979 21201 solver.cpp:244]     Train net output #0: loss = 0.00735337 (* 1 = 0.00735337 loss)
I1024 15:19:01.381983 21201 sgd_solver.cpp:106] Iteration 21200, lr = 0.001
I1024 15:19:15.243067 21201 solver.cpp:228] Iteration 21300, loss = 0.00682209
I1024 15:19:15.243140 21201 solver.cpp:244]     Train net output #0: loss = 0.006822 (* 1 = 0.006822 loss)
I1024 15:19:15.243145 21201 sgd_solver.cpp:106] Iteration 21300, lr = 0.001
I1024 15:19:29.103108 21201 solver.cpp:228] Iteration 21400, loss = 0.00673239
I1024 15:19:29.103127 21201 solver.cpp:244]     Train net output #0: loss = 0.0067323 (* 1 = 0.0067323 loss)
I1024 15:19:29.103129 21201 sgd_solver.cpp:106] Iteration 21400, lr = 0.001
I1024 15:19:42.961771 21201 solver.cpp:228] Iteration 21500, loss = 0.00706027
I1024 15:19:42.961791 21201 solver.cpp:244]     Train net output #0: loss = 0.00706018 (* 1 = 0.00706018 loss)
I1024 15:19:42.961793 21201 sgd_solver.cpp:106] Iteration 21500, lr = 0.001
I1024 15:19:56.825078 21201 solver.cpp:228] Iteration 21600, loss = 0.00659792
I1024 15:19:56.825147 21201 solver.cpp:244]     Train net output #0: loss = 0.00659783 (* 1 = 0.00659783 loss)
I1024 15:19:56.825165 21201 sgd_solver.cpp:106] Iteration 21600, lr = 0.001
I1024 15:20:10.687214 21201 solver.cpp:228] Iteration 21700, loss = 0.00738189
I1024 15:20:10.687233 21201 solver.cpp:244]     Train net output #0: loss = 0.0073818 (* 1 = 0.0073818 loss)
I1024 15:20:10.687237 21201 sgd_solver.cpp:106] Iteration 21700, lr = 0.001
I1024 15:20:24.547832 21201 solver.cpp:228] Iteration 21800, loss = 0.0068629
I1024 15:20:24.547850 21201 solver.cpp:244]     Train net output #0: loss = 0.00686281 (* 1 = 0.00686281 loss)
I1024 15:20:24.547854 21201 sgd_solver.cpp:106] Iteration 21800, lr = 0.001
I1024 15:20:38.412389 21201 solver.cpp:228] Iteration 21900, loss = 0.00679006
I1024 15:20:38.412478 21201 solver.cpp:244]     Train net output #0: loss = 0.00678998 (* 1 = 0.00678998 loss)
I1024 15:20:38.412482 21201 sgd_solver.cpp:106] Iteration 21900, lr = 0.001
I1024 15:20:52.137970 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_22000.caffemodel
I1024 15:20:52.154314 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_22000.solverstate
I1024 15:20:52.162189 21201 solver.cpp:337] Iteration 22000, Testing net (#0)
I1024 15:20:52.162259 21201 net.cpp:691] Ignoring source layer loss
I1024 15:20:54.965443 21201 solver.cpp:404]     Test net output #0: accuracy = 0.734976
I1024 15:20:55.101711 21201 solver.cpp:228] Iteration 22000, loss = 0.00712087
I1024 15:20:55.101723 21201 solver.cpp:244]     Train net output #0: loss = 0.00712078 (* 1 = 0.00712078 loss)
I1024 15:20:55.101727 21201 sgd_solver.cpp:106] Iteration 22000, lr = 0.001
I1024 15:21:08.962817 21201 solver.cpp:228] Iteration 22100, loss = 0.00659613
I1024 15:21:08.962891 21201 solver.cpp:244]     Train net output #0: loss = 0.00659604 (* 1 = 0.00659604 loss)
I1024 15:21:08.962895 21201 sgd_solver.cpp:106] Iteration 22100, lr = 0.001
I1024 15:21:22.824795 21201 solver.cpp:228] Iteration 22200, loss = 0.0073912
I1024 15:21:22.824812 21201 solver.cpp:244]     Train net output #0: loss = 0.00739111 (* 1 = 0.00739111 loss)
I1024 15:21:22.824816 21201 sgd_solver.cpp:106] Iteration 22200, lr = 0.001
I1024 15:21:36.685735 21201 solver.cpp:228] Iteration 22300, loss = 0.00686685
I1024 15:21:36.685753 21201 solver.cpp:244]     Train net output #0: loss = 0.00686677 (* 1 = 0.00686677 loss)
I1024 15:21:36.685756 21201 sgd_solver.cpp:106] Iteration 22300, lr = 0.001
I1024 15:21:50.543073 21201 solver.cpp:228] Iteration 22400, loss = 0.00678477
I1024 15:21:50.543160 21201 solver.cpp:244]     Train net output #0: loss = 0.00678468 (* 1 = 0.00678468 loss)
I1024 15:21:50.543164 21201 sgd_solver.cpp:106] Iteration 22400, lr = 0.001
I1024 15:22:04.406826 21201 solver.cpp:228] Iteration 22500, loss = 0.00715016
I1024 15:22:04.406846 21201 solver.cpp:244]     Train net output #0: loss = 0.00715007 (* 1 = 0.00715007 loss)
I1024 15:22:04.406848 21201 sgd_solver.cpp:106] Iteration 22500, lr = 0.001
I1024 15:22:18.263757 21201 solver.cpp:228] Iteration 22600, loss = 0.00660471
I1024 15:22:18.263775 21201 solver.cpp:244]     Train net output #0: loss = 0.00660463 (* 1 = 0.00660463 loss)
I1024 15:22:18.263778 21201 sgd_solver.cpp:106] Iteration 22600, lr = 0.001
I1024 15:22:32.125378 21201 solver.cpp:228] Iteration 22700, loss = 0.00738495
I1024 15:22:32.125473 21201 solver.cpp:244]     Train net output #0: loss = 0.00738486 (* 1 = 0.00738486 loss)
I1024 15:22:32.125478 21201 sgd_solver.cpp:106] Iteration 22700, lr = 0.001
I1024 15:22:45.979382 21201 solver.cpp:228] Iteration 22800, loss = 0.00688925
I1024 15:22:45.979399 21201 solver.cpp:244]     Train net output #0: loss = 0.00688916 (* 1 = 0.00688916 loss)
I1024 15:22:45.979403 21201 sgd_solver.cpp:106] Iteration 22800, lr = 0.001
I1024 15:22:59.838714 21201 solver.cpp:228] Iteration 22900, loss = 0.00680677
I1024 15:22:59.838732 21201 solver.cpp:244]     Train net output #0: loss = 0.00680668 (* 1 = 0.00680668 loss)
I1024 15:22:59.838735 21201 sgd_solver.cpp:106] Iteration 22900, lr = 0.001
I1024 15:23:13.561897 21201 solver.cpp:337] Iteration 23000, Testing net (#0)
I1024 15:23:13.561995 21201 net.cpp:691] Ignoring source layer loss
I1024 15:23:16.362681 21201 solver.cpp:404]     Test net output #0: accuracy = 0.750801
I1024 15:23:16.498874 21201 solver.cpp:228] Iteration 23000, loss = 0.00717781
I1024 15:23:16.498888 21201 solver.cpp:244]     Train net output #0: loss = 0.00717773 (* 1 = 0.00717773 loss)
I1024 15:23:16.498891 21201 sgd_solver.cpp:106] Iteration 23000, lr = 0.001
I1024 15:23:30.358098 21201 solver.cpp:228] Iteration 23100, loss = 0.00658144
I1024 15:23:30.358116 21201 solver.cpp:244]     Train net output #0: loss = 0.00658136 (* 1 = 0.00658136 loss)
I1024 15:23:30.358119 21201 sgd_solver.cpp:106] Iteration 23100, lr = 0.001
I1024 15:23:44.215500 21201 solver.cpp:228] Iteration 23200, loss = 0.00737372
I1024 15:23:44.215575 21201 solver.cpp:244]     Train net output #0: loss = 0.00737363 (* 1 = 0.00737363 loss)
I1024 15:23:44.215592 21201 sgd_solver.cpp:106] Iteration 23200, lr = 0.001
I1024 15:23:58.075163 21201 solver.cpp:228] Iteration 23300, loss = 0.00690202
I1024 15:23:58.075181 21201 solver.cpp:244]     Train net output #0: loss = 0.00690193 (* 1 = 0.00690193 loss)
I1024 15:23:58.075184 21201 sgd_solver.cpp:106] Iteration 23300, lr = 0.001
I1024 15:24:11.933085 21201 solver.cpp:228] Iteration 23400, loss = 0.00682647
I1024 15:24:11.933104 21201 solver.cpp:244]     Train net output #0: loss = 0.00682639 (* 1 = 0.00682639 loss)
I1024 15:24:11.933107 21201 sgd_solver.cpp:106] Iteration 23400, lr = 0.001
I1024 15:24:25.792958 21201 solver.cpp:228] Iteration 23500, loss = 0.00721994
I1024 15:24:25.793020 21201 solver.cpp:244]     Train net output #0: loss = 0.00721985 (* 1 = 0.00721985 loss)
I1024 15:24:25.793023 21201 sgd_solver.cpp:106] Iteration 23500, lr = 0.001
I1024 15:24:39.651509 21201 solver.cpp:228] Iteration 23600, loss = 0.00658524
I1024 15:24:39.651526 21201 solver.cpp:244]     Train net output #0: loss = 0.00658515 (* 1 = 0.00658515 loss)
I1024 15:24:39.651530 21201 sgd_solver.cpp:106] Iteration 23600, lr = 0.001
I1024 15:24:53.515854 21201 solver.cpp:228] Iteration 23700, loss = 0.00736568
I1024 15:24:53.515873 21201 solver.cpp:244]     Train net output #0: loss = 0.0073656 (* 1 = 0.0073656 loss)
I1024 15:24:53.515877 21201 sgd_solver.cpp:106] Iteration 23700, lr = 0.001
I1024 15:25:07.373212 21201 solver.cpp:228] Iteration 23800, loss = 0.00689985
I1024 15:25:07.373251 21201 solver.cpp:244]     Train net output #0: loss = 0.00689976 (* 1 = 0.00689976 loss)
I1024 15:25:07.373255 21201 sgd_solver.cpp:106] Iteration 23800, lr = 0.001
I1024 15:25:21.234480 21201 solver.cpp:228] Iteration 23900, loss = 0.00681897
I1024 15:25:21.234498 21201 solver.cpp:244]     Train net output #0: loss = 0.00681888 (* 1 = 0.00681888 loss)
I1024 15:25:21.234503 21201 sgd_solver.cpp:106] Iteration 23900, lr = 0.001
I1024 15:25:34.957906 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_24000.caffemodel
I1024 15:25:34.971215 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_24000.solverstate
I1024 15:25:34.977401 21201 solver.cpp:337] Iteration 24000, Testing net (#0)
I1024 15:25:34.977469 21201 net.cpp:691] Ignoring source layer loss
I1024 15:25:37.773517 21201 solver.cpp:404]     Test net output #0: accuracy = 0.736178
I1024 15:25:37.909565 21201 solver.cpp:228] Iteration 24000, loss = 0.007218
I1024 15:25:37.909577 21201 solver.cpp:244]     Train net output #0: loss = 0.00721792 (* 1 = 0.00721792 loss)
I1024 15:25:37.909581 21201 sgd_solver.cpp:106] Iteration 24000, lr = 0.001
I1024 15:25:51.766072 21201 solver.cpp:228] Iteration 24100, loss = 0.00659771
I1024 15:25:51.766093 21201 solver.cpp:244]     Train net output #0: loss = 0.00659763 (* 1 = 0.00659763 loss)
I1024 15:25:51.766110 21201 sgd_solver.cpp:106] Iteration 24100, lr = 0.001
I1024 15:26:05.631983 21201 solver.cpp:228] Iteration 24200, loss = 0.00734497
I1024 15:26:05.632001 21201 solver.cpp:244]     Train net output #0: loss = 0.00734488 (* 1 = 0.00734488 loss)
I1024 15:26:05.632005 21201 sgd_solver.cpp:106] Iteration 24200, lr = 0.001
I1024 15:26:19.493343 21201 solver.cpp:228] Iteration 24300, loss = 0.00690845
I1024 15:26:19.493429 21201 solver.cpp:244]     Train net output #0: loss = 0.00690836 (* 1 = 0.00690836 loss)
I1024 15:26:19.493433 21201 sgd_solver.cpp:106] Iteration 24300, lr = 0.001
I1024 15:26:33.349184 21201 solver.cpp:228] Iteration 24400, loss = 0.00686988
I1024 15:26:33.349203 21201 solver.cpp:244]     Train net output #0: loss = 0.00686979 (* 1 = 0.00686979 loss)
I1024 15:26:33.349221 21201 sgd_solver.cpp:106] Iteration 24400, lr = 0.001
I1024 15:26:47.210726 21201 solver.cpp:228] Iteration 24500, loss = 0.00721689
I1024 15:26:47.210745 21201 solver.cpp:244]     Train net output #0: loss = 0.0072168 (* 1 = 0.0072168 loss)
I1024 15:26:47.210749 21201 sgd_solver.cpp:106] Iteration 24500, lr = 0.001
I1024 15:27:01.071205 21201 solver.cpp:228] Iteration 24600, loss = 0.0066038
I1024 15:27:01.071322 21201 solver.cpp:244]     Train net output #0: loss = 0.00660371 (* 1 = 0.00660371 loss)
I1024 15:27:01.071326 21201 sgd_solver.cpp:106] Iteration 24600, lr = 0.001
I1024 15:27:14.933771 21201 solver.cpp:228] Iteration 24700, loss = 0.00736814
I1024 15:27:14.933789 21201 solver.cpp:244]     Train net output #0: loss = 0.00736805 (* 1 = 0.00736805 loss)
I1024 15:27:14.933794 21201 sgd_solver.cpp:106] Iteration 24700, lr = 0.001
I1024 15:27:28.798748 21201 solver.cpp:228] Iteration 24800, loss = 0.00688486
I1024 15:27:28.798766 21201 solver.cpp:244]     Train net output #0: loss = 0.00688477 (* 1 = 0.00688477 loss)
I1024 15:27:28.798770 21201 sgd_solver.cpp:106] Iteration 24800, lr = 0.001
I1024 15:27:42.656427 21201 solver.cpp:228] Iteration 24900, loss = 0.0068763
I1024 15:27:42.656488 21201 solver.cpp:244]     Train net output #0: loss = 0.00687621 (* 1 = 0.00687621 loss)
I1024 15:27:42.656492 21201 sgd_solver.cpp:106] Iteration 24900, lr = 0.001
I1024 15:27:56.375589 21201 solver.cpp:337] Iteration 25000, Testing net (#0)
I1024 15:27:56.375628 21201 net.cpp:691] Ignoring source layer loss
I1024 15:27:59.175675 21201 solver.cpp:404]     Test net output #0: accuracy = 0.741587
I1024 15:27:59.311830 21201 solver.cpp:228] Iteration 25000, loss = 0.00723288
I1024 15:27:59.311843 21201 solver.cpp:244]     Train net output #0: loss = 0.00723279 (* 1 = 0.00723279 loss)
I1024 15:27:59.311849 21201 sgd_solver.cpp:106] Iteration 25000, lr = 0.001
I1024 15:28:13.173589 21201 solver.cpp:228] Iteration 25100, loss = 0.00661174
I1024 15:28:13.173650 21201 solver.cpp:244]     Train net output #0: loss = 0.00661166 (* 1 = 0.00661166 loss)
I1024 15:28:13.173655 21201 sgd_solver.cpp:106] Iteration 25100, lr = 0.001
I1024 15:28:27.023080 21201 solver.cpp:228] Iteration 25200, loss = 0.00732508
I1024 15:28:27.023098 21201 solver.cpp:244]     Train net output #0: loss = 0.00732499 (* 1 = 0.00732499 loss)
I1024 15:28:27.023102 21201 sgd_solver.cpp:106] Iteration 25200, lr = 0.001
I1024 15:28:40.876088 21201 solver.cpp:228] Iteration 25300, loss = 0.00685744
I1024 15:28:40.876106 21201 solver.cpp:244]     Train net output #0: loss = 0.00685735 (* 1 = 0.00685735 loss)
I1024 15:28:40.876111 21201 sgd_solver.cpp:106] Iteration 25300, lr = 0.001
I1024 15:28:54.725638 21201 solver.cpp:228] Iteration 25400, loss = 0.00686496
I1024 15:28:54.725735 21201 solver.cpp:244]     Train net output #0: loss = 0.00686487 (* 1 = 0.00686487 loss)
I1024 15:28:54.725751 21201 sgd_solver.cpp:106] Iteration 25400, lr = 0.001
I1024 15:29:08.582590 21201 solver.cpp:228] Iteration 25500, loss = 0.00722193
I1024 15:29:08.582609 21201 solver.cpp:244]     Train net output #0: loss = 0.00722184 (* 1 = 0.00722184 loss)
I1024 15:29:08.582628 21201 sgd_solver.cpp:106] Iteration 25500, lr = 0.001
I1024 15:29:22.439924 21201 solver.cpp:228] Iteration 25600, loss = 0.00659517
I1024 15:29:22.439941 21201 solver.cpp:244]     Train net output #0: loss = 0.00659508 (* 1 = 0.00659508 loss)
I1024 15:29:22.439960 21201 sgd_solver.cpp:106] Iteration 25600, lr = 0.001
I1024 15:29:36.297940 21201 solver.cpp:228] Iteration 25700, loss = 0.00731588
I1024 15:29:36.297993 21201 solver.cpp:244]     Train net output #0: loss = 0.00731579 (* 1 = 0.00731579 loss)
I1024 15:29:36.297997 21201 sgd_solver.cpp:106] Iteration 25700, lr = 0.001
I1024 15:29:50.160652 21201 solver.cpp:228] Iteration 25800, loss = 0.00686343
I1024 15:29:50.160670 21201 solver.cpp:244]     Train net output #0: loss = 0.00686334 (* 1 = 0.00686334 loss)
I1024 15:29:50.160675 21201 sgd_solver.cpp:106] Iteration 25800, lr = 0.001
I1024 15:30:04.020514 21201 solver.cpp:228] Iteration 25900, loss = 0.00681301
I1024 15:30:04.020536 21201 solver.cpp:244]     Train net output #0: loss = 0.00681292 (* 1 = 0.00681292 loss)
I1024 15:30:04.020540 21201 sgd_solver.cpp:106] Iteration 25900, lr = 0.001
I1024 15:30:17.747236 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_26000.caffemodel
I1024 15:30:17.760690 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_26000.solverstate
I1024 15:30:17.766721 21201 solver.cpp:337] Iteration 26000, Testing net (#0)
I1024 15:30:17.766790 21201 net.cpp:691] Ignoring source layer loss
I1024 15:30:20.566363 21201 solver.cpp:404]     Test net output #0: accuracy = 0.732372
I1024 15:30:20.702435 21201 solver.cpp:228] Iteration 26000, loss = 0.00719477
I1024 15:30:20.702447 21201 solver.cpp:244]     Train net output #0: loss = 0.00719468 (* 1 = 0.00719468 loss)
I1024 15:30:20.702452 21201 sgd_solver.cpp:106] Iteration 26000, lr = 0.001
I1024 15:30:34.565979 21201 solver.cpp:228] Iteration 26100, loss = 0.00659041
I1024 15:30:34.565997 21201 solver.cpp:244]     Train net output #0: loss = 0.00659033 (* 1 = 0.00659033 loss)
I1024 15:30:34.566000 21201 sgd_solver.cpp:106] Iteration 26100, lr = 0.001
I1024 15:30:48.431280 21201 solver.cpp:228] Iteration 26200, loss = 0.00730156
I1024 15:30:48.431366 21201 solver.cpp:244]     Train net output #0: loss = 0.00730147 (* 1 = 0.00730147 loss)
I1024 15:30:48.431371 21201 sgd_solver.cpp:106] Iteration 26200, lr = 0.001
I1024 15:31:02.294905 21201 solver.cpp:228] Iteration 26300, loss = 0.00683374
I1024 15:31:02.294924 21201 solver.cpp:244]     Train net output #0: loss = 0.00683365 (* 1 = 0.00683365 loss)
I1024 15:31:02.294927 21201 sgd_solver.cpp:106] Iteration 26300, lr = 0.001
I1024 15:31:16.157296 21201 solver.cpp:228] Iteration 26400, loss = 0.00685041
I1024 15:31:16.157317 21201 solver.cpp:244]     Train net output #0: loss = 0.00685032 (* 1 = 0.00685032 loss)
I1024 15:31:16.157336 21201 sgd_solver.cpp:106] Iteration 26400, lr = 0.001
I1024 15:31:30.019130 21201 solver.cpp:228] Iteration 26500, loss = 0.00721331
I1024 15:31:30.019201 21201 solver.cpp:244]     Train net output #0: loss = 0.00721322 (* 1 = 0.00721322 loss)
I1024 15:31:30.019207 21201 sgd_solver.cpp:106] Iteration 26500, lr = 0.001
I1024 15:31:43.878851 21201 solver.cpp:228] Iteration 26600, loss = 0.00659834
I1024 15:31:43.878870 21201 solver.cpp:244]     Train net output #0: loss = 0.00659825 (* 1 = 0.00659825 loss)
I1024 15:31:43.878872 21201 sgd_solver.cpp:106] Iteration 26600, lr = 0.001
I1024 15:31:57.738286 21201 solver.cpp:228] Iteration 26700, loss = 0.00729658
I1024 15:31:57.738303 21201 solver.cpp:244]     Train net output #0: loss = 0.00729649 (* 1 = 0.00729649 loss)
I1024 15:31:57.738306 21201 sgd_solver.cpp:106] Iteration 26700, lr = 0.001
I1024 15:32:11.597553 21201 solver.cpp:228] Iteration 26800, loss = 0.00681646
I1024 15:32:11.597636 21201 solver.cpp:244]     Train net output #0: loss = 0.00681637 (* 1 = 0.00681637 loss)
I1024 15:32:11.597640 21201 sgd_solver.cpp:106] Iteration 26800, lr = 0.001
I1024 15:32:25.457412 21201 solver.cpp:228] Iteration 26900, loss = 0.00686114
I1024 15:32:25.457429 21201 solver.cpp:244]     Train net output #0: loss = 0.00686105 (* 1 = 0.00686105 loss)
I1024 15:32:25.457432 21201 sgd_solver.cpp:106] Iteration 26900, lr = 0.001
I1024 15:32:39.176627 21201 solver.cpp:337] Iteration 27000, Testing net (#0)
I1024 15:32:39.176678 21201 net.cpp:691] Ignoring source layer loss
I1024 15:32:41.996670 21201 solver.cpp:404]     Test net output #0: accuracy = 0.743389
I1024 15:32:42.132822 21201 solver.cpp:228] Iteration 27000, loss = 0.00723318
I1024 15:32:42.132833 21201 solver.cpp:244]     Train net output #0: loss = 0.00723309 (* 1 = 0.00723309 loss)
I1024 15:32:42.132838 21201 sgd_solver.cpp:106] Iteration 27000, lr = 0.001
I1024 15:32:55.991299 21201 solver.cpp:228] Iteration 27100, loss = 0.00661847
I1024 15:32:55.991317 21201 solver.cpp:244]     Train net output #0: loss = 0.00661838 (* 1 = 0.00661838 loss)
I1024 15:32:55.991320 21201 sgd_solver.cpp:106] Iteration 27100, lr = 0.001
I1024 15:33:09.850216 21201 solver.cpp:228] Iteration 27200, loss = 0.00730533
I1024 15:33:09.850234 21201 solver.cpp:244]     Train net output #0: loss = 0.00730524 (* 1 = 0.00730524 loss)
I1024 15:33:09.850237 21201 sgd_solver.cpp:106] Iteration 27200, lr = 0.001
I1024 15:33:23.709103 21201 solver.cpp:228] Iteration 27300, loss = 0.00678178
I1024 15:33:23.709190 21201 solver.cpp:244]     Train net output #0: loss = 0.00678169 (* 1 = 0.00678169 loss)
I1024 15:33:23.709194 21201 sgd_solver.cpp:106] Iteration 27300, lr = 0.001
I1024 15:33:37.561095 21201 solver.cpp:228] Iteration 27400, loss = 0.00685982
I1024 15:33:37.561113 21201 solver.cpp:244]     Train net output #0: loss = 0.00685973 (* 1 = 0.00685973 loss)
I1024 15:33:37.561117 21201 sgd_solver.cpp:106] Iteration 27400, lr = 0.001
I1024 15:33:51.423147 21201 solver.cpp:228] Iteration 27500, loss = 0.00726428
I1024 15:33:51.423166 21201 solver.cpp:244]     Train net output #0: loss = 0.00726419 (* 1 = 0.00726419 loss)
I1024 15:33:51.423171 21201 sgd_solver.cpp:106] Iteration 27500, lr = 0.001
I1024 15:34:05.290314 21201 solver.cpp:228] Iteration 27600, loss = 0.00663852
I1024 15:34:05.290383 21201 solver.cpp:244]     Train net output #0: loss = 0.00663843 (* 1 = 0.00663843 loss)
I1024 15:34:05.290387 21201 sgd_solver.cpp:106] Iteration 27600, lr = 0.001
I1024 15:34:19.149593 21201 solver.cpp:228] Iteration 27700, loss = 0.00730223
I1024 15:34:19.149611 21201 solver.cpp:244]     Train net output #0: loss = 0.00730214 (* 1 = 0.00730214 loss)
I1024 15:34:19.149615 21201 sgd_solver.cpp:106] Iteration 27700, lr = 0.001
I1024 15:34:33.011879 21201 solver.cpp:228] Iteration 27800, loss = 0.00675909
I1024 15:34:33.011898 21201 solver.cpp:244]     Train net output #0: loss = 0.006759 (* 1 = 0.006759 loss)
I1024 15:34:33.011916 21201 sgd_solver.cpp:106] Iteration 27800, lr = 0.001
I1024 15:34:46.873710 21201 solver.cpp:228] Iteration 27900, loss = 0.00686544
I1024 15:34:46.873750 21201 solver.cpp:244]     Train net output #0: loss = 0.00686536 (* 1 = 0.00686536 loss)
I1024 15:34:46.873754 21201 sgd_solver.cpp:106] Iteration 27900, lr = 0.001
I1024 15:35:00.594787 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_28000.caffemodel
I1024 15:35:00.607982 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_28000.solverstate
I1024 15:35:00.614051 21201 solver.cpp:337] Iteration 28000, Testing net (#0)
I1024 15:35:00.614120 21201 net.cpp:691] Ignoring source layer loss
I1024 15:35:03.410270 21201 solver.cpp:404]     Test net output #0: accuracy = 0.727965
I1024 15:35:03.546444 21201 solver.cpp:228] Iteration 28000, loss = 0.00729711
I1024 15:35:03.546456 21201 solver.cpp:244]     Train net output #0: loss = 0.00729702 (* 1 = 0.00729702 loss)
I1024 15:35:03.546459 21201 sgd_solver.cpp:106] Iteration 28000, lr = 0.001
I1024 15:35:17.410622 21201 solver.cpp:228] Iteration 28100, loss = 0.00667806
I1024 15:35:17.410701 21201 solver.cpp:244]     Train net output #0: loss = 0.00667797 (* 1 = 0.00667797 loss)
I1024 15:35:17.410704 21201 sgd_solver.cpp:106] Iteration 28100, lr = 0.001
I1024 15:35:31.271839 21201 solver.cpp:228] Iteration 28200, loss = 0.00722457
I1024 15:35:31.271857 21201 solver.cpp:244]     Train net output #0: loss = 0.00722449 (* 1 = 0.00722449 loss)
I1024 15:35:31.271862 21201 sgd_solver.cpp:106] Iteration 28200, lr = 0.001
I1024 15:35:45.133641 21201 solver.cpp:228] Iteration 28300, loss = 0.00672177
I1024 15:35:45.133674 21201 solver.cpp:244]     Train net output #0: loss = 0.00672168 (* 1 = 0.00672168 loss)
I1024 15:35:45.133678 21201 sgd_solver.cpp:106] Iteration 28300, lr = 0.001
I1024 15:35:58.993068 21201 solver.cpp:228] Iteration 28400, loss = 0.00688042
I1024 15:35:58.993142 21201 solver.cpp:244]     Train net output #0: loss = 0.00688033 (* 1 = 0.00688033 loss)
I1024 15:35:58.993146 21201 sgd_solver.cpp:106] Iteration 28400, lr = 0.001
I1024 15:36:12.853629 21201 solver.cpp:228] Iteration 28500, loss = 0.00731643
I1024 15:36:12.853648 21201 solver.cpp:244]     Train net output #0: loss = 0.00731635 (* 1 = 0.00731635 loss)
I1024 15:36:12.853652 21201 sgd_solver.cpp:106] Iteration 28500, lr = 0.001
I1024 15:36:26.713243 21201 solver.cpp:228] Iteration 28600, loss = 0.00668363
I1024 15:36:26.713263 21201 solver.cpp:244]     Train net output #0: loss = 0.00668354 (* 1 = 0.00668354 loss)
I1024 15:36:26.713265 21201 sgd_solver.cpp:106] Iteration 28600, lr = 0.001
I1024 15:36:40.577494 21201 solver.cpp:228] Iteration 28700, loss = 0.00719208
I1024 15:36:40.577579 21201 solver.cpp:244]     Train net output #0: loss = 0.00719199 (* 1 = 0.00719199 loss)
I1024 15:36:40.577584 21201 sgd_solver.cpp:106] Iteration 28700, lr = 0.001
I1024 15:36:54.435619 21201 solver.cpp:228] Iteration 28800, loss = 0.00670561
I1024 15:36:54.435636 21201 solver.cpp:244]     Train net output #0: loss = 0.00670553 (* 1 = 0.00670553 loss)
I1024 15:36:54.435640 21201 sgd_solver.cpp:106] Iteration 28800, lr = 0.001
I1024 15:37:08.294168 21201 solver.cpp:228] Iteration 28900, loss = 0.00693565
I1024 15:37:08.294186 21201 solver.cpp:244]     Train net output #0: loss = 0.00693556 (* 1 = 0.00693556 loss)
I1024 15:37:08.294190 21201 sgd_solver.cpp:106] Iteration 28900, lr = 0.001
I1024 15:37:22.016646 21201 solver.cpp:337] Iteration 29000, Testing net (#0)
I1024 15:37:22.016746 21201 net.cpp:691] Ignoring source layer loss
I1024 15:37:24.814782 21201 solver.cpp:404]     Test net output #0: accuracy = 0.737981
I1024 15:37:24.951061 21201 solver.cpp:228] Iteration 29000, loss = 0.00731812
I1024 15:37:24.951073 21201 solver.cpp:244]     Train net output #0: loss = 0.00731803 (* 1 = 0.00731803 loss)
I1024 15:37:24.951077 21201 sgd_solver.cpp:106] Iteration 29000, lr = 0.001
I1024 15:37:38.813025 21201 solver.cpp:228] Iteration 29100, loss = 0.00667808
I1024 15:37:38.813043 21201 solver.cpp:244]     Train net output #0: loss = 0.00667799 (* 1 = 0.00667799 loss)
I1024 15:37:38.813047 21201 sgd_solver.cpp:106] Iteration 29100, lr = 0.001
I1024 15:37:52.676748 21201 solver.cpp:228] Iteration 29200, loss = 0.00718511
I1024 15:37:52.676820 21201 solver.cpp:244]     Train net output #0: loss = 0.00718503 (* 1 = 0.00718503 loss)
I1024 15:37:52.676825 21201 sgd_solver.cpp:106] Iteration 29200, lr = 0.001
I1024 15:38:06.537096 21201 solver.cpp:228] Iteration 29300, loss = 0.00669162
I1024 15:38:06.537113 21201 solver.cpp:244]     Train net output #0: loss = 0.00669153 (* 1 = 0.00669153 loss)
I1024 15:38:06.537117 21201 sgd_solver.cpp:106] Iteration 29300, lr = 0.001
I1024 15:38:20.390624 21201 solver.cpp:228] Iteration 29400, loss = 0.00699554
I1024 15:38:20.390641 21201 solver.cpp:244]     Train net output #0: loss = 0.00699546 (* 1 = 0.00699546 loss)
I1024 15:38:20.390645 21201 sgd_solver.cpp:106] Iteration 29400, lr = 0.001
I1024 15:38:34.250505 21201 solver.cpp:228] Iteration 29500, loss = 0.00732245
I1024 15:38:34.250593 21201 solver.cpp:244]     Train net output #0: loss = 0.00732236 (* 1 = 0.00732236 loss)
I1024 15:38:34.250597 21201 sgd_solver.cpp:106] Iteration 29500, lr = 0.001
I1024 15:38:48.098701 21201 solver.cpp:228] Iteration 29600, loss = 0.00669947
I1024 15:38:48.098719 21201 solver.cpp:244]     Train net output #0: loss = 0.00669938 (* 1 = 0.00669938 loss)
I1024 15:38:48.098737 21201 sgd_solver.cpp:106] Iteration 29600, lr = 0.001
I1024 15:39:01.960602 21201 solver.cpp:228] Iteration 29700, loss = 0.00717309
I1024 15:39:01.960621 21201 solver.cpp:244]     Train net output #0: loss = 0.007173 (* 1 = 0.007173 loss)
I1024 15:39:01.960624 21201 sgd_solver.cpp:106] Iteration 29700, lr = 0.001
I1024 15:39:15.820034 21201 solver.cpp:228] Iteration 29800, loss = 0.00662522
I1024 15:39:15.820135 21201 solver.cpp:244]     Train net output #0: loss = 0.00662513 (* 1 = 0.00662513 loss)
I1024 15:39:15.820139 21201 sgd_solver.cpp:106] Iteration 29800, lr = 0.001
I1024 15:39:29.674881 21201 solver.cpp:228] Iteration 29900, loss = 0.00700535
I1024 15:39:29.674899 21201 solver.cpp:244]     Train net output #0: loss = 0.00700526 (* 1 = 0.00700526 loss)
I1024 15:39:29.674902 21201 sgd_solver.cpp:106] Iteration 29900, lr = 0.001
I1024 15:39:43.391986 21201 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/1parts/inception_snapshot_iter_30000.caffemodel
I1024 15:39:43.405411 21201 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/1parts/inception_snapshot_iter_30000.solverstate
I1024 15:39:43.411330 21201 solver.cpp:337] Iteration 30000, Testing net (#0)
I1024 15:39:43.411397 21201 net.cpp:691] Ignoring source layer loss
I1024 15:39:46.198060 21201 solver.cpp:404]     Test net output #0: accuracy = 0.729968
I1024 15:39:46.334424 21201 solver.cpp:228] Iteration 30000, loss = 0.00735501
I1024 15:39:46.334435 21201 solver.cpp:244]     Train net output #0: loss = 0.00735492 (* 1 = 0.00735492 loss)
I1024 15:39:46.334439 21201 sgd_solver.cpp:106] Iteration 30000, lr = 0.001
I1024 15:40:00.196671 21201 solver.cpp:228] Iteration 30100, loss = 0.00671815
I1024 15:40:00.196691 21201 solver.cpp:244]     Train net output #0: loss = 0.00671806 (* 1 = 0.00671806 loss)
I1024 15:40:00.196693 21201 sgd_solver.cpp:106] Iteration 30100, lr = 0.001
I1024 15:40:14.053510 21201 solver.cpp:228] Iteration 30200, loss = 0.00712456
I1024 15:40:14.053529 21201 solver.cpp:244]     Train net output #0: loss = 0.00712447 (* 1 = 0.00712447 loss)
I1024 15:40:14.053531 21201 sgd_solver.cpp:106] Iteration 30200, lr = 0.001
I1024 15:40:27.912580 21201 solver.cpp:228] Iteration 30300, loss = 0.00662864
I1024 15:40:27.912675 21201 solver.cpp:244]     Train net output #0: loss = 0.00662855 (* 1 = 0.00662855 loss)
I1024 15:40:27.912693 21201 sgd_solver.cpp:106] Iteration 30300, lr = 0.001
I1024 15:40:41.769162 21201 solver.cpp:228] Iteration 30400, loss = 0.00703624
I1024 15:40:41.769181 21201 solver.cpp:244]     Train net output #0: loss = 0.00703615 (* 1 = 0.00703615 loss)
I1024 15:40:41.769184 21201 sgd_solver.cpp:106] Iteration 30400, lr = 0.001
I1024 15:40:55.628119 21201 solver.cpp:228] Iteration 30500, loss = 0.00736262
I1024 15:40:55.628137 21201 solver.cpp:244]     Train net output #0: loss = 0.00736254 (* 1 = 0.00736254 loss)
I1024 15:40:55.628140 21201 sgd_solver.cpp:106] Iteration 30500, lr = 0.001
I1024 15:41:09.479275 21201 solver.cpp:228] Iteration 30600, loss = 0.00671884
I1024 15:41:09.479336 21201 solver.cpp:244]     Train net output #0: loss = 0.00671875 (* 1 = 0.00671875 loss)
I1024 15:41:09.479341 21201 sgd_solver.cpp:106] Iteration 30600, lr = 0.001
I1024 15:41:23.329315 21201 solver.cpp:228] Iteration 30700, loss = 0.0071158
I1024 15:41:23.329334 21201 solver.cpp:244]     Train net output #0: loss = 0.00711572 (* 1 = 0.00711572 loss)
I1024 15:41:23.329337 21201 sgd_solver.cpp:106] Iteration 30700, lr = 0.001
I1024 15:41:37.185488 21201 solver.cpp:228] Iteration 30800, loss = 0.00665735
I1024 15:41:37.185506 21201 solver.cpp:244]     Train net output #0: loss = 0.00665726 (* 1 = 0.00665726 loss)
I1024 15:41:37.185509 21201 sgd_solver.cpp:106] Iteration 30800, lr = 0.001
I1024 15:41:51.046303 21201 solver.cpp:228] Iteration 30900, loss = 0.00705727
I1024 15:41:51.046376 21201 solver.cpp:244]     Train net output #0: loss = 0.00705718 (* 1 = 0.00705718 loss)
I1024 15:41:51.046380 21201 sgd_solver.cpp:106] Iteration 30900, lr = 0.001
I1024 15:42:04.774775 21201 solver.cpp:337] Iteration 31000, Testing net (#0)
I1024 15:42:04.774825 21201 net.cpp:691] Ignoring source layer loss
I1024 15:42:07.569406 21201 solver.cpp:404]     Test net output #0: accuracy = 0.735978
I1024 15:42:07.705567 21201 solver.cpp:228] Iteration 31000, loss = 0.00735843
I1024 15:42:07.705579 21201 solver.cpp:244]     Train net output #0: loss = 0.00735834 (* 1 = 0.00735834 loss)
I1024 15:42:07.705584 21201 sgd_solver.cpp:106] Iteration 31000, lr = 0.001
I1024 15:42:21.561661 21201 solver.cpp:228] Iteration 31100, loss = 0.00673668
I1024 15:42:21.561748 21201 solver.cpp:244]     Train net output #0: loss = 0.00673659 (* 1 = 0.00673659 loss)
I1024 15:42:21.561751 21201 sgd_solver.cpp:106] Iteration 31100, lr = 0.001
I1024 15:42:35.418706 21201 solver.cpp:228] Iteration 31200, loss = 0.00709663
I1024 15:42:35.418725 21201 solver.cpp:244]     Train net output #0: loss = 0.00709654 (* 1 = 0.00709654 loss)
I1024 15:42:35.418727 21201 sgd_solver.cpp:106] Iteration 31200, lr = 0.001
I1024 15:42:49.274977 21201 solver.cpp:228] Iteration 31300, loss = 0.00671147
I1024 15:42:49.275010 21201 solver.cpp:244]     Train net output #0: loss = 0.00671138 (* 1 = 0.00671138 loss)
I1024 15:42:49.275014 21201 sgd_solver.cpp:106] Iteration 31300, lr = 0.001
I1024 15:43:03.129278 21201 solver.cpp:228] Iteration 31400, loss = 0.00709007
I1024 15:43:03.129375 21201 solver.cpp:244]     Train net output #0: loss = 0.00708998 (* 1 = 0.00708998 loss)
I1024 15:43:03.129380 21201 sgd_solver.cpp:106] Iteration 31400, lr = 0.001
